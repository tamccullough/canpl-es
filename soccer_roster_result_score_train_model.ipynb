{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cpl_main as cpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(f'datasets/soccer-nn-train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game</th>\n",
       "      <th>team</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>p5</th>\n",
       "      <th>p6</th>\n",
       "      <th>p7</th>\n",
       "      <th>p8</th>\n",
       "      <th>p9</th>\n",
       "      <th>p9.1</th>\n",
       "      <th>p10</th>\n",
       "      <th>p11</th>\n",
       "      <th>p12</th>\n",
       "      <th>p13</th>\n",
       "      <th>r</th>\n",
       "      <th>s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I1</td>\n",
       "      <td>Forge FC</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I1</td>\n",
       "      <td>York9 FC</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I2</td>\n",
       "      <td>Pacific FC</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I2</td>\n",
       "      <td>HFX Wanderers FC</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I3</td>\n",
       "      <td>Pacific FC</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1785</th>\n",
       "      <td>XVIII389</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786</th>\n",
       "      <td>XVIII390</td>\n",
       "      <td>NY Red Bulls</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1787</th>\n",
       "      <td>XVIII390</td>\n",
       "      <td>Orlando City</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1788</th>\n",
       "      <td>XVIII391</td>\n",
       "      <td>NYCFC</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1789</th>\n",
       "      <td>XVIII391</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1790 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          game              team    p1    p2    p3    p4    p5    p6    p7  \\\n",
       "0           I1          Forge FC  0.71  0.89  0.74  0.71  0.48  0.89  0.77   \n",
       "1           I1          York9 FC  0.93  0.92  0.91  0.86  0.41  0.78  0.65   \n",
       "2           I2        Pacific FC  0.54  0.78  0.69  0.50  0.39  0.72  0.69   \n",
       "3           I2  HFX Wanderers FC  0.54  0.92  0.77  0.67  0.62  0.57  0.52   \n",
       "4           I3        Pacific FC  0.54  0.78  0.69  0.50  0.39  0.72  0.69   \n",
       "...        ...               ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "1785  XVIII389           Atlanta  0.73  0.82  0.74  0.70  0.53  0.94  0.85   \n",
       "1786  XVIII390      NY Red Bulls  0.72  0.74  0.63  0.60  0.58  0.79  0.70   \n",
       "1787  XVIII390      Orlando City  0.58  0.71  0.43  0.36  0.26  0.66  0.40   \n",
       "1788  XVIII391             NYCFC  0.77  0.66  0.56  0.46  0.42  0.97  0.60   \n",
       "1789  XVIII391      Philadelphia  0.85  0.82  0.72  0.46  0.39  0.80  0.72   \n",
       "\n",
       "        p8    p9  p9.1   p10  p11  p12  p13  r  s  \n",
       "0     0.52  0.50  0.48  0.42    0    0    0  2  1  \n",
       "1     0.64  0.46  0.70  0.47    0    0    0  2  1  \n",
       "2     0.57  0.51  0.79  0.27    0    0    0  3  1  \n",
       "3     0.47  0.37  0.77  0.28    0    0    0  1  0  \n",
       "4     0.57  0.51  0.79  0.27    0    0    0  1  1  \n",
       "...    ...   ...   ...   ...  ...  ...  ... .. ..  \n",
       "1785  0.62  0.40  0.84  0.03    0    0    0  1  1  \n",
       "1786  0.69  0.61  0.06  0.03    0    0    0  3  1  \n",
       "1787  0.33  0.33  0.62  0.47    0    0    0  1  0  \n",
       "1788  0.54  0.49  0.67  0.33    0    0    0  3  3  \n",
       "1789  0.66  0.65  0.44  0.00    0    0    0  1  1  \n",
       "\n",
       "[1790 rows x 18 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1790, 18)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pump_it_up(db):\n",
    "    df = db.copy()\n",
    "    dc = df.copy()\n",
    "    m = df['p1'].copy()\n",
    "    n = df['p2'].copy()\n",
    "    o = df['p3'].copy()\n",
    "    p = df['p4'].copy()\n",
    "    q = df['p5'].copy()\n",
    "    r = df['p6'].copy()\n",
    "    df['p1'] = dc.pop('p8')\n",
    "    df['p2'] = dc.pop('p10')\n",
    "    df['p3'] = dc.pop('p12')\n",
    "    df['p4'] = dc.pop('p9')\n",
    "    df['p5'] = dc.pop('p11')\n",
    "    df['p6'] = dc.pop('p13')\n",
    "    df['p7'] = m\n",
    "    df['p8'] = n\n",
    "    df['p9'] = o\n",
    "    df['p10'] = p\n",
    "    df['p11'] = q\n",
    "    df['p12'] = r\n",
    "    df['p13'] = dc.pop('p7')\n",
    "    dc = df.copy()\n",
    "    db = pd.concat([db,df])\n",
    "    df = dc.copy()\n",
    "    m = df['p13'].copy()\n",
    "    n = df['p12'].copy()\n",
    "    o = df['p11'].copy()\n",
    "    p = df['p10'].copy()\n",
    "    q = df['p9'].copy()\n",
    "    r = df['p8'].copy()\n",
    "    df['p13'] = dc.pop('p8')\n",
    "    df['p12'] = dc.pop('p10')\n",
    "    df['p11'] = dc.pop('p12')\n",
    "    df['p10'] = dc.pop('p9')\n",
    "    df['p9'] = dc.pop('p11')\n",
    "    df['p8'] = dc.pop('p13')\n",
    "    df['p7'] = m\n",
    "    df['p6'] = n\n",
    "    df['p5'] = o\n",
    "    df['p4'] = p\n",
    "    df['p3'] = q\n",
    "    df['p2'] = r\n",
    "    df['p1'] = dc.pop('p7')\n",
    "    #dc = df.copy()\n",
    "    db = pd.concat([db,df])\n",
    "    db = cpl.index_reset(db)\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5370, 18)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pump_it_up(results)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16110, 18)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = pump_it_up(df)\n",
    "db.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.pop('game')\n",
    "db.pop('team')\n",
    "db.pop('r')\n",
    "y = db.pop('s')\n",
    "X = db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>p5</th>\n",
       "      <th>p6</th>\n",
       "      <th>p7</th>\n",
       "      <th>p8</th>\n",
       "      <th>p9</th>\n",
       "      <th>p9.1</th>\n",
       "      <th>p10</th>\n",
       "      <th>p11</th>\n",
       "      <th>p12</th>\n",
       "      <th>p13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     p1    p2    p3    p4    p5    p6    p7    p8    p9  p9.1   p10  p11  p12  \\\n",
       "0  0.71  0.89  0.74  0.71  0.48  0.89  0.77  0.52  0.50  0.48  0.42  0.0  0.0   \n",
       "1  0.93  0.92  0.91  0.86  0.41  0.78  0.65  0.64  0.46  0.70  0.47  0.0  0.0   \n",
       "\n",
       "   p13  \n",
       "0  0.0  \n",
       "1  0.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries from sklearn\n",
    "from sklearn import tree\n",
    "#from sklearn.datasets import make_classification\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler#,Imputer\n",
    "from sklearn import metrics\n",
    "#colours = sns.set_palette('pastel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import algorithm modules\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeRegressor \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Model\n",
      "\n",
      "RMSE:  1.270476015912387\n",
      "\n",
      "Score 1.32\n"
     ]
    }
   ],
   "source": [
    "#Linear Regression Model\n",
    "def linearRegression():\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "lr = linearRegression()\n",
    "\n",
    "print('Linear Regression Model')\n",
    "\n",
    "print('\\nRMSE: ', sqrt(mean_squared_error(y_test,lr.predict(X_test))))\n",
    "print('\\nScore',round(lr.score(X_test, y_test)*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Regression Model\n",
      "\n",
      "RMSE:  1.274244322645035\n",
      "\n",
      "Score 0.73\n"
     ]
    }
   ],
   "source": [
    "#DecisionTreeRegressor\n",
    "def decisionTree():\n",
    "    model = DecisionTreeRegressor(criterion='mse', splitter='random', max_depth=8, max_features='log2')\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "dt = decisionTree()\n",
    "\n",
    "print('Decision Tree Regression Model')\n",
    "\n",
    "print('\\nRMSE: ', sqrt(mean_squared_error(y_test, dt.predict(X_test))))\n",
    "print('\\nScore',round(dt.score(X_test, y_test)*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regression Model\n",
      "\n",
      "RMSE:  1.2733561723611195\n",
      "\n",
      "Score 0.87\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Regression\n",
    "def forestRegression():\n",
    "    model = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "    \n",
    "rf = forestRegression()\n",
    "\n",
    "print('Random Forest Regression Model')\n",
    "\n",
    "print('\\nRMSE: ', sqrt(mean_squared_error(y_test,rf.predict(X_test))))\n",
    "print('\\nScore',round(rf.score(X_test, y_test)*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingRegressor\n",
    "vr = VotingRegressor(estimators=[('lr', lr), ('dt', dt), ('rf', rf)])\n",
    "vr = vr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                960       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 5,185\n",
      "Trainable params: 5,185\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def kerasSequential():\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(64, activation='relu', input_shape=[X_train.shape[1]]),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "    model.compile(loss='mse',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['mae', 'mse'])\n",
    "    \n",
    "    return model\n",
    "ks = kerasSequential()\n",
    "\n",
    "ks.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_shapes(): # can make yours to take inputs; this'll use local variable values\n",
    "    print(\"Expected: (num_samples, timesteps, channels)\")\n",
    "    print(\"Sequences: {}\".format(Sequences.shape))\n",
    "    print(\"Targets:   {}\".format(Targets.shape))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.25557768],\n",
       "       [-0.11910703],\n",
       "       [-0.13915148],\n",
       "       [-0.27170318],\n",
       "       [-0.12889375],\n",
       "       [-0.18813527],\n",
       "       [-0.13426894],\n",
       "       [-0.30673444],\n",
       "       [-0.31226888],\n",
       "       [-0.3011915 ]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_batch = X_train[:10]\n",
    "example_result = ks.predict(example_batch)\n",
    "example_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9021 samples, validate on 2256 samples\n",
      "Epoch 1/1000\n",
      "9021/9021 [==============================] - 2s 175us/sample - loss: 1.7655 - mae: 1.0478 - mse: 1.7655 - val_loss: 1.4805 - val_mae: 0.9861 - val_mse: 1.4805\n",
      "Epoch 2/1000\n",
      "9021/9021 [==============================] - 0s 37us/sample - loss: 1.5557 - mae: 1.0093 - mse: 1.5557 - val_loss: 1.4753 - val_mae: 0.9876 - val_mse: 1.4753\n",
      "Epoch 3/1000\n",
      "9021/9021 [==============================] - 0s 38us/sample - loss: 1.5527 - mae: 1.0083 - mse: 1.5527 - val_loss: 1.4758 - val_mae: 0.9851 - val_mse: 1.4758\n",
      "Epoch 4/1000\n",
      "9021/9021 [==============================] - 0s 38us/sample - loss: 1.5492 - mae: 1.0078 - mse: 1.5492 - val_loss: 1.4865 - val_mae: 0.9977 - val_mse: 1.4865\n",
      "Epoch 5/1000\n",
      "9021/9021 [==============================] - 0s 42us/sample - loss: 1.5462 - mae: 1.0078 - mse: 1.5462 - val_loss: 1.5401 - val_mae: 0.9741 - val_mse: 1.5401\n",
      "Epoch 6/1000\n",
      "9021/9021 [==============================] - 0s 46us/sample - loss: 1.5451 - mae: 1.0044 - mse: 1.5451 - val_loss: 1.4742 - val_mae: 0.9862 - val_mse: 1.4742\n",
      "Epoch 7/1000\n",
      "9021/9021 [==============================] - 0s 53us/sample - loss: 1.5490 - mae: 1.0059 - mse: 1.5490 - val_loss: 1.4779 - val_mae: 0.9827 - val_mse: 1.4779\n",
      "Epoch 8/1000\n",
      "9021/9021 [==============================] - 0s 43us/sample - loss: 1.5435 - mae: 1.0046 - mse: 1.5435 - val_loss: 1.4717 - val_mae: 0.9914 - val_mse: 1.4717\n",
      "Epoch 9/1000\n",
      "9021/9021 [==============================] - 0s 39us/sample - loss: 1.5431 - mae: 1.0046 - mse: 1.5431 - val_loss: 1.4771 - val_mae: 0.9944 - val_mse: 1.4771\n",
      "Epoch 10/1000\n",
      "9021/9021 [==============================] - 0s 35us/sample - loss: 1.5401 - mae: 1.0027 - mse: 1.5401 - val_loss: 1.4966 - val_mae: 0.9780 - val_mse: 1.4966\n",
      "Epoch 11/1000\n",
      "9021/9021 [==============================] - 0s 29us/sample - loss: 1.5372 - mae: 1.0009 - mse: 1.5372 - val_loss: 1.4790 - val_mae: 0.9944 - val_mse: 1.4790\n",
      "Epoch 12/1000\n",
      "9021/9021 [==============================] - 0s 27us/sample - loss: 1.5404 - mae: 1.0036 - mse: 1.5404 - val_loss: 1.4761 - val_mae: 0.9933 - val_mse: 1.4761\n",
      "Epoch 13/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.5385 - mae: 1.0017 - mse: 1.5385 - val_loss: 1.4739 - val_mae: 0.9922 - val_mse: 1.4739\n",
      "Epoch 14/1000\n",
      "9021/9021 [==============================] - 0s 27us/sample - loss: 1.5381 - mae: 1.0026 - mse: 1.5381 - val_loss: 1.4770 - val_mae: 0.9832 - val_mse: 1.4770\n",
      "Epoch 15/1000\n",
      "9021/9021 [==============================] - 0s 47us/sample - loss: 1.5388 - mae: 1.0031 - mse: 1.5388 - val_loss: 1.4898 - val_mae: 0.9795 - val_mse: 1.4898\n",
      "Epoch 16/1000\n",
      "9021/9021 [==============================] - 0s 44us/sample - loss: 1.5389 - mae: 1.0023 - mse: 1.5389 - val_loss: 1.4986 - val_mae: 0.9998 - val_mse: 1.4986\n",
      "Epoch 17/1000\n",
      "9021/9021 [==============================] - 0s 38us/sample - loss: 1.5365 - mae: 1.0009 - mse: 1.5365 - val_loss: 1.4728 - val_mae: 0.9907 - val_mse: 1.4728\n",
      "Epoch 18/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.5379 - mae: 1.0011 - mse: 1.5379 - val_loss: 1.4743 - val_mae: 0.9913 - val_mse: 1.4743\n",
      "Epoch 19/1000\n",
      "9021/9021 [==============================] - 0s 25us/sample - loss: 1.5351 - mae: 0.9997 - mse: 1.5351 - val_loss: 1.4763 - val_mae: 0.9811 - val_mse: 1.4763\n",
      "Epoch 20/1000\n",
      "9021/9021 [==============================] - 0s 28us/sample - loss: 1.5369 - mae: 1.0010 - mse: 1.5369 - val_loss: 1.4727 - val_mae: 0.9840 - val_mse: 1.4727\n",
      "Epoch 21/1000\n",
      "9021/9021 [==============================] - 0s 31us/sample - loss: 1.5356 - mae: 0.9999 - mse: 1.5356 - val_loss: 1.4816 - val_mae: 0.9805 - val_mse: 1.4816\n",
      "Epoch 22/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.5356 - mae: 1.0009 - mse: 1.5356 - val_loss: 1.4708 - val_mae: 0.9861 - val_mse: 1.4708\n",
      "Epoch 23/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.5337 - mae: 0.9985 - mse: 1.5337 - val_loss: 1.4755 - val_mae: 0.9823 - val_mse: 1.4755\n",
      "Epoch 24/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.5333 - mae: 0.9983 - mse: 1.5333 - val_loss: 1.4804 - val_mae: 0.9807 - val_mse: 1.4804\n",
      "Epoch 25/1000\n",
      "9021/9021 [==============================] - 0s 29us/sample - loss: 1.5325 - mae: 0.9974 - mse: 1.5325 - val_loss: 1.4906 - val_mae: 0.9948 - val_mse: 1.4906\n",
      "Epoch 26/1000\n",
      "9021/9021 [==============================] - 0s 28us/sample - loss: 1.5331 - mae: 0.9986 - mse: 1.5331 - val_loss: 1.4742 - val_mae: 0.9827 - val_mse: 1.4742\n",
      "Epoch 27/1000\n",
      "9021/9021 [==============================] - 0s 44us/sample - loss: 1.5309 - mae: 0.9979 - mse: 1.5309 - val_loss: 1.4843 - val_mae: 0.9955 - val_mse: 1.4843\n",
      "Epoch 28/1000\n",
      "9021/9021 [==============================] - 0s 30us/sample - loss: 1.5293 - mae: 0.9970 - mse: 1.5293 - val_loss: 1.4786 - val_mae: 0.9811 - val_mse: 1.4786\n",
      "Epoch 29/1000\n",
      "9021/9021 [==============================] - 0s 34us/sample - loss: 1.5326 - mae: 0.9968 - mse: 1.5326 - val_loss: 1.4736 - val_mae: 0.9835 - val_mse: 1.4736\n",
      "Epoch 30/1000\n",
      "9021/9021 [==============================] - 0s 52us/sample - loss: 1.5306 - mae: 0.9973 - mse: 1.5306 - val_loss: 1.4742 - val_mae: 0.9830 - val_mse: 1.4742\n",
      "Epoch 31/1000\n",
      "9021/9021 [==============================] - 0s 53us/sample - loss: 1.5309 - mae: 0.9976 - mse: 1.5309 - val_loss: 1.5078 - val_mae: 0.9763 - val_mse: 1.5078\n",
      "Epoch 32/1000\n",
      "9021/9021 [==============================] - 0s 39us/sample - loss: 1.5303 - mae: 0.9959 - mse: 1.5303 - val_loss: 1.4797 - val_mae: 0.9905 - val_mse: 1.4797\n",
      "Epoch 33/1000\n",
      "9021/9021 [==============================] - 0s 40us/sample - loss: 1.5309 - mae: 0.9979 - mse: 1.5309 - val_loss: 1.4981 - val_mae: 0.9776 - val_mse: 1.4981\n",
      "Epoch 34/1000\n",
      "9021/9021 [==============================] - 0s 44us/sample - loss: 1.5304 - mae: 0.9970 - mse: 1.5304 - val_loss: 1.4800 - val_mae: 0.9822 - val_mse: 1.4800\n",
      "Epoch 35/1000\n",
      "9021/9021 [==============================] - 0s 44us/sample - loss: 1.5260 - mae: 0.9943 - mse: 1.5260 - val_loss: 1.4829 - val_mae: 0.9920 - val_mse: 1.4829\n",
      "Epoch 36/1000\n",
      "9021/9021 [==============================] - 0s 40us/sample - loss: 1.5329 - mae: 0.9980 - mse: 1.5329 - val_loss: 1.5009 - val_mae: 0.9991 - val_mse: 1.5009\n",
      "Epoch 37/1000\n",
      "9021/9021 [==============================] - 0s 41us/sample - loss: 1.5284 - mae: 0.9962 - mse: 1.5284 - val_loss: 1.5125 - val_mae: 0.9761 - val_mse: 1.5125\n",
      "Epoch 38/1000\n",
      "9021/9021 [==============================] - 0s 40us/sample - loss: 1.5284 - mae: 0.9954 - mse: 1.5284 - val_loss: 1.4737 - val_mae: 0.9876 - val_mse: 1.4737\n",
      "Epoch 39/1000\n",
      "9021/9021 [==============================] - 0s 43us/sample - loss: 1.5309 - mae: 0.9966 - mse: 1.5309 - val_loss: 1.4889 - val_mae: 0.9798 - val_mse: 1.4889\n",
      "Epoch 40/1000\n",
      "9021/9021 [==============================] - 0s 40us/sample - loss: 1.5277 - mae: 0.9959 - mse: 1.5277 - val_loss: 1.4749 - val_mae: 0.9892 - val_mse: 1.4749\n",
      "Epoch 41/1000\n",
      "9021/9021 [==============================] - 0s 43us/sample - loss: 1.5285 - mae: 0.9953 - mse: 1.5285 - val_loss: 1.4813 - val_mae: 0.9806 - val_mse: 1.4813\n",
      "Epoch 42/1000\n",
      "9021/9021 [==============================] - 0s 40us/sample - loss: 1.5273 - mae: 0.9951 - mse: 1.5273 - val_loss: 1.4781 - val_mae: 0.9813 - val_mse: 1.4781\n",
      "Epoch 43/1000\n",
      "9021/9021 [==============================] - 1s 55us/sample - loss: 1.5260 - mae: 0.9950 - mse: 1.5260 - val_loss: 1.5242 - val_mae: 0.9758 - val_mse: 1.5242\n",
      "Epoch 44/1000\n",
      "9021/9021 [==============================] - 0s 36us/sample - loss: 1.5260 - mae: 0.9938 - mse: 1.5260 - val_loss: 1.4711 - val_mae: 0.9848 - val_mse: 1.4711\n",
      "Epoch 45/1000\n",
      "9021/9021 [==============================] - 0s 34us/sample - loss: 1.5244 - mae: 0.9932 - mse: 1.5244 - val_loss: 1.4713 - val_mae: 0.9860 - val_mse: 1.4713\n",
      "Epoch 46/1000\n",
      "9021/9021 [==============================] - 0s 34us/sample - loss: 1.5248 - mae: 0.9942 - mse: 1.5248 - val_loss: 1.4840 - val_mae: 0.9921 - val_mse: 1.4840\n",
      "Epoch 47/1000\n",
      "9021/9021 [==============================] - 0s 36us/sample - loss: 1.5262 - mae: 0.9931 - mse: 1.5262 - val_loss: 1.4731 - val_mae: 0.9819 - val_mse: 1.4731\n",
      "Epoch 48/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9021/9021 [==============================] - 0s 38us/sample - loss: 1.5227 - mae: 0.9927 - mse: 1.5227 - val_loss: 1.4803 - val_mae: 0.9900 - val_mse: 1.4803\n",
      "Epoch 49/1000\n",
      "9021/9021 [==============================] - 0s 35us/sample - loss: 1.5260 - mae: 0.9952 - mse: 1.5260 - val_loss: 1.4778 - val_mae: 0.9888 - val_mse: 1.4778\n",
      "Epoch 50/1000\n",
      "9021/9021 [==============================] - 0s 28us/sample - loss: 1.5276 - mae: 0.9956 - mse: 1.5276 - val_loss: 1.4723 - val_mae: 0.9845 - val_mse: 1.4723\n",
      "Epoch 51/1000\n",
      "9021/9021 [==============================] - 0s 34us/sample - loss: 1.5244 - mae: 0.9941 - mse: 1.5244 - val_loss: 1.4980 - val_mae: 0.9973 - val_mse: 1.4980\n",
      "Epoch 52/1000\n",
      "9021/9021 [==============================] - 0s 40us/sample - loss: 1.5223 - mae: 0.9937 - mse: 1.5223 - val_loss: 1.5265 - val_mae: 0.9765 - val_mse: 1.5265\n",
      "Epoch 53/1000\n",
      "9021/9021 [==============================] - 0s 40us/sample - loss: 1.5239 - mae: 0.9945 - mse: 1.5239 - val_loss: 1.4766 - val_mae: 0.9841 - val_mse: 1.4766\n",
      "Epoch 54/1000\n",
      "9021/9021 [==============================] - 0s 37us/sample - loss: 1.5236 - mae: 0.9937 - mse: 1.5236 - val_loss: 1.4760 - val_mae: 0.9848 - val_mse: 1.4760\n",
      "Epoch 55/1000\n",
      "9021/9021 [==============================] - 0s 37us/sample - loss: 1.5208 - mae: 0.9932 - mse: 1.5208 - val_loss: 1.5249 - val_mae: 0.9779 - val_mse: 1.5249\n",
      "Epoch 56/1000\n",
      "9021/9021 [==============================] - 0s 34us/sample - loss: 1.5222 - mae: 0.9918 - mse: 1.5222 - val_loss: 1.4738 - val_mae: 0.9861 - val_mse: 1.4738\n",
      "Epoch 57/1000\n",
      "9021/9021 [==============================] - 0s 39us/sample - loss: 1.5214 - mae: 0.9922 - mse: 1.5214 - val_loss: 1.5072 - val_mae: 0.9771 - val_mse: 1.5072\n",
      "Epoch 58/1000\n",
      "9021/9021 [==============================] - 0s 45us/sample - loss: 1.5238 - mae: 0.9939 - mse: 1.5238 - val_loss: 1.4813 - val_mae: 0.9800 - val_mse: 1.4813\n",
      "Epoch 59/1000\n",
      "9021/9021 [==============================] - 0s 38us/sample - loss: 1.5224 - mae: 0.9933 - mse: 1.5224 - val_loss: 1.4805 - val_mae: 0.9907 - val_mse: 1.4805\n",
      "Epoch 60/1000\n",
      "9021/9021 [==============================] - 0s 37us/sample - loss: 1.5193 - mae: 0.9921 - mse: 1.5193 - val_loss: 1.4743 - val_mae: 0.9869 - val_mse: 1.4743\n",
      "Epoch 61/1000\n",
      "9021/9021 [==============================] - 0s 35us/sample - loss: 1.5191 - mae: 0.9916 - mse: 1.5191 - val_loss: 1.4759 - val_mae: 0.9850 - val_mse: 1.4759\n",
      "Epoch 62/1000\n",
      "9021/9021 [==============================] - 0s 37us/sample - loss: 1.5229 - mae: 0.9940 - mse: 1.5229 - val_loss: 1.5011 - val_mae: 0.9989 - val_mse: 1.5011\n",
      "Epoch 63/1000\n",
      "9021/9021 [==============================] - 0s 34us/sample - loss: 1.5200 - mae: 0.9920 - mse: 1.5200 - val_loss: 1.4731 - val_mae: 0.9854 - val_mse: 1.4731\n",
      "Epoch 64/1000\n",
      "9021/9021 [==============================] - 0s 34us/sample - loss: 1.5159 - mae: 0.9911 - mse: 1.5159 - val_loss: 1.4736 - val_mae: 0.9819 - val_mse: 1.4736\n",
      "Epoch 65/1000\n",
      "9021/9021 [==============================] - 0s 38us/sample - loss: 1.5196 - mae: 0.9916 - mse: 1.5196 - val_loss: 1.4819 - val_mae: 0.9810 - val_mse: 1.4819\n",
      "Epoch 66/1000\n",
      "9021/9021 [==============================] - 0s 43us/sample - loss: 1.5191 - mae: 0.9897 - mse: 1.5191 - val_loss: 1.4818 - val_mae: 0.9887 - val_mse: 1.4818\n",
      "Epoch 67/1000\n",
      "9021/9021 [==============================] - 0s 38us/sample - loss: 1.5192 - mae: 0.9909 - mse: 1.5192 - val_loss: 1.5068 - val_mae: 0.9773 - val_mse: 1.5068\n",
      "Epoch 68/1000\n",
      "9021/9021 [==============================] - 0s 43us/sample - loss: 1.5201 - mae: 0.9917 - mse: 1.5201 - val_loss: 1.4804 - val_mae: 0.9894 - val_mse: 1.4804\n",
      "Epoch 69/1000\n",
      "9021/9021 [==============================] - 0s 53us/sample - loss: 1.5219 - mae: 0.9919 - mse: 1.5219 - val_loss: 1.4877 - val_mae: 0.9796 - val_mse: 1.4877\n",
      "Epoch 70/1000\n",
      "9021/9021 [==============================] - 0s 43us/sample - loss: 1.5197 - mae: 0.9912 - mse: 1.5197 - val_loss: 1.5192 - val_mae: 0.9748 - val_mse: 1.5192\n",
      "Epoch 71/1000\n",
      "9021/9021 [==============================] - 0s 37us/sample - loss: 1.5176 - mae: 0.9901 - mse: 1.5176 - val_loss: 1.4884 - val_mae: 0.9787 - val_mse: 1.4884\n",
      "Epoch 72/1000\n",
      "9021/9021 [==============================] - 0s 36us/sample - loss: 1.5144 - mae: 0.9882 - mse: 1.5144 - val_loss: 1.4801 - val_mae: 0.9843 - val_mse: 1.4801\n",
      "Epoch 73/1000\n",
      "9021/9021 [==============================] - 0s 36us/sample - loss: 1.5152 - mae: 0.9888 - mse: 1.5152 - val_loss: 1.4863 - val_mae: 0.9933 - val_mse: 1.4863\n",
      "Epoch 74/1000\n",
      "9021/9021 [==============================] - 1s 56us/sample - loss: 1.5166 - mae: 0.9901 - mse: 1.5166 - val_loss: 1.4746 - val_mae: 0.9871 - val_mse: 1.4746\n",
      "Epoch 75/1000\n",
      "9021/9021 [==============================] - 1s 56us/sample - loss: 1.5176 - mae: 0.9914 - mse: 1.5176 - val_loss: 1.4763 - val_mae: 0.9869 - val_mse: 1.4763\n",
      "Epoch 76/1000\n",
      "9021/9021 [==============================] - 0s 45us/sample - loss: 1.5163 - mae: 0.9893 - mse: 1.5163 - val_loss: 1.4901 - val_mae: 0.9801 - val_mse: 1.4901\n",
      "Epoch 77/1000\n",
      "9021/9021 [==============================] - 0s 41us/sample - loss: 1.5170 - mae: 0.9902 - mse: 1.5170 - val_loss: 1.4776 - val_mae: 0.9860 - val_mse: 1.4776\n",
      "Epoch 78/1000\n",
      "9021/9021 [==============================] - 0s 44us/sample - loss: 1.5170 - mae: 0.9901 - mse: 1.5170 - val_loss: 1.5112 - val_mae: 1.0005 - val_mse: 1.5112\n",
      "Epoch 79/1000\n",
      "9021/9021 [==============================] - 0s 39us/sample - loss: 1.5173 - mae: 0.9905 - mse: 1.5173 - val_loss: 1.4792 - val_mae: 0.9803 - val_mse: 1.4792\n",
      "Epoch 80/1000\n",
      "9021/9021 [==============================] - 0s 49us/sample - loss: 1.5160 - mae: 0.9885 - mse: 1.5160 - val_loss: 1.4756 - val_mae: 0.9811 - val_mse: 1.4756\n",
      "Epoch 81/1000\n",
      "9021/9021 [==============================] - 0s 43us/sample - loss: 1.5155 - mae: 0.9900 - mse: 1.5155 - val_loss: 1.4833 - val_mae: 0.9804 - val_mse: 1.4833\n",
      "Epoch 82/1000\n",
      "9021/9021 [==============================] - 0s 48us/sample - loss: 1.5167 - mae: 0.9902 - mse: 1.5167 - val_loss: 1.4755 - val_mae: 0.9828 - val_mse: 1.4755\n",
      "Epoch 83/1000\n",
      "9021/9021 [==============================] - 0s 51us/sample - loss: 1.5146 - mae: 0.9898 - mse: 1.5146 - val_loss: 1.4916 - val_mae: 0.9796 - val_mse: 1.4916\n",
      "Epoch 84/1000\n",
      "9021/9021 [==============================] - 0s 45us/sample - loss: 1.5162 - mae: 0.9909 - mse: 1.5162 - val_loss: 1.4778 - val_mae: 0.9820 - val_mse: 1.4778\n",
      "Epoch 85/1000\n",
      "9021/9021 [==============================] - 0s 46us/sample - loss: 1.5154 - mae: 0.9898 - mse: 1.5154 - val_loss: 1.4795 - val_mae: 0.9844 - val_mse: 1.4795\n",
      "Epoch 86/1000\n",
      "9021/9021 [==============================] - 0s 44us/sample - loss: 1.5134 - mae: 0.9881 - mse: 1.5134 - val_loss: 1.4756 - val_mae: 0.9803 - val_mse: 1.4756\n",
      "Epoch 87/1000\n",
      "9021/9021 [==============================] - 0s 41us/sample - loss: 1.5144 - mae: 0.9892 - mse: 1.5144 - val_loss: 1.4925 - val_mae: 0.9786 - val_mse: 1.4925\n",
      "Epoch 88/1000\n",
      "9021/9021 [==============================] - 0s 47us/sample - loss: 1.5121 - mae: 0.9877 - mse: 1.5121 - val_loss: 1.5023 - val_mae: 0.9803 - val_mse: 1.5023\n",
      "Epoch 89/1000\n",
      "9021/9021 [==============================] - 0s 43us/sample - loss: 1.5131 - mae: 0.9886 - mse: 1.5131 - val_loss: 1.4872 - val_mae: 0.9795 - val_mse: 1.4872\n",
      "Epoch 90/1000\n",
      "9021/9021 [==============================] - 0s 44us/sample - loss: 1.5133 - mae: 0.9885 - mse: 1.5133 - val_loss: 1.4739 - val_mae: 0.9824 - val_mse: 1.4739\n",
      "Epoch 91/1000\n",
      "9021/9021 [==============================] - 0s 41us/sample - loss: 1.5142 - mae: 0.9889 - mse: 1.5142 - val_loss: 1.4751 - val_mae: 0.9833 - val_mse: 1.4751\n",
      "Epoch 92/1000\n",
      "9021/9021 [==============================] - 0s 55us/sample - loss: 1.5127 - mae: 0.9881 - mse: 1.5127 - val_loss: 1.4743 - val_mae: 0.9851 - val_mse: 1.4743\n",
      "Epoch 93/1000\n",
      "9021/9021 [==============================] - 0s 44us/sample - loss: 1.5163 - mae: 0.9901 - mse: 1.5163 - val_loss: 1.4949 - val_mae: 0.9777 - val_mse: 1.4949\n",
      "Epoch 94/1000\n",
      "9021/9021 [==============================] - 1s 82us/sample - loss: 1.5123 - mae: 0.9878 - mse: 1.5123 - val_loss: 1.4800 - val_mae: 0.9812 - val_mse: 1.4800\n",
      "Epoch 95/1000\n",
      "9021/9021 [==============================] - 0s 54us/sample - loss: 1.5127 - mae: 0.9881 - mse: 1.5127 - val_loss: 1.4842 - val_mae: 0.9885 - val_mse: 1.4842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/1000\n",
      "9021/9021 [==============================] - 0s 37us/sample - loss: 1.5114 - mae: 0.9882 - mse: 1.5114 - val_loss: 1.4788 - val_mae: 0.9834 - val_mse: 1.4788\n",
      "Epoch 97/1000\n",
      "9021/9021 [==============================] - 0s 39us/sample - loss: 1.5112 - mae: 0.9883 - mse: 1.5112 - val_loss: 1.4780 - val_mae: 0.9869 - val_mse: 1.4780\n",
      "Epoch 98/1000\n",
      "9021/9021 [==============================] - 0s 43us/sample - loss: 1.5125 - mae: 0.9893 - mse: 1.5125 - val_loss: 1.4789 - val_mae: 0.9824 - val_mse: 1.4789\n",
      "Epoch 99/1000\n",
      "9021/9021 [==============================] - 0s 31us/sample - loss: 1.5119 - mae: 0.9884 - mse: 1.5119 - val_loss: 1.4868 - val_mae: 0.9791 - val_mse: 1.4868\n",
      "Epoch 100/1000\n",
      "9021/9021 [==============================] - 0s 39us/sample - loss: 1.5104 - mae: 0.9861 - mse: 1.5104 - val_loss: 1.4959 - val_mae: 0.9969 - val_mse: 1.4959\n",
      "Epoch 101/1000\n",
      "9021/9021 [==============================] - 1s 65us/sample - loss: 1.5105 - mae: 0.9879 - mse: 1.5105 - val_loss: 1.4836 - val_mae: 0.9814 - val_mse: 1.4836\n",
      "Epoch 102/1000\n",
      "9021/9021 [==============================] - 0s 34us/sample - loss: 1.5134 - mae: 0.9882 - mse: 1.5134 - val_loss: 1.4798 - val_mae: 0.9845 - val_mse: 1.4798\n",
      "Epoch 103/1000\n",
      "9021/9021 [==============================] - 0s 42us/sample - loss: 1.5093 - mae: 0.9871 - mse: 1.5093 - val_loss: 1.4881 - val_mae: 0.9935 - val_mse: 1.4881\n",
      "Epoch 104/1000\n",
      "9021/9021 [==============================] - 0s 42us/sample - loss: 1.5107 - mae: 0.9888 - mse: 1.5107 - val_loss: 1.4798 - val_mae: 0.9796 - val_mse: 1.4798\n",
      "Epoch 105/1000\n",
      "9021/9021 [==============================] - 0s 43us/sample - loss: 1.5079 - mae: 0.9861 - mse: 1.5079 - val_loss: 1.4818 - val_mae: 0.9854 - val_mse: 1.4818\n",
      "Epoch 106/1000\n",
      "9021/9021 [==============================] - 0s 42us/sample - loss: 1.5078 - mae: 0.9873 - mse: 1.5078 - val_loss: 1.5004 - val_mae: 0.9793 - val_mse: 1.5004\n",
      "Epoch 107/1000\n",
      "9021/9021 [==============================] - 0s 36us/sample - loss: 1.5104 - mae: 0.9873 - mse: 1.5104 - val_loss: 1.4956 - val_mae: 0.9793 - val_mse: 1.4956\n",
      "Epoch 108/1000\n",
      "9021/9021 [==============================] - 0s 43us/sample - loss: 1.5084 - mae: 0.9857 - mse: 1.5084 - val_loss: 1.4842 - val_mae: 0.9863 - val_mse: 1.4842\n",
      "Epoch 109/1000\n",
      "9021/9021 [==============================] - 1s 62us/sample - loss: 1.5095 - mae: 0.9878 - mse: 1.5095 - val_loss: 1.4849 - val_mae: 0.9766 - val_mse: 1.4849\n",
      "Epoch 110/1000\n",
      "9021/9021 [==============================] - 0s 40us/sample - loss: 1.5122 - mae: 0.9880 - mse: 1.5122 - val_loss: 1.4829 - val_mae: 0.9860 - val_mse: 1.4829\n",
      "Epoch 111/1000\n",
      "9021/9021 [==============================] - 0s 48us/sample - loss: 1.5087 - mae: 0.9872 - mse: 1.5087 - val_loss: 1.5003 - val_mae: 0.9771 - val_mse: 1.5003\n",
      "Epoch 112/1000\n",
      "9021/9021 [==============================] - 0s 41us/sample - loss: 1.5075 - mae: 0.9854 - mse: 1.5075 - val_loss: 1.4803 - val_mae: 0.9833 - val_mse: 1.4803\n",
      "Epoch 113/1000\n",
      "9021/9021 [==============================] - 0s 44us/sample - loss: 1.5085 - mae: 0.9876 - mse: 1.5085 - val_loss: 1.5275 - val_mae: 0.9751 - val_mse: 1.5275\n",
      "Epoch 114/1000\n",
      "9021/9021 [==============================] - 0s 34us/sample - loss: 1.5086 - mae: 0.9862 - mse: 1.5086 - val_loss: 1.4833 - val_mae: 0.9803 - val_mse: 1.4833\n",
      "Epoch 115/1000\n",
      "9021/9021 [==============================] - 0s 33us/sample - loss: 1.5075 - mae: 0.9860 - mse: 1.5075 - val_loss: 1.4759 - val_mae: 0.9827 - val_mse: 1.4759\n",
      "Epoch 116/1000\n",
      "9021/9021 [==============================] - 0s 44us/sample - loss: 1.5084 - mae: 0.9859 - mse: 1.5084 - val_loss: 1.4790 - val_mae: 0.9860 - val_mse: 1.4790\n",
      "Epoch 117/1000\n",
      "9021/9021 [==============================] - 0s 49us/sample - loss: 1.5051 - mae: 0.9858 - mse: 1.5051 - val_loss: 1.4801 - val_mae: 0.9839 - val_mse: 1.4801\n",
      "Epoch 118/1000\n",
      "9021/9021 [==============================] - 0s 42us/sample - loss: 1.5095 - mae: 0.9855 - mse: 1.5095 - val_loss: 1.5342 - val_mae: 1.0089 - val_mse: 1.5342\n",
      "Epoch 119/1000\n",
      "9021/9021 [==============================] - 0s 40us/sample - loss: 1.5071 - mae: 0.9858 - mse: 1.5071 - val_loss: 1.4931 - val_mae: 0.9759 - val_mse: 1.4931\n",
      "Epoch 120/1000\n",
      "9021/9021 [==============================] - 0s 48us/sample - loss: 1.5038 - mae: 0.9846 - mse: 1.5038 - val_loss: 1.4895 - val_mae: 0.9762 - val_mse: 1.4895\n",
      "Epoch 121/1000\n",
      "9021/9021 [==============================] - 0s 54us/sample - loss: 1.5080 - mae: 0.9871 - mse: 1.5080 - val_loss: 1.4780 - val_mae: 0.9828 - val_mse: 1.4780\n",
      "Epoch 122/1000\n",
      "9021/9021 [==============================] - 0s 49us/sample - loss: 1.5038 - mae: 0.9862 - mse: 1.5038 - val_loss: 1.4948 - val_mae: 0.9780 - val_mse: 1.4948\n",
      "Epoch 123/1000\n",
      "9021/9021 [==============================] - 1s 60us/sample - loss: 1.5077 - mae: 0.9863 - mse: 1.5077 - val_loss: 1.4833 - val_mae: 0.9822 - val_mse: 1.4833\n",
      "Epoch 124/1000\n",
      "9021/9021 [==============================] - 1s 57us/sample - loss: 1.5077 - mae: 0.9863 - mse: 1.5077 - val_loss: 1.5039 - val_mae: 0.9799 - val_mse: 1.5039\n",
      "Epoch 125/1000\n",
      "9021/9021 [==============================] - 1s 63us/sample - loss: 1.5043 - mae: 0.9848 - mse: 1.5043 - val_loss: 1.5009 - val_mae: 0.9772 - val_mse: 1.5009\n",
      "Epoch 126/1000\n",
      "9021/9021 [==============================] - 0s 53us/sample - loss: 1.5048 - mae: 0.9863 - mse: 1.5048 - val_loss: 1.4880 - val_mae: 0.9787 - val_mse: 1.4880\n",
      "Epoch 127/1000\n",
      "9021/9021 [==============================] - 1s 56us/sample - loss: 1.5049 - mae: 0.9860 - mse: 1.5049 - val_loss: 1.4846 - val_mae: 0.9892 - val_mse: 1.4846\n",
      "Epoch 128/1000\n",
      "9021/9021 [==============================] - 0s 48us/sample - loss: 1.5049 - mae: 0.9854 - mse: 1.5049 - val_loss: 1.4810 - val_mae: 0.9863 - val_mse: 1.4810\n",
      "Epoch 129/1000\n",
      "9021/9021 [==============================] - 0s 50us/sample - loss: 1.5080 - mae: 0.9862 - mse: 1.5080 - val_loss: 1.4849 - val_mae: 0.9851 - val_mse: 1.4849\n",
      "Epoch 130/1000\n",
      "9021/9021 [==============================] - 0s 51us/sample - loss: 1.5054 - mae: 0.9854 - mse: 1.5054 - val_loss: 1.5015 - val_mae: 0.9763 - val_mse: 1.5015\n",
      "Epoch 131/1000\n",
      "9021/9021 [==============================] - 0s 46us/sample - loss: 1.5055 - mae: 0.9844 - mse: 1.5055 - val_loss: 1.5056 - val_mae: 0.9989 - val_mse: 1.5056\n",
      "Epoch 132/1000\n",
      "9021/9021 [==============================] - 1s 71us/sample - loss: 1.5049 - mae: 0.9851 - mse: 1.5049 - val_loss: 1.4845 - val_mae: 0.9784 - val_mse: 1.4845\n",
      "Epoch 133/1000\n",
      "9021/9021 [==============================] - 0s 29us/sample - loss: 1.5030 - mae: 0.9843 - mse: 1.5030 - val_loss: 1.4809 - val_mae: 0.9850 - val_mse: 1.4809\n",
      "Epoch 134/1000\n",
      "9021/9021 [==============================] - 0s 38us/sample - loss: 1.5035 - mae: 0.9833 - mse: 1.5035 - val_loss: 1.4946 - val_mae: 0.9791 - val_mse: 1.4946\n",
      "Epoch 135/1000\n",
      "9021/9021 [==============================] - 0s 55us/sample - loss: 1.5046 - mae: 0.9853 - mse: 1.5046 - val_loss: 1.4833 - val_mae: 0.9855 - val_mse: 1.4833\n",
      "Epoch 136/1000\n",
      "9021/9021 [==============================] - 0s 30us/sample - loss: 1.5043 - mae: 0.9856 - mse: 1.5043 - val_loss: 1.5130 - val_mae: 0.9793 - val_mse: 1.5130\n",
      "Epoch 137/1000\n",
      "9021/9021 [==============================] - 0s 24us/sample - loss: 1.5020 - mae: 0.9831 - mse: 1.5020 - val_loss: 1.4847 - val_mae: 0.9867 - val_mse: 1.4847\n",
      "Epoch 138/1000\n",
      "9021/9021 [==============================] - 0s 35us/sample - loss: 1.5070 - mae: 0.9859 - mse: 1.5070 - val_loss: 1.4835 - val_mae: 0.9869 - val_mse: 1.4835\n",
      "Epoch 139/1000\n",
      "9021/9021 [==============================] - 0s 34us/sample - loss: 1.5044 - mae: 0.9846 - mse: 1.5044 - val_loss: 1.4896 - val_mae: 0.9794 - val_mse: 1.4896\n",
      "Epoch 140/1000\n",
      "9021/9021 [==============================] - 0s 31us/sample - loss: 1.5055 - mae: 0.9853 - mse: 1.5055 - val_loss: 1.4933 - val_mae: 0.9799 - val_mse: 1.4933\n",
      "Epoch 141/1000\n",
      "9021/9021 [==============================] - 0s 25us/sample - loss: 1.5049 - mae: 0.9845 - mse: 1.5049 - val_loss: 1.4837 - val_mae: 0.9765 - val_mse: 1.4837\n",
      "Epoch 142/1000\n",
      "9021/9021 [==============================] - 0s 27us/sample - loss: 1.5044 - mae: 0.9845 - mse: 1.5044 - val_loss: 1.4874 - val_mae: 0.9890 - val_mse: 1.4874\n",
      "Epoch 143/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9021/9021 [==============================] - 0s 27us/sample - loss: 1.5029 - mae: 0.9851 - mse: 1.5029 - val_loss: 1.4924 - val_mae: 0.9915 - val_mse: 1.4924\n",
      "Epoch 144/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.5020 - mae: 0.9839 - mse: 1.5020 - val_loss: 1.4864 - val_mae: 0.9827 - val_mse: 1.4864\n",
      "Epoch 145/1000\n",
      "9021/9021 [==============================] - 0s 25us/sample - loss: 1.5024 - mae: 0.9833 - mse: 1.5024 - val_loss: 1.4932 - val_mae: 0.9815 - val_mse: 1.4932\n",
      "Epoch 146/1000\n",
      "9021/9021 [==============================] - 0s 25us/sample - loss: 1.5016 - mae: 0.9838 - mse: 1.5016 - val_loss: 1.4969 - val_mae: 0.9821 - val_mse: 1.4969\n",
      "Epoch 147/1000\n",
      "9021/9021 [==============================] - 0s 25us/sample - loss: 1.5015 - mae: 0.9832 - mse: 1.5015 - val_loss: 1.4983 - val_mae: 0.9784 - val_mse: 1.4983\n",
      "Epoch 148/1000\n",
      "9021/9021 [==============================] - 0s 24us/sample - loss: 1.5024 - mae: 0.9834 - mse: 1.5024 - val_loss: 1.4914 - val_mae: 0.9884 - val_mse: 1.4914\n",
      "Epoch 149/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.5017 - mae: 0.9846 - mse: 1.5017 - val_loss: 1.5161 - val_mae: 0.9762 - val_mse: 1.5161\n",
      "Epoch 150/1000\n",
      "9021/9021 [==============================] - 0s 25us/sample - loss: 1.5016 - mae: 0.9835 - mse: 1.5016 - val_loss: 1.5301 - val_mae: 0.9758 - val_mse: 1.5301\n",
      "Epoch 151/1000\n",
      "9021/9021 [==============================] - 0s 25us/sample - loss: 1.5023 - mae: 0.9819 - mse: 1.5023 - val_loss: 1.4956 - val_mae: 0.9870 - val_mse: 1.4956\n",
      "Epoch 152/1000\n",
      "9021/9021 [==============================] - 0s 25us/sample - loss: 1.4998 - mae: 0.9834 - mse: 1.4998 - val_loss: 1.5061 - val_mae: 0.9789 - val_mse: 1.5061\n",
      "Epoch 153/1000\n",
      "9021/9021 [==============================] - 0s 37us/sample - loss: 1.5019 - mae: 0.9832 - mse: 1.5019 - val_loss: 1.4825 - val_mae: 0.9810 - val_mse: 1.4825\n",
      "Epoch 154/1000\n",
      "9021/9021 [==============================] - 0s 31us/sample - loss: 1.5009 - mae: 0.9825 - mse: 1.5009 - val_loss: 1.5121 - val_mae: 0.9780 - val_mse: 1.5121\n",
      "Epoch 155/1000\n",
      "9021/9021 [==============================] - 0s 29us/sample - loss: 1.5023 - mae: 0.9839 - mse: 1.5023 - val_loss: 1.4825 - val_mae: 0.9837 - val_mse: 1.4825\n",
      "Epoch 156/1000\n",
      "9021/9021 [==============================] - 0s 25us/sample - loss: 1.5032 - mae: 0.9853 - mse: 1.5032 - val_loss: 1.4898 - val_mae: 0.9928 - val_mse: 1.4898\n",
      "Epoch 157/1000\n",
      "9021/9021 [==============================] - 0s 33us/sample - loss: 1.5008 - mae: 0.9839 - mse: 1.5008 - val_loss: 1.4974 - val_mae: 0.9776 - val_mse: 1.4974\n",
      "Epoch 158/1000\n",
      "9021/9021 [==============================] - 0s 37us/sample - loss: 1.5037 - mae: 0.9854 - mse: 1.5037 - val_loss: 1.4934 - val_mae: 0.9769 - val_mse: 1.4934\n",
      "Epoch 159/1000\n",
      "9021/9021 [==============================] - 0s 40us/sample - loss: 1.5007 - mae: 0.9839 - mse: 1.5007 - val_loss: 1.4882 - val_mae: 0.9793 - val_mse: 1.4882\n",
      "Epoch 160/1000\n",
      "9021/9021 [==============================] - 0s 40us/sample - loss: 1.4961 - mae: 0.9822 - mse: 1.4961 - val_loss: 1.4766 - val_mae: 0.9825 - val_mse: 1.4766\n",
      "Epoch 161/1000\n",
      "9021/9021 [==============================] - 0s 41us/sample - loss: 1.5014 - mae: 0.9830 - mse: 1.5014 - val_loss: 1.5116 - val_mae: 1.0025 - val_mse: 1.5116\n",
      "Epoch 162/1000\n",
      "9021/9021 [==============================] - 0s 46us/sample - loss: 1.4995 - mae: 0.9843 - mse: 1.4995 - val_loss: 1.5238 - val_mae: 0.9765 - val_mse: 1.5238\n",
      "Epoch 163/1000\n",
      "9021/9021 [==============================] - 0s 43us/sample - loss: 1.4998 - mae: 0.9824 - mse: 1.4998 - val_loss: 1.5061 - val_mae: 0.9961 - val_mse: 1.5061\n",
      "Epoch 164/1000\n",
      "9021/9021 [==============================] - 1s 56us/sample - loss: 1.4989 - mae: 0.9827 - mse: 1.4989 - val_loss: 1.4812 - val_mae: 0.9828 - val_mse: 1.4812\n",
      "Epoch 165/1000\n",
      "9021/9021 [==============================] - 0s 41us/sample - loss: 1.5002 - mae: 0.9838 - mse: 1.5002 - val_loss: 1.4856 - val_mae: 0.9808 - val_mse: 1.4856\n",
      "Epoch 166/1000\n",
      "9021/9021 [==============================] - 0s 39us/sample - loss: 1.4994 - mae: 0.9829 - mse: 1.4994 - val_loss: 1.4875 - val_mae: 0.9814 - val_mse: 1.4875\n",
      "Epoch 167/1000\n",
      "9021/9021 [==============================] - 0s 55us/sample - loss: 1.5002 - mae: 0.9835 - mse: 1.5002 - val_loss: 1.4996 - val_mae: 0.9800 - val_mse: 1.4996\n",
      "Epoch 168/1000\n",
      "9021/9021 [==============================] - 1s 62us/sample - loss: 1.5023 - mae: 0.9843 - mse: 1.5023 - val_loss: 1.4872 - val_mae: 0.9817 - val_mse: 1.4872\n",
      "Epoch 169/1000\n",
      "9021/9021 [==============================] - 0s 49us/sample - loss: 1.5004 - mae: 0.9829 - mse: 1.5004 - val_loss: 1.4854 - val_mae: 0.9856 - val_mse: 1.4854\n",
      "Epoch 170/1000\n",
      "9021/9021 [==============================] - 0s 51us/sample - loss: 1.4987 - mae: 0.9832 - mse: 1.4987 - val_loss: 1.4843 - val_mae: 0.9817 - val_mse: 1.4843\n",
      "Epoch 171/1000\n",
      "9021/9021 [==============================] - 1s 73us/sample - loss: 1.4984 - mae: 0.9832 - mse: 1.4984 - val_loss: 1.4866 - val_mae: 0.9868 - val_mse: 1.4866\n",
      "Epoch 172/1000\n",
      "9021/9021 [==============================] - 0s 41us/sample - loss: 1.4985 - mae: 0.9827 - mse: 1.4985 - val_loss: 1.5189 - val_mae: 0.9748 - val_mse: 1.5189\n",
      "Epoch 173/1000\n",
      "9021/9021 [==============================] - 0s 50us/sample - loss: 1.4988 - mae: 0.9823 - mse: 1.4988 - val_loss: 1.5141 - val_mae: 1.0034 - val_mse: 1.5141\n",
      "Epoch 174/1000\n",
      "9021/9021 [==============================] - 0s 46us/sample - loss: 1.4963 - mae: 0.9817 - mse: 1.4963 - val_loss: 1.4940 - val_mae: 0.9776 - val_mse: 1.4940\n",
      "Epoch 175/1000\n",
      "9021/9021 [==============================] - 0s 49us/sample - loss: 1.4998 - mae: 0.9832 - mse: 1.4998 - val_loss: 1.4882 - val_mae: 0.9803 - val_mse: 1.4882\n",
      "Epoch 176/1000\n",
      "9021/9021 [==============================] - 0s 49us/sample - loss: 1.4965 - mae: 0.9819 - mse: 1.4965 - val_loss: 1.4918 - val_mae: 0.9897 - val_mse: 1.4918\n",
      "Epoch 177/1000\n",
      "9021/9021 [==============================] - 0s 43us/sample - loss: 1.4982 - mae: 0.9816 - mse: 1.4982 - val_loss: 1.4946 - val_mae: 0.9906 - val_mse: 1.4946\n",
      "Epoch 178/1000\n",
      "9021/9021 [==============================] - 0s 29us/sample - loss: 1.4977 - mae: 0.9836 - mse: 1.4977 - val_loss: 1.4927 - val_mae: 0.9900 - val_mse: 1.4927\n",
      "Epoch 179/1000\n",
      "9021/9021 [==============================] - 0s 46us/sample - loss: 1.4985 - mae: 0.9819 - mse: 1.4985 - val_loss: 1.4892 - val_mae: 0.9817 - val_mse: 1.4892\n",
      "Epoch 180/1000\n",
      "9021/9021 [==============================] - 0s 42us/sample - loss: 1.4995 - mae: 0.9829 - mse: 1.4995 - val_loss: 1.5087 - val_mae: 0.9776 - val_mse: 1.5087\n",
      "Epoch 181/1000\n",
      "9021/9021 [==============================] - 0s 51us/sample - loss: 1.4958 - mae: 0.9815 - mse: 1.4958 - val_loss: 1.5025 - val_mae: 0.9807 - val_mse: 1.5025\n",
      "Epoch 182/1000\n",
      "9021/9021 [==============================] - 0s 39us/sample - loss: 1.4983 - mae: 0.9824 - mse: 1.4983 - val_loss: 1.4948 - val_mae: 0.9823 - val_mse: 1.4948\n",
      "Epoch 183/1000\n",
      "9021/9021 [==============================] - 0s 51us/sample - loss: 1.4985 - mae: 0.9819 - mse: 1.4985 - val_loss: 1.4872 - val_mae: 0.9792 - val_mse: 1.4872\n",
      "Epoch 184/1000\n",
      "9021/9021 [==============================] - 0s 38us/sample - loss: 1.4983 - mae: 0.9817 - mse: 1.4983 - val_loss: 1.4944 - val_mae: 0.9819 - val_mse: 1.4944\n",
      "Epoch 185/1000\n",
      "9021/9021 [==============================] - 0s 42us/sample - loss: 1.4992 - mae: 0.9834 - mse: 1.4992 - val_loss: 1.4957 - val_mae: 0.9756 - val_mse: 1.4957\n",
      "Epoch 186/1000\n",
      "9021/9021 [==============================] - 0s 35us/sample - loss: 1.4973 - mae: 0.9815 - mse: 1.4973 - val_loss: 1.4980 - val_mae: 0.9779 - val_mse: 1.4980\n",
      "Epoch 187/1000\n",
      "9021/9021 [==============================] - 0s 37us/sample - loss: 1.4953 - mae: 0.9805 - mse: 1.4953 - val_loss: 1.4882 - val_mae: 0.9833 - val_mse: 1.4882\n",
      "Epoch 188/1000\n",
      "9021/9021 [==============================] - 0s 36us/sample - loss: 1.4975 - mae: 0.9823 - mse: 1.4975 - val_loss: 1.4776 - val_mae: 0.9781 - val_mse: 1.4776\n",
      "Epoch 189/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.4984 - mae: 0.9825 - mse: 1.4984 - val_loss: 1.5112 - val_mae: 0.9744 - val_mse: 1.5112\n",
      "Epoch 190/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9021/9021 [==============================] - 0s 25us/sample - loss: 1.4974 - mae: 0.9809 - mse: 1.4974 - val_loss: 1.5060 - val_mae: 0.9988 - val_mse: 1.5060\n",
      "Epoch 191/1000\n",
      "9021/9021 [==============================] - 0s 33us/sample - loss: 1.4980 - mae: 0.9824 - mse: 1.4980 - val_loss: 1.4834 - val_mae: 0.9792 - val_mse: 1.4834\n",
      "Epoch 192/1000\n",
      "9021/9021 [==============================] - 0s 41us/sample - loss: 1.4963 - mae: 0.9816 - mse: 1.4963 - val_loss: 1.4857 - val_mae: 0.9823 - val_mse: 1.4858\n",
      "Epoch 193/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.4967 - mae: 0.9817 - mse: 1.4967 - val_loss: 1.5119 - val_mae: 1.0001 - val_mse: 1.5119\n",
      "Epoch 194/1000\n",
      "9021/9021 [==============================] - 0s 31us/sample - loss: 1.4998 - mae: 0.9836 - mse: 1.4998 - val_loss: 1.4893 - val_mae: 0.9872 - val_mse: 1.4893\n",
      "Epoch 195/1000\n",
      "9021/9021 [==============================] - 0s 29us/sample - loss: 1.4953 - mae: 0.9817 - mse: 1.4953 - val_loss: 1.4856 - val_mae: 0.9836 - val_mse: 1.4856\n",
      "Epoch 196/1000\n",
      "9021/9021 [==============================] - 0s 25us/sample - loss: 1.4945 - mae: 0.9803 - mse: 1.4945 - val_loss: 1.5013 - val_mae: 0.9782 - val_mse: 1.5013\n",
      "Epoch 197/1000\n",
      "9021/9021 [==============================] - 0s 28us/sample - loss: 1.4959 - mae: 0.9809 - mse: 1.4959 - val_loss: 1.5000 - val_mae: 0.9900 - val_mse: 1.5000\n",
      "Epoch 198/1000\n",
      "9021/9021 [==============================] - 0s 33us/sample - loss: 1.4977 - mae: 0.9819 - mse: 1.4977 - val_loss: 1.4835 - val_mae: 0.9840 - val_mse: 1.4835\n",
      "Epoch 199/1000\n",
      "9021/9021 [==============================] - 0s 27us/sample - loss: 1.4960 - mae: 0.9801 - mse: 1.4960 - val_loss: 1.4928 - val_mae: 0.9932 - val_mse: 1.4928\n",
      "Epoch 200/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.4957 - mae: 0.9825 - mse: 1.4957 - val_loss: 1.5202 - val_mae: 0.9743 - val_mse: 1.5202\n",
      "Epoch 201/1000\n",
      "9021/9021 [==============================] - 0s 27us/sample - loss: 1.4974 - mae: 0.9809 - mse: 1.4974 - val_loss: 1.4851 - val_mae: 0.9831 - val_mse: 1.4851\n",
      "Epoch 202/1000\n",
      "9021/9021 [==============================] - 0s 27us/sample - loss: 1.4962 - mae: 0.9818 - mse: 1.4962 - val_loss: 1.4986 - val_mae: 0.9774 - val_mse: 1.4986\n",
      "Epoch 203/1000\n",
      "9021/9021 [==============================] - 0s 25us/sample - loss: 1.4961 - mae: 0.9817 - mse: 1.4961 - val_loss: 1.4852 - val_mae: 0.9796 - val_mse: 1.4852\n",
      "Epoch 204/1000\n",
      "9021/9021 [==============================] - 0s 33us/sample - loss: 1.4958 - mae: 0.9803 - mse: 1.4958 - val_loss: 1.4984 - val_mae: 0.9890 - val_mse: 1.4984\n",
      "Epoch 205/1000\n",
      "9021/9021 [==============================] - 0s 39us/sample - loss: 1.4953 - mae: 0.9816 - mse: 1.4953 - val_loss: 1.4992 - val_mae: 0.9770 - val_mse: 1.4992\n",
      "Epoch 206/1000\n",
      "9021/9021 [==============================] - 0s 34us/sample - loss: 1.4974 - mae: 0.9829 - mse: 1.4974 - val_loss: 1.4936 - val_mae: 0.9786 - val_mse: 1.4936\n",
      "Epoch 207/1000\n",
      "9021/9021 [==============================] - 0s 27us/sample - loss: 1.4952 - mae: 0.9806 - mse: 1.4952 - val_loss: 1.5074 - val_mae: 0.9940 - val_mse: 1.5074\n",
      "Epoch 208/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.4961 - mae: 0.9831 - mse: 1.4961 - val_loss: 1.5129 - val_mae: 0.9799 - val_mse: 1.5129\n",
      "Epoch 209/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.4949 - mae: 0.9805 - mse: 1.4949 - val_loss: 1.4934 - val_mae: 0.9882 - val_mse: 1.4934\n",
      "Epoch 210/1000\n",
      "9021/9021 [==============================] - 0s 27us/sample - loss: 1.4956 - mae: 0.9809 - mse: 1.4956 - val_loss: 1.5053 - val_mae: 0.9768 - val_mse: 1.5053\n",
      "Epoch 211/1000\n",
      "9021/9021 [==============================] - 0s 27us/sample - loss: 1.4945 - mae: 0.9802 - mse: 1.4945 - val_loss: 1.4865 - val_mae: 0.9834 - val_mse: 1.4865\n",
      "Epoch 212/1000\n",
      "9021/9021 [==============================] - 0s 28us/sample - loss: 1.4934 - mae: 0.9812 - mse: 1.4934 - val_loss: 1.4935 - val_mae: 0.9880 - val_mse: 1.4935\n",
      "Epoch 213/1000\n",
      "9021/9021 [==============================] - 0s 31us/sample - loss: 1.4956 - mae: 0.9826 - mse: 1.4956 - val_loss: 1.5122 - val_mae: 0.9773 - val_mse: 1.5122\n",
      "Epoch 214/1000\n",
      "9021/9021 [==============================] - 0s 31us/sample - loss: 1.4939 - mae: 0.9804 - mse: 1.4939 - val_loss: 1.4970 - val_mae: 0.9854 - val_mse: 1.4970\n",
      "Epoch 215/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.4945 - mae: 0.9801 - mse: 1.4945 - val_loss: 1.5066 - val_mae: 0.9983 - val_mse: 1.5066\n",
      "Epoch 216/1000\n",
      "9021/9021 [==============================] - 0s 27us/sample - loss: 1.4939 - mae: 0.9807 - mse: 1.4939 - val_loss: 1.4890 - val_mae: 0.9897 - val_mse: 1.4890\n",
      "Epoch 217/1000\n",
      "9021/9021 [==============================] - 0s 28us/sample - loss: 1.4954 - mae: 0.9809 - mse: 1.4954 - val_loss: 1.4857 - val_mae: 0.9834 - val_mse: 1.4857\n",
      "Epoch 218/1000\n",
      "9021/9021 [==============================] - 0s 40us/sample - loss: 1.4945 - mae: 0.9814 - mse: 1.4945 - val_loss: 1.5018 - val_mae: 0.9784 - val_mse: 1.5018\n",
      "Epoch 219/1000\n",
      "9021/9021 [==============================] - 0s 39us/sample - loss: 1.4929 - mae: 0.9804 - mse: 1.4929 - val_loss: 1.4952 - val_mae: 0.9836 - val_mse: 1.4952\n",
      "Epoch 220/1000\n",
      "9021/9021 [==============================] - 0s 28us/sample - loss: 1.4931 - mae: 0.9806 - mse: 1.4931 - val_loss: 1.5039 - val_mae: 0.9948 - val_mse: 1.5039\n",
      "Epoch 221/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.4962 - mae: 0.9821 - mse: 1.4962 - val_loss: 1.4917 - val_mae: 0.9775 - val_mse: 1.4917\n",
      "Epoch 222/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.4938 - mae: 0.9803 - mse: 1.4938 - val_loss: 1.4978 - val_mae: 0.9907 - val_mse: 1.4978\n",
      "Epoch 223/1000\n",
      "9021/9021 [==============================] - 0s 24us/sample - loss: 1.4951 - mae: 0.9822 - mse: 1.4951 - val_loss: 1.4952 - val_mae: 0.9831 - val_mse: 1.4952\n",
      "Epoch 224/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.4926 - mae: 0.9804 - mse: 1.4926 - val_loss: 1.4896 - val_mae: 0.9793 - val_mse: 1.4896\n",
      "Epoch 225/1000\n",
      "9021/9021 [==============================] - 0s 27us/sample - loss: 1.4955 - mae: 0.9820 - mse: 1.4955 - val_loss: 1.4879 - val_mae: 0.9833 - val_mse: 1.4879\n",
      "Epoch 226/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.4927 - mae: 0.9794 - mse: 1.4927 - val_loss: 1.5006 - val_mae: 0.9894 - val_mse: 1.5006\n",
      "Epoch 227/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.4924 - mae: 0.9794 - mse: 1.4924 - val_loss: 1.4879 - val_mae: 0.9793 - val_mse: 1.4879\n",
      "Epoch 228/1000\n",
      "9021/9021 [==============================] - 0s 28us/sample - loss: 1.4935 - mae: 0.9807 - mse: 1.4935 - val_loss: 1.5110 - val_mae: 0.9963 - val_mse: 1.5110\n",
      "Epoch 229/1000\n",
      "9021/9021 [==============================] - 0s 28us/sample - loss: 1.4937 - mae: 0.9812 - mse: 1.4937 - val_loss: 1.4917 - val_mae: 0.9782 - val_mse: 1.4917\n",
      "Epoch 230/1000\n",
      "9021/9021 [==============================] - 0s 36us/sample - loss: 1.4936 - mae: 0.9793 - mse: 1.4936 - val_loss: 1.4904 - val_mae: 0.9871 - val_mse: 1.4904\n",
      "Epoch 231/1000\n",
      "9021/9021 [==============================] - 0s 54us/sample - loss: 1.4911 - mae: 0.9799 - mse: 1.4911 - val_loss: 1.5028 - val_mae: 0.9954 - val_mse: 1.5028\n",
      "Epoch 232/1000\n",
      "9021/9021 [==============================] - 0s 42us/sample - loss: 1.4945 - mae: 0.9809 - mse: 1.4945 - val_loss: 1.4913 - val_mae: 0.9873 - val_mse: 1.4913\n",
      "Epoch 233/1000\n",
      "9021/9021 [==============================] - 0s 40us/sample - loss: 1.4941 - mae: 0.9810 - mse: 1.4941 - val_loss: 1.4926 - val_mae: 0.9903 - val_mse: 1.4926\n",
      "Epoch 234/1000\n",
      "9021/9021 [==============================] - 0s 28us/sample - loss: 1.4952 - mae: 0.9815 - mse: 1.4952 - val_loss: 1.4952 - val_mae: 0.9790 - val_mse: 1.4952\n",
      "Epoch 235/1000\n",
      "9021/9021 [==============================] - 0s 27us/sample - loss: 1.4935 - mae: 0.9797 - mse: 1.4935 - val_loss: 1.4890 - val_mae: 0.9793 - val_mse: 1.4890\n",
      "Epoch 236/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.4906 - mae: 0.9800 - mse: 1.4906 - val_loss: 1.4978 - val_mae: 0.9779 - val_mse: 1.4978\n",
      "Epoch 237/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9021/9021 [==============================] - 0s 25us/sample - loss: 1.4945 - mae: 0.9814 - mse: 1.4945 - val_loss: 1.4974 - val_mae: 0.9789 - val_mse: 1.4974\n",
      "Epoch 238/1000\n",
      "9021/9021 [==============================] - 0s 41us/sample - loss: 1.4917 - mae: 0.9779 - mse: 1.4917 - val_loss: 1.4929 - val_mae: 0.9912 - val_mse: 1.4929\n",
      "Epoch 239/1000\n",
      "9021/9021 [==============================] - 0s 45us/sample - loss: 1.4913 - mae: 0.9810 - mse: 1.4913 - val_loss: 1.4894 - val_mae: 0.9814 - val_mse: 1.4894\n",
      "Epoch 240/1000\n",
      "9021/9021 [==============================] - 0s 28us/sample - loss: 1.4951 - mae: 0.9804 - mse: 1.4951 - val_loss: 1.4842 - val_mae: 0.9816 - val_mse: 1.4842\n",
      "Epoch 241/1000\n",
      "9021/9021 [==============================] - 0s 33us/sample - loss: 1.4917 - mae: 0.9796 - mse: 1.4917 - val_loss: 1.4923 - val_mae: 0.9840 - val_mse: 1.4923\n",
      "Epoch 242/1000\n",
      "9021/9021 [==============================] - 0s 36us/sample - loss: 1.4911 - mae: 0.9793 - mse: 1.4911 - val_loss: 1.4993 - val_mae: 0.9765 - val_mse: 1.4993\n",
      "Epoch 243/1000\n",
      "9021/9021 [==============================] - 0s 36us/sample - loss: 1.4932 - mae: 0.9808 - mse: 1.4932 - val_loss: 1.4857 - val_mae: 0.9839 - val_mse: 1.4857\n",
      "Epoch 244/1000\n",
      "9021/9021 [==============================] - 0s 44us/sample - loss: 1.4892 - mae: 0.9790 - mse: 1.4892 - val_loss: 1.5385 - val_mae: 0.9763 - val_mse: 1.5385\n",
      "Epoch 245/1000\n",
      "9021/9021 [==============================] - 1s 63us/sample - loss: 1.4937 - mae: 0.9797 - mse: 1.4937 - val_loss: 1.5001 - val_mae: 0.9776 - val_mse: 1.5001\n",
      "Epoch 246/1000\n",
      "9021/9021 [==============================] - 0s 37us/sample - loss: 1.4918 - mae: 0.9786 - mse: 1.4918 - val_loss: 1.4903 - val_mae: 0.9799 - val_mse: 1.4903\n",
      "Epoch 247/1000\n",
      "9021/9021 [==============================] - 0s 52us/sample - loss: 1.4911 - mae: 0.9790 - mse: 1.4911 - val_loss: 1.5144 - val_mae: 1.0009 - val_mse: 1.5144\n",
      "Epoch 248/1000\n",
      "9021/9021 [==============================] - 0s 48us/sample - loss: 1.4921 - mae: 0.9790 - mse: 1.4921 - val_loss: 1.4844 - val_mae: 0.9856 - val_mse: 1.4844\n",
      "Epoch 249/1000\n",
      "9021/9021 [==============================] - 0s 44us/sample - loss: 1.4924 - mae: 0.9810 - mse: 1.4924 - val_loss: 1.4958 - val_mae: 0.9874 - val_mse: 1.4958\n",
      "Epoch 250/1000\n",
      "9021/9021 [==============================] - 0s 38us/sample - loss: 1.4927 - mae: 0.9793 - mse: 1.4927 - val_loss: 1.4887 - val_mae: 0.9808 - val_mse: 1.4887\n",
      "Epoch 251/1000\n",
      "9021/9021 [==============================] - 0s 53us/sample - loss: 1.4928 - mae: 0.9803 - mse: 1.4928 - val_loss: 1.4885 - val_mae: 0.9826 - val_mse: 1.4885\n",
      "Epoch 252/1000\n",
      "9021/9021 [==============================] - 0s 33us/sample - loss: 1.4890 - mae: 0.9786 - mse: 1.4890 - val_loss: 1.4921 - val_mae: 0.9807 - val_mse: 1.4921\n",
      "Epoch 253/1000\n",
      "9021/9021 [==============================] - 0s 28us/sample - loss: 1.4917 - mae: 0.9803 - mse: 1.4917 - val_loss: 1.4882 - val_mae: 0.9863 - val_mse: 1.4882\n",
      "Epoch 254/1000\n",
      "9021/9021 [==============================] - 0s 51us/sample - loss: 1.4920 - mae: 0.9806 - mse: 1.4920 - val_loss: 1.4972 - val_mae: 0.9867 - val_mse: 1.4972\n",
      "Epoch 255/1000\n",
      "9021/9021 [==============================] - 0s 35us/sample - loss: 1.4912 - mae: 0.9792 - mse: 1.4912 - val_loss: 1.5178 - val_mae: 1.0002 - val_mse: 1.5178\n",
      "Epoch 256/1000\n",
      "9021/9021 [==============================] - 0s 50us/sample - loss: 1.4937 - mae: 0.9810 - mse: 1.4937 - val_loss: 1.4996 - val_mae: 0.9791 - val_mse: 1.4996\n",
      "Epoch 257/1000\n",
      "9021/9021 [==============================] - 0s 40us/sample - loss: 1.4917 - mae: 0.9789 - mse: 1.4917 - val_loss: 1.4958 - val_mae: 0.9884 - val_mse: 1.4958\n",
      "Epoch 258/1000\n",
      "9021/9021 [==============================] - 0s 40us/sample - loss: 1.4908 - mae: 0.9784 - mse: 1.4908 - val_loss: 1.5000 - val_mae: 0.9806 - val_mse: 1.5000\n",
      "Epoch 259/1000\n",
      "9021/9021 [==============================] - 0s 45us/sample - loss: 1.4903 - mae: 0.9792 - mse: 1.4903 - val_loss: 1.5053 - val_mae: 0.9834 - val_mse: 1.5053\n",
      "Epoch 260/1000\n",
      "9021/9021 [==============================] - 0s 37us/sample - loss: 1.4885 - mae: 0.9780 - mse: 1.4885 - val_loss: 1.4921 - val_mae: 0.9800 - val_mse: 1.4921\n",
      "Epoch 261/1000\n",
      "9021/9021 [==============================] - 0s 40us/sample - loss: 1.4940 - mae: 0.9803 - mse: 1.4940 - val_loss: 1.5009 - val_mae: 0.9777 - val_mse: 1.5009\n",
      "Epoch 262/1000\n",
      "9021/9021 [==============================] - 0s 35us/sample - loss: 1.4895 - mae: 0.9791 - mse: 1.4895 - val_loss: 1.4901 - val_mae: 0.9823 - val_mse: 1.4901\n",
      "Epoch 263/1000\n",
      "9021/9021 [==============================] - 0s 25us/sample - loss: 1.4925 - mae: 0.9803 - mse: 1.4925 - val_loss: 1.4870 - val_mae: 0.9814 - val_mse: 1.4870\n",
      "Epoch 264/1000\n",
      "9021/9021 [==============================] - 0s 41us/sample - loss: 1.4902 - mae: 0.9787 - mse: 1.4902 - val_loss: 1.5026 - val_mae: 0.9925 - val_mse: 1.5026\n",
      "Epoch 265/1000\n",
      "9021/9021 [==============================] - 0s 35us/sample - loss: 1.4896 - mae: 0.9771 - mse: 1.4896 - val_loss: 1.5168 - val_mae: 1.0010 - val_mse: 1.5168\n",
      "Epoch 266/1000\n",
      "9021/9021 [==============================] - 0s 27us/sample - loss: 1.4915 - mae: 0.9809 - mse: 1.4915 - val_loss: 1.5015 - val_mae: 0.9780 - val_mse: 1.5015\n",
      "Epoch 267/1000\n",
      "9021/9021 [==============================] - 0s 37us/sample - loss: 1.4908 - mae: 0.9785 - mse: 1.4908 - val_loss: 1.5053 - val_mae: 0.9785 - val_mse: 1.5053\n",
      "Epoch 268/1000\n",
      "9021/9021 [==============================] - 0s 36us/sample - loss: 1.4950 - mae: 0.9798 - mse: 1.4950 - val_loss: 1.4949 - val_mae: 0.9838 - val_mse: 1.4949\n",
      "Epoch 269/1000\n",
      "9021/9021 [==============================] - 1s 59us/sample - loss: 1.4918 - mae: 0.9800 - mse: 1.4918 - val_loss: 1.4954 - val_mae: 0.9818 - val_mse: 1.4954\n",
      "Epoch 270/1000\n",
      "9021/9021 [==============================] - 0s 52us/sample - loss: 1.4904 - mae: 0.9791 - mse: 1.4904 - val_loss: 1.5256 - val_mae: 0.9776 - val_mse: 1.5256\n",
      "Epoch 271/1000\n",
      "9021/9021 [==============================] - 0s 50us/sample - loss: 1.4921 - mae: 0.9781 - mse: 1.4921 - val_loss: 1.4884 - val_mae: 0.9842 - val_mse: 1.4884\n",
      "Epoch 272/1000\n",
      "9021/9021 [==============================] - 0s 51us/sample - loss: 1.4901 - mae: 0.9802 - mse: 1.4901 - val_loss: 1.4996 - val_mae: 0.9756 - val_mse: 1.4996\n",
      "Epoch 273/1000\n",
      "9021/9021 [==============================] - 0s 42us/sample - loss: 1.4895 - mae: 0.9775 - mse: 1.4895 - val_loss: 1.5081 - val_mae: 0.9798 - val_mse: 1.5081\n",
      "Epoch 274/1000\n",
      "9021/9021 [==============================] - 0s 47us/sample - loss: 1.4894 - mae: 0.9776 - mse: 1.4894 - val_loss: 1.4904 - val_mae: 0.9853 - val_mse: 1.4904\n",
      "Epoch 275/1000\n",
      "9021/9021 [==============================] - 0s 43us/sample - loss: 1.4906 - mae: 0.9788 - mse: 1.4906 - val_loss: 1.4961 - val_mae: 0.9834 - val_mse: 1.4961\n",
      "Epoch 276/1000\n",
      "9021/9021 [==============================] - 0s 27us/sample - loss: 1.4885 - mae: 0.9785 - mse: 1.4885 - val_loss: 1.5109 - val_mae: 0.9809 - val_mse: 1.5109\n",
      "Epoch 277/1000\n",
      "9021/9021 [==============================] - 0s 48us/sample - loss: 1.4893 - mae: 0.9775 - mse: 1.4893 - val_loss: 1.5025 - val_mae: 0.9959 - val_mse: 1.5025\n",
      "Epoch 278/1000\n",
      "9021/9021 [==============================] - 0s 33us/sample - loss: 1.4895 - mae: 0.9788 - mse: 1.4895 - val_loss: 1.4991 - val_mae: 0.9897 - val_mse: 1.4991\n",
      "Epoch 279/1000\n",
      "9021/9021 [==============================] - 0s 36us/sample - loss: 1.4925 - mae: 0.9786 - mse: 1.4925 - val_loss: 1.4835 - val_mae: 0.9847 - val_mse: 1.4835\n",
      "Epoch 280/1000\n",
      "9021/9021 [==============================] - 0s 29us/sample - loss: 1.4914 - mae: 0.9801 - mse: 1.4914 - val_loss: 1.5022 - val_mae: 0.9955 - val_mse: 1.5022\n",
      "Epoch 281/1000\n",
      "9021/9021 [==============================] - 0s 39us/sample - loss: 1.4863 - mae: 0.9777 - mse: 1.4863 - val_loss: 1.4935 - val_mae: 0.9823 - val_mse: 1.4935\n",
      "Epoch 282/1000\n",
      "9021/9021 [==============================] - 0s 36us/sample - loss: 1.4906 - mae: 0.9806 - mse: 1.4906 - val_loss: 1.5128 - val_mae: 0.9766 - val_mse: 1.5128\n",
      "Epoch 283/1000\n",
      "9021/9021 [==============================] - 0s 31us/sample - loss: 1.4895 - mae: 0.9785 - mse: 1.4895 - val_loss: 1.4966 - val_mae: 0.9893 - val_mse: 1.4966\n",
      "Epoch 284/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9021/9021 [==============================] - 0s 25us/sample - loss: 1.4895 - mae: 0.9785 - mse: 1.4895 - val_loss: 1.4923 - val_mae: 0.9888 - val_mse: 1.4923\n",
      "Epoch 285/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.4901 - mae: 0.9794 - mse: 1.4901 - val_loss: 1.4956 - val_mae: 0.9878 - val_mse: 1.4956\n",
      "Epoch 286/1000\n",
      "9021/9021 [==============================] - 0s 27us/sample - loss: 1.4900 - mae: 0.9793 - mse: 1.4900 - val_loss: 1.4957 - val_mae: 0.9782 - val_mse: 1.4957\n",
      "Epoch 287/1000\n",
      "9021/9021 [==============================] - 0s 37us/sample - loss: 1.4881 - mae: 0.9779 - mse: 1.4881 - val_loss: 1.5001 - val_mae: 0.9830 - val_mse: 1.5001\n",
      "Epoch 288/1000\n",
      "9021/9021 [==============================] - 0s 35us/sample - loss: 1.4894 - mae: 0.9786 - mse: 1.4894 - val_loss: 1.4963 - val_mae: 0.9907 - val_mse: 1.4963\n",
      "Epoch 289/1000\n",
      "9021/9021 [==============================] - 0s 36us/sample - loss: 1.4878 - mae: 0.9782 - mse: 1.4878 - val_loss: 1.4941 - val_mae: 0.9883 - val_mse: 1.4941\n",
      "Epoch 290/1000\n",
      "9021/9021 [==============================] - 0s 31us/sample - loss: 1.4900 - mae: 0.9796 - mse: 1.4900 - val_loss: 1.4937 - val_mae: 0.9812 - val_mse: 1.4937\n",
      "Epoch 291/1000\n",
      "9021/9021 [==============================] - 0s 27us/sample - loss: 1.4887 - mae: 0.9790 - mse: 1.4887 - val_loss: 1.5071 - val_mae: 0.9949 - val_mse: 1.5071\n",
      "Epoch 292/1000\n",
      "9021/9021 [==============================] - 0s 28us/sample - loss: 1.4896 - mae: 0.9798 - mse: 1.4896 - val_loss: 1.4893 - val_mae: 0.9798 - val_mse: 1.4893\n",
      "Epoch 293/1000\n",
      "9021/9021 [==============================] - 0s 24us/sample - loss: 1.4876 - mae: 0.9770 - mse: 1.4876 - val_loss: 1.4941 - val_mae: 0.9873 - val_mse: 1.4941\n",
      "Epoch 294/1000\n",
      "9021/9021 [==============================] - 0s 25us/sample - loss: 1.4892 - mae: 0.9790 - mse: 1.4892 - val_loss: 1.5284 - val_mae: 0.9893 - val_mse: 1.5284\n",
      "Epoch 295/1000\n",
      "9021/9021 [==============================] - 0s 36us/sample - loss: 1.4890 - mae: 0.9794 - mse: 1.4890 - val_loss: 1.5142 - val_mae: 0.9741 - val_mse: 1.5142\n",
      "Epoch 296/1000\n",
      "9021/9021 [==============================] - 0s 33us/sample - loss: 1.4871 - mae: 0.9762 - mse: 1.4871 - val_loss: 1.4956 - val_mae: 0.9842 - val_mse: 1.4956\n",
      "Epoch 297/1000\n",
      "9021/9021 [==============================] - 0s 39us/sample - loss: 1.4883 - mae: 0.9783 - mse: 1.4883 - val_loss: 1.4981 - val_mae: 0.9805 - val_mse: 1.4981\n",
      "Epoch 298/1000\n",
      "9021/9021 [==============================] - 0s 31us/sample - loss: 1.4876 - mae: 0.9773 - mse: 1.4876 - val_loss: 1.5118 - val_mae: 0.9739 - val_mse: 1.5118\n",
      "Epoch 299/1000\n",
      "9021/9021 [==============================] - 0s 24us/sample - loss: 1.4885 - mae: 0.9782 - mse: 1.4885 - val_loss: 1.4991 - val_mae: 0.9876 - val_mse: 1.4991\n",
      "Epoch 300/1000\n",
      "9021/9021 [==============================] - 0s 27us/sample - loss: 1.4905 - mae: 0.9792 - mse: 1.4905 - val_loss: 1.5014 - val_mae: 0.9900 - val_mse: 1.5014\n",
      "Epoch 301/1000\n",
      "9021/9021 [==============================] - 0s 32us/sample - loss: 1.4922 - mae: 0.9792 - mse: 1.4922 - val_loss: 1.5059 - val_mae: 0.9800 - val_mse: 1.5059\n",
      "Epoch 302/1000\n",
      "9021/9021 [==============================] - 0s 37us/sample - loss: 1.4890 - mae: 0.9777 - mse: 1.4890 - val_loss: 1.5007 - val_mae: 0.9819 - val_mse: 1.5007\n",
      "Epoch 303/1000\n",
      "9021/9021 [==============================] - 0s 27us/sample - loss: 1.4882 - mae: 0.9791 - mse: 1.4882 - val_loss: 1.4932 - val_mae: 0.9806 - val_mse: 1.4932\n",
      "Epoch 304/1000\n",
      "9021/9021 [==============================] - 0s 27us/sample - loss: 1.4867 - mae: 0.9770 - mse: 1.4867 - val_loss: 1.5064 - val_mae: 0.9979 - val_mse: 1.5064\n",
      "Epoch 305/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.4907 - mae: 0.9796 - mse: 1.4907 - val_loss: 1.4953 - val_mae: 0.9812 - val_mse: 1.4953\n",
      "Epoch 306/1000\n",
      "9021/9021 [==============================] - 0s 24us/sample - loss: 1.4879 - mae: 0.9775 - mse: 1.4879 - val_loss: 1.4864 - val_mae: 0.9841 - val_mse: 1.4864\n",
      "Epoch 307/1000\n",
      "9021/9021 [==============================] - 0s 25us/sample - loss: 1.4891 - mae: 0.9789 - mse: 1.4891 - val_loss: 1.5374 - val_mae: 0.9772 - val_mse: 1.5374\n",
      "Epoch 308/1000\n",
      "9021/9021 [==============================] - 0s 27us/sample - loss: 1.4884 - mae: 0.9773 - mse: 1.4884 - val_loss: 1.5021 - val_mae: 0.9947 - val_mse: 1.5021\n",
      "Epoch 309/1000\n",
      "9021/9021 [==============================] - 0s 36us/sample - loss: 1.4895 - mae: 0.9799 - mse: 1.4895 - val_loss: 1.5005 - val_mae: 0.9771 - val_mse: 1.5005\n",
      "Epoch 310/1000\n",
      "9021/9021 [==============================] - 0s 25us/sample - loss: 1.4873 - mae: 0.9772 - mse: 1.4873 - val_loss: 1.4935 - val_mae: 0.9823 - val_mse: 1.4935\n",
      "Epoch 311/1000\n",
      "9021/9021 [==============================] - 0s 37us/sample - loss: 1.4889 - mae: 0.9785 - mse: 1.4889 - val_loss: 1.4885 - val_mae: 0.9824 - val_mse: 1.4885\n",
      "Epoch 312/1000\n",
      "9021/9021 [==============================] - 0s 40us/sample - loss: 1.4861 - mae: 0.9765 - mse: 1.4861 - val_loss: 1.5019 - val_mae: 0.9800 - val_mse: 1.5019\n",
      "Epoch 313/1000\n",
      "9021/9021 [==============================] - 0s 27us/sample - loss: 1.4905 - mae: 0.9779 - mse: 1.4906 - val_loss: 1.4931 - val_mae: 0.9831 - val_mse: 1.4931\n",
      "Epoch 314/1000\n",
      "9021/9021 [==============================] - 0s 33us/sample - loss: 1.4870 - mae: 0.9768 - mse: 1.4870 - val_loss: 1.4969 - val_mae: 0.9783 - val_mse: 1.4969\n",
      "Epoch 315/1000\n",
      "9021/9021 [==============================] - 0s 41us/sample - loss: 1.4889 - mae: 0.9783 - mse: 1.4889 - val_loss: 1.4915 - val_mae: 0.9811 - val_mse: 1.4915\n",
      "Epoch 316/1000\n",
      "9021/9021 [==============================] - 0s 33us/sample - loss: 1.4881 - mae: 0.9789 - mse: 1.4881 - val_loss: 1.5259 - val_mae: 0.9986 - val_mse: 1.5259\n",
      "Epoch 317/1000\n",
      "9021/9021 [==============================] - 0s 46us/sample - loss: 1.4891 - mae: 0.9784 - mse: 1.4891 - val_loss: 1.4910 - val_mae: 0.9859 - val_mse: 1.4910\n",
      "Epoch 318/1000\n",
      "9021/9021 [==============================] - 0s 33us/sample - loss: 1.4878 - mae: 0.9783 - mse: 1.4878 - val_loss: 1.5041 - val_mae: 0.9787 - val_mse: 1.5041\n",
      "Epoch 319/1000\n",
      "9021/9021 [==============================] - 0s 30us/sample - loss: 1.4886 - mae: 0.9782 - mse: 1.4886 - val_loss: 1.4896 - val_mae: 0.9793 - val_mse: 1.4896\n",
      "Epoch 320/1000\n",
      "9021/9021 [==============================] - 1s 59us/sample - loss: 1.4903 - mae: 0.9787 - mse: 1.4903 - val_loss: 1.5015 - val_mae: 0.9835 - val_mse: 1.5015\n",
      "Epoch 321/1000\n",
      "9021/9021 [==============================] - 1s 57us/sample - loss: 1.4865 - mae: 0.9774 - mse: 1.4865 - val_loss: 1.5000 - val_mae: 0.9853 - val_mse: 1.5000\n",
      "Epoch 322/1000\n",
      "9021/9021 [==============================] - 0s 30us/sample - loss: 1.4895 - mae: 0.9789 - mse: 1.4895 - val_loss: 1.4923 - val_mae: 0.9818 - val_mse: 1.4923\n",
      "Epoch 323/1000\n",
      "9021/9021 [==============================] - 0s 28us/sample - loss: 1.4849 - mae: 0.9771 - mse: 1.4849 - val_loss: 1.4973 - val_mae: 0.9804 - val_mse: 1.4973\n",
      "Epoch 324/1000\n",
      "9021/9021 [==============================] - 0s 39us/sample - loss: 1.4860 - mae: 0.9769 - mse: 1.4860 - val_loss: 1.4909 - val_mae: 0.9804 - val_mse: 1.4909\n",
      "Epoch 325/1000\n",
      "9021/9021 [==============================] - 0s 46us/sample - loss: 1.4887 - mae: 0.9785 - mse: 1.4887 - val_loss: 1.4978 - val_mae: 0.9804 - val_mse: 1.4978\n",
      "Epoch 326/1000\n",
      "9021/9021 [==============================] - 0s 39us/sample - loss: 1.4882 - mae: 0.9770 - mse: 1.4882 - val_loss: 1.4892 - val_mae: 0.9838 - val_mse: 1.4892\n",
      "Epoch 327/1000\n",
      "9021/9021 [==============================] - 0s 27us/sample - loss: 1.4889 - mae: 0.9782 - mse: 1.4889 - val_loss: 1.5020 - val_mae: 0.9840 - val_mse: 1.5020\n",
      "Epoch 328/1000\n",
      "9021/9021 [==============================] - 0s 32us/sample - loss: 1.4864 - mae: 0.9782 - mse: 1.4864 - val_loss: 1.5018 - val_mae: 0.9786 - val_mse: 1.5018\n",
      "Epoch 329/1000\n",
      "9021/9021 [==============================] - 1s 57us/sample - loss: 1.4878 - mae: 0.9780 - mse: 1.4878 - val_loss: 1.4956 - val_mae: 0.9832 - val_mse: 1.4956\n",
      "Epoch 330/1000\n",
      "9021/9021 [==============================] - 0s 29us/sample - loss: 1.4841 - mae: 0.9767 - mse: 1.4841 - val_loss: 1.5370 - val_mae: 0.9757 - val_mse: 1.5370\n",
      "Epoch 331/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9021/9021 [==============================] - 0s 45us/sample - loss: 1.4894 - mae: 0.9788 - mse: 1.4894 - val_loss: 1.5117 - val_mae: 0.9994 - val_mse: 1.5117\n",
      "Epoch 332/1000\n",
      "9021/9021 [==============================] - 0s 32us/sample - loss: 1.4899 - mae: 0.9791 - mse: 1.4899 - val_loss: 1.5050 - val_mae: 0.9817 - val_mse: 1.5050\n",
      "Epoch 333/1000\n",
      "9021/9021 [==============================] - 0s 39us/sample - loss: 1.4853 - mae: 0.9744 - mse: 1.4853 - val_loss: 1.4989 - val_mae: 0.9856 - val_mse: 1.4989\n",
      "Epoch 334/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.4887 - mae: 0.9789 - mse: 1.4887 - val_loss: 1.5206 - val_mae: 1.0011 - val_mse: 1.5206\n",
      "Epoch 335/1000\n",
      "9021/9021 [==============================] - 0s 31us/sample - loss: 1.4907 - mae: 0.9793 - mse: 1.4907 - val_loss: 1.4933 - val_mae: 0.9842 - val_mse: 1.4933\n",
      "Epoch 336/1000\n",
      "9021/9021 [==============================] - 0s 32us/sample - loss: 1.4856 - mae: 0.9764 - mse: 1.4856 - val_loss: 1.4966 - val_mae: 0.9852 - val_mse: 1.4966\n",
      "Epoch 337/1000\n",
      "9021/9021 [==============================] - 0s 36us/sample - loss: 1.4855 - mae: 0.9763 - mse: 1.4855 - val_loss: 1.5147 - val_mae: 0.9827 - val_mse: 1.5147\n",
      "Epoch 338/1000\n",
      "9021/9021 [==============================] - 0s 39us/sample - loss: 1.4867 - mae: 0.9785 - mse: 1.4867 - val_loss: 1.5052 - val_mae: 0.9872 - val_mse: 1.5052\n",
      "Epoch 339/1000\n",
      "9021/9021 [==============================] - 0s 29us/sample - loss: 1.4893 - mae: 0.9795 - mse: 1.4893 - val_loss: 1.5060 - val_mae: 0.9817 - val_mse: 1.5060\n",
      "Epoch 340/1000\n",
      "9021/9021 [==============================] - 0s 52us/sample - loss: 1.4863 - mae: 0.9774 - mse: 1.4863 - val_loss: 1.5319 - val_mae: 1.0055 - val_mse: 1.5319\n",
      "Epoch 341/1000\n",
      "9021/9021 [==============================] - 0s 34us/sample - loss: 1.4879 - mae: 0.9786 - mse: 1.4879 - val_loss: 1.5049 - val_mae: 0.9791 - val_mse: 1.5049\n",
      "Epoch 342/1000\n",
      "9021/9021 [==============================] - 0s 25us/sample - loss: 1.4861 - mae: 0.9763 - mse: 1.4861 - val_loss: 1.4965 - val_mae: 0.9831 - val_mse: 1.4965\n",
      "Epoch 343/1000\n",
      "9021/9021 [==============================] - 0s 36us/sample - loss: 1.4877 - mae: 0.9782 - mse: 1.4877 - val_loss: 1.4977 - val_mae: 0.9788 - val_mse: 1.4977\n",
      "Epoch 344/1000\n",
      "9021/9021 [==============================] - 0s 27us/sample - loss: 1.4876 - mae: 0.9783 - mse: 1.4876 - val_loss: 1.4979 - val_mae: 0.9796 - val_mse: 1.4979\n",
      "Epoch 345/1000\n",
      "9021/9021 [==============================] - 0s 27us/sample - loss: 1.4909 - mae: 0.9787 - mse: 1.4909 - val_loss: 1.4987 - val_mae: 0.9853 - val_mse: 1.4987\n",
      "Epoch 346/1000\n",
      "9021/9021 [==============================] - 0s 24us/sample - loss: 1.4879 - mae: 0.9784 - mse: 1.4879 - val_loss: 1.4966 - val_mae: 0.9806 - val_mse: 1.4966\n",
      "Epoch 347/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.4860 - mae: 0.9780 - mse: 1.4860 - val_loss: 1.4992 - val_mae: 0.9847 - val_mse: 1.4992\n",
      "Epoch 348/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.4883 - mae: 0.9779 - mse: 1.4883 - val_loss: 1.5068 - val_mae: 0.9951 - val_mse: 1.5068\n",
      "Epoch 349/1000\n",
      "9021/9021 [==============================] - 0s 28us/sample - loss: 1.4886 - mae: 0.9775 - mse: 1.4886 - val_loss: 1.4962 - val_mae: 0.9866 - val_mse: 1.4962\n",
      "Epoch 350/1000\n",
      "9021/9021 [==============================] - 0s 39us/sample - loss: 1.4864 - mae: 0.9786 - mse: 1.4864 - val_loss: 1.5099 - val_mae: 0.9834 - val_mse: 1.5099\n",
      "Epoch 351/1000\n",
      "9021/9021 [==============================] - 0s 38us/sample - loss: 1.4871 - mae: 0.9768 - mse: 1.4871 - val_loss: 1.5046 - val_mae: 0.9783 - val_mse: 1.5046\n",
      "Epoch 352/1000\n",
      "9021/9021 [==============================] - 0s 37us/sample - loss: 1.4861 - mae: 0.9766 - mse: 1.4861 - val_loss: 1.4978 - val_mae: 0.9831 - val_mse: 1.4978\n",
      "Epoch 353/1000\n",
      "9021/9021 [==============================] - 0s 37us/sample - loss: 1.4880 - mae: 0.9778 - mse: 1.4880 - val_loss: 1.5051 - val_mae: 0.9801 - val_mse: 1.5051\n",
      "Epoch 354/1000\n",
      "9021/9021 [==============================] - 0s 31us/sample - loss: 1.4865 - mae: 0.9778 - mse: 1.4865 - val_loss: 1.5094 - val_mae: 0.9787 - val_mse: 1.5094\n",
      "Epoch 355/1000\n",
      "9021/9021 [==============================] - 0s 39us/sample - loss: 1.4879 - mae: 0.9778 - mse: 1.4879 - val_loss: 1.5030 - val_mae: 0.9901 - val_mse: 1.5030\n",
      "Epoch 356/1000\n",
      "9021/9021 [==============================] - 0s 47us/sample - loss: 1.4875 - mae: 0.9772 - mse: 1.4875 - val_loss: 1.4941 - val_mae: 0.9866 - val_mse: 1.4941\n",
      "Epoch 357/1000\n",
      "9021/9021 [==============================] - 0s 51us/sample - loss: 1.4870 - mae: 0.9787 - mse: 1.4870 - val_loss: 1.4963 - val_mae: 0.9854 - val_mse: 1.4963\n",
      "Epoch 358/1000\n",
      "9021/9021 [==============================] - 0s 30us/sample - loss: 1.4860 - mae: 0.9776 - mse: 1.4860 - val_loss: 1.4972 - val_mae: 0.9793 - val_mse: 1.4972\n",
      "Epoch 359/1000\n",
      "9021/9021 [==============================] - 1s 64us/sample - loss: 1.4847 - mae: 0.9764 - mse: 1.4847 - val_loss: 1.5179 - val_mae: 0.9957 - val_mse: 1.5179\n",
      "Epoch 360/1000\n",
      "9021/9021 [==============================] - 0s 29us/sample - loss: 1.4878 - mae: 0.9790 - mse: 1.4878 - val_loss: 1.4913 - val_mae: 0.9842 - val_mse: 1.4913\n",
      "Epoch 361/1000\n",
      "9021/9021 [==============================] - 0s 33us/sample - loss: 1.4852 - mae: 0.9770 - mse: 1.4852 - val_loss: 1.5125 - val_mae: 0.9860 - val_mse: 1.5125\n",
      "Epoch 362/1000\n",
      "9021/9021 [==============================] - 0s 24us/sample - loss: 1.4869 - mae: 0.9779 - mse: 1.4869 - val_loss: 1.4934 - val_mae: 0.9821 - val_mse: 1.4934\n",
      "Epoch 363/1000\n",
      "9021/9021 [==============================] - 0s 28us/sample - loss: 1.4868 - mae: 0.9775 - mse: 1.4868 - val_loss: 1.4986 - val_mae: 0.9858 - val_mse: 1.4986\n",
      "Epoch 364/1000\n",
      "9021/9021 [==============================] - 0s 25us/sample - loss: 1.4870 - mae: 0.9774 - mse: 1.4870 - val_loss: 1.4905 - val_mae: 0.9834 - val_mse: 1.4905\n",
      "Epoch 365/1000\n",
      "9021/9021 [==============================] - 0s 27us/sample - loss: 1.4874 - mae: 0.9777 - mse: 1.4874 - val_loss: 1.4963 - val_mae: 0.9799 - val_mse: 1.4963\n",
      "Epoch 366/1000\n",
      "9021/9021 [==============================] - 0s 27us/sample - loss: 1.4857 - mae: 0.9761 - mse: 1.4857 - val_loss: 1.5082 - val_mae: 0.9803 - val_mse: 1.5082\n",
      "Epoch 367/1000\n",
      "9021/9021 [==============================] - 0s 32us/sample - loss: 1.4884 - mae: 0.9772 - mse: 1.4884 - val_loss: 1.5159 - val_mae: 0.9831 - val_mse: 1.5159\n",
      "Epoch 368/1000\n",
      "9021/9021 [==============================] - 0s 27us/sample - loss: 1.4884 - mae: 0.9777 - mse: 1.4884 - val_loss: 1.5020 - val_mae: 0.9782 - val_mse: 1.5020\n",
      "Epoch 369/1000\n",
      "9021/9021 [==============================] - 0s 28us/sample - loss: 1.4880 - mae: 0.9782 - mse: 1.4880 - val_loss: 1.4954 - val_mae: 0.9842 - val_mse: 1.4954\n",
      "Epoch 370/1000\n",
      "9021/9021 [==============================] - 0s 24us/sample - loss: 1.4864 - mae: 0.9779 - mse: 1.4864 - val_loss: 1.5112 - val_mae: 0.9903 - val_mse: 1.5112\n",
      "Epoch 371/1000\n",
      "9021/9021 [==============================] - 0s 24us/sample - loss: 1.4861 - mae: 0.9772 - mse: 1.4861 - val_loss: 1.4969 - val_mae: 0.9799 - val_mse: 1.4969\n",
      "Epoch 372/1000\n",
      "9021/9021 [==============================] - 0s 28us/sample - loss: 1.4842 - mae: 0.9749 - mse: 1.4842 - val_loss: 1.5009 - val_mae: 0.9804 - val_mse: 1.5009\n",
      "Epoch 373/1000\n",
      "9021/9021 [==============================] - 0s 27us/sample - loss: 1.4876 - mae: 0.9768 - mse: 1.4876 - val_loss: 1.5030 - val_mae: 0.9914 - val_mse: 1.5030\n",
      "Epoch 374/1000\n",
      "9021/9021 [==============================] - 0s 25us/sample - loss: 1.4826 - mae: 0.9766 - mse: 1.4826 - val_loss: 1.5365 - val_mae: 0.9775 - val_mse: 1.5365\n",
      "Epoch 375/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.4878 - mae: 0.9767 - mse: 1.4878 - val_loss: 1.5041 - val_mae: 0.9779 - val_mse: 1.5041\n",
      "Epoch 376/1000\n",
      "9021/9021 [==============================] - 0s 25us/sample - loss: 1.4866 - mae: 0.9778 - mse: 1.4866 - val_loss: 1.5032 - val_mae: 0.9830 - val_mse: 1.5032\n",
      "Epoch 377/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.4878 - mae: 0.9780 - mse: 1.4878 - val_loss: 1.5086 - val_mae: 0.9883 - val_mse: 1.5086\n",
      "Epoch 378/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.4870 - mae: 0.9769 - mse: 1.4870 - val_loss: 1.4932 - val_mae: 0.9848 - val_mse: 1.4932\n",
      "Epoch 379/1000\n",
      "9021/9021 [==============================] - 0s 37us/sample - loss: 1.4874 - mae: 0.9769 - mse: 1.4874 - val_loss: 1.5121 - val_mae: 0.9950 - val_mse: 1.5121\n",
      "Epoch 380/1000\n",
      "9021/9021 [==============================] - 0s 34us/sample - loss: 1.4876 - mae: 0.9773 - mse: 1.4876 - val_loss: 1.4943 - val_mae: 0.9806 - val_mse: 1.4943\n",
      "Epoch 381/1000\n",
      "9021/9021 [==============================] - 0s 33us/sample - loss: 1.4856 - mae: 0.9771 - mse: 1.4856 - val_loss: 1.5059 - val_mae: 0.9961 - val_mse: 1.5059\n",
      "Epoch 382/1000\n",
      "9021/9021 [==============================] - 0s 27us/sample - loss: 1.4875 - mae: 0.9789 - mse: 1.4875 - val_loss: 1.5035 - val_mae: 0.9789 - val_mse: 1.5035\n",
      "Epoch 383/1000\n",
      "9021/9021 [==============================] - 0s 37us/sample - loss: 1.4838 - mae: 0.9759 - mse: 1.4838 - val_loss: 1.5177 - val_mae: 0.9928 - val_mse: 1.5177\n",
      "Epoch 384/1000\n",
      "9021/9021 [==============================] - 0s 45us/sample - loss: 1.4885 - mae: 0.9778 - mse: 1.4885 - val_loss: 1.5062 - val_mae: 0.9897 - val_mse: 1.5062\n",
      "Epoch 385/1000\n",
      "9021/9021 [==============================] - 0s 34us/sample - loss: 1.4867 - mae: 0.9764 - mse: 1.4867 - val_loss: 1.5061 - val_mae: 0.9953 - val_mse: 1.5061\n",
      "Epoch 386/1000\n",
      "9021/9021 [==============================] - 0s 44us/sample - loss: 1.4852 - mae: 0.9766 - mse: 1.4852 - val_loss: 1.5014 - val_mae: 0.9797 - val_mse: 1.5014\n",
      "Epoch 387/1000\n",
      "9021/9021 [==============================] - 0s 24us/sample - loss: 1.4865 - mae: 0.9763 - mse: 1.4865 - val_loss: 1.4934 - val_mae: 0.9866 - val_mse: 1.4934\n",
      "Epoch 388/1000\n",
      "9021/9021 [==============================] - 0s 27us/sample - loss: 1.4851 - mae: 0.9761 - mse: 1.4851 - val_loss: 1.5111 - val_mae: 0.9829 - val_mse: 1.5111\n",
      "Epoch 389/1000\n",
      "9021/9021 [==============================] - 0s 25us/sample - loss: 1.4870 - mae: 0.9770 - mse: 1.4870 - val_loss: 1.4984 - val_mae: 0.9872 - val_mse: 1.4984\n",
      "Epoch 390/1000\n",
      "9021/9021 [==============================] - 0s 22us/sample - loss: 1.4849 - mae: 0.9754 - mse: 1.4849 - val_loss: 1.4917 - val_mae: 0.9855 - val_mse: 1.4917\n",
      "Epoch 391/1000\n",
      "9021/9021 [==============================] - 0s 34us/sample - loss: 1.4868 - mae: 0.9787 - mse: 1.4868 - val_loss: 1.4967 - val_mae: 0.9808 - val_mse: 1.4967\n",
      "Epoch 392/1000\n",
      "9021/9021 [==============================] - 0s 27us/sample - loss: 1.4868 - mae: 0.9775 - mse: 1.4868 - val_loss: 1.5199 - val_mae: 0.9992 - val_mse: 1.5199\n",
      "Epoch 393/1000\n",
      "9021/9021 [==============================] - 0s 25us/sample - loss: 1.4864 - mae: 0.9766 - mse: 1.4864 - val_loss: 1.5009 - val_mae: 0.9815 - val_mse: 1.5009\n",
      "Epoch 394/1000\n",
      "9021/9021 [==============================] - 0s 35us/sample - loss: 1.4854 - mae: 0.9783 - mse: 1.4854 - val_loss: 1.5253 - val_mae: 0.9815 - val_mse: 1.5253\n",
      "Epoch 395/1000\n",
      "9021/9021 [==============================] - 0s 34us/sample - loss: 1.4843 - mae: 0.9763 - mse: 1.4843 - val_loss: 1.5222 - val_mae: 0.9797 - val_mse: 1.5222\n",
      "Epoch 396/1000\n",
      "9021/9021 [==============================] - 0s 34us/sample - loss: 1.4857 - mae: 0.9768 - mse: 1.4857 - val_loss: 1.5060 - val_mae: 0.9950 - val_mse: 1.5060\n",
      "Epoch 397/1000\n",
      "9021/9021 [==============================] - 0s 27us/sample - loss: 1.4847 - mae: 0.9777 - mse: 1.4847 - val_loss: 1.4986 - val_mae: 0.9812 - val_mse: 1.4986\n",
      "Epoch 398/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.4857 - mae: 0.9757 - mse: 1.4857 - val_loss: 1.4923 - val_mae: 0.9858 - val_mse: 1.4923\n",
      "Epoch 399/1000\n",
      "9021/9021 [==============================] - 0s 27us/sample - loss: 1.4855 - mae: 0.9768 - mse: 1.4855 - val_loss: 1.5032 - val_mae: 0.9878 - val_mse: 1.5032\n",
      "Epoch 400/1000\n",
      "9021/9021 [==============================] - 0s 25us/sample - loss: 1.4843 - mae: 0.9764 - mse: 1.4843 - val_loss: 1.4978 - val_mae: 0.9806 - val_mse: 1.4978\n",
      "Epoch 401/1000\n",
      "9021/9021 [==============================] - 0s 31us/sample - loss: 1.4858 - mae: 0.9771 - mse: 1.4858 - val_loss: 1.4926 - val_mae: 0.9836 - val_mse: 1.4926\n",
      "Epoch 402/1000\n",
      "9021/9021 [==============================] - 0s 36us/sample - loss: 1.4848 - mae: 0.9771 - mse: 1.4848 - val_loss: 1.4989 - val_mae: 0.9903 - val_mse: 1.4989\n",
      "Epoch 403/1000\n",
      "9021/9021 [==============================] - 0s 29us/sample - loss: 1.4850 - mae: 0.9771 - mse: 1.4850 - val_loss: 1.5007 - val_mae: 0.9889 - val_mse: 1.5007\n",
      "Epoch 404/1000\n",
      "9021/9021 [==============================] - 0s 42us/sample - loss: 1.4847 - mae: 0.9773 - mse: 1.4847 - val_loss: 1.5219 - val_mae: 0.9774 - val_mse: 1.5219\n",
      "Epoch 405/1000\n",
      "9021/9021 [==============================] - 0s 36us/sample - loss: 1.4865 - mae: 0.9774 - mse: 1.4865 - val_loss: 1.5140 - val_mae: 0.9815 - val_mse: 1.5140\n",
      "Epoch 406/1000\n",
      "9021/9021 [==============================] - 0s 28us/sample - loss: 1.4832 - mae: 0.9758 - mse: 1.4832 - val_loss: 1.5143 - val_mae: 0.9822 - val_mse: 1.5143\n",
      "Epoch 407/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.4865 - mae: 0.9765 - mse: 1.4865 - val_loss: 1.4917 - val_mae: 0.9833 - val_mse: 1.4917\n",
      "Epoch 408/1000\n",
      "9021/9021 [==============================] - 0s 27us/sample - loss: 1.4844 - mae: 0.9759 - mse: 1.4844 - val_loss: 1.4963 - val_mae: 0.9893 - val_mse: 1.4963\n",
      "Epoch 409/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.4861 - mae: 0.9764 - mse: 1.4861 - val_loss: 1.4909 - val_mae: 0.9812 - val_mse: 1.4909\n",
      "Epoch 410/1000\n",
      "9021/9021 [==============================] - 0s 25us/sample - loss: 1.4838 - mae: 0.9761 - mse: 1.4838 - val_loss: 1.5113 - val_mae: 0.9757 - val_mse: 1.5113\n",
      "Epoch 411/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.4862 - mae: 0.9765 - mse: 1.4862 - val_loss: 1.4978 - val_mae: 0.9884 - val_mse: 1.4978\n",
      "Epoch 412/1000\n",
      "9021/9021 [==============================] - 0s 24us/sample - loss: 1.4842 - mae: 0.9772 - mse: 1.4842 - val_loss: 1.5069 - val_mae: 0.9865 - val_mse: 1.5069\n",
      "Epoch 413/1000\n",
      "9021/9021 [==============================] - 0s 24us/sample - loss: 1.4874 - mae: 0.9769 - mse: 1.4875 - val_loss: 1.4944 - val_mae: 0.9859 - val_mse: 1.4944\n",
      "Epoch 414/1000\n",
      "9021/9021 [==============================] - 0s 27us/sample - loss: 1.4825 - mae: 0.9757 - mse: 1.4825 - val_loss: 1.4971 - val_mae: 0.9813 - val_mse: 1.4971\n",
      "Epoch 415/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.4837 - mae: 0.9760 - mse: 1.4837 - val_loss: 1.4969 - val_mae: 0.9821 - val_mse: 1.4969\n",
      "Epoch 416/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.4839 - mae: 0.9769 - mse: 1.4839 - val_loss: 1.5105 - val_mae: 0.9845 - val_mse: 1.5105\n",
      "Epoch 417/1000\n",
      "9021/9021 [==============================] - 0s 25us/sample - loss: 1.4857 - mae: 0.9760 - mse: 1.4857 - val_loss: 1.5019 - val_mae: 0.9883 - val_mse: 1.5019\n",
      "Epoch 418/1000\n",
      "9021/9021 [==============================] - 0s 25us/sample - loss: 1.4873 - mae: 0.9779 - mse: 1.4873 - val_loss: 1.5085 - val_mae: 0.9895 - val_mse: 1.5085\n",
      "Epoch 419/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.4841 - mae: 0.9747 - mse: 1.4841 - val_loss: 1.5116 - val_mae: 0.9922 - val_mse: 1.5116\n",
      "Epoch 420/1000\n",
      "9021/9021 [==============================] - 0s 25us/sample - loss: 1.4857 - mae: 0.9775 - mse: 1.4857 - val_loss: 1.4979 - val_mae: 0.9808 - val_mse: 1.4979\n",
      "Epoch 421/1000\n",
      "9021/9021 [==============================] - 0s 25us/sample - loss: 1.4822 - mae: 0.9763 - mse: 1.4822 - val_loss: 1.5085 - val_mae: 0.9874 - val_mse: 1.5085\n",
      "Epoch 422/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.4824 - mae: 0.9749 - mse: 1.4824 - val_loss: 1.5054 - val_mae: 0.9924 - val_mse: 1.5054\n",
      "Epoch 423/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.4850 - mae: 0.9762 - mse: 1.4850 - val_loss: 1.4947 - val_mae: 0.9863 - val_mse: 1.4947\n",
      "Epoch 424/1000\n",
      "9021/9021 [==============================] - 0s 27us/sample - loss: 1.4850 - mae: 0.9769 - mse: 1.4850 - val_loss: 1.5007 - val_mae: 0.9837 - val_mse: 1.5007\n",
      "Epoch 425/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9021/9021 [==============================] - 0s 25us/sample - loss: 1.4846 - mae: 0.9751 - mse: 1.4846 - val_loss: 1.5150 - val_mae: 0.9959 - val_mse: 1.5150\n",
      "Epoch 426/1000\n",
      "9021/9021 [==============================] - 0s 24us/sample - loss: 1.4837 - mae: 0.9766 - mse: 1.4837 - val_loss: 1.5187 - val_mae: 0.9808 - val_mse: 1.5187\n",
      "Epoch 427/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.4836 - mae: 0.9767 - mse: 1.4836 - val_loss: 1.4923 - val_mae: 0.9784 - val_mse: 1.4923\n",
      "Epoch 428/1000\n",
      "9021/9021 [==============================] - 0s 36us/sample - loss: 1.4860 - mae: 0.9774 - mse: 1.4860 - val_loss: 1.5063 - val_mae: 0.9866 - val_mse: 1.5063\n",
      "Epoch 429/1000\n",
      "9021/9021 [==============================] - 0s 25us/sample - loss: 1.4847 - mae: 0.9761 - mse: 1.4847 - val_loss: 1.5042 - val_mae: 0.9806 - val_mse: 1.5042\n",
      "Epoch 430/1000\n",
      "9021/9021 [==============================] - 0s 32us/sample - loss: 1.4857 - mae: 0.9766 - mse: 1.4857 - val_loss: 1.5019 - val_mae: 0.9845 - val_mse: 1.5019\n",
      "Epoch 431/1000\n",
      "9021/9021 [==============================] - 0s 27us/sample - loss: 1.4828 - mae: 0.9749 - mse: 1.4828 - val_loss: 1.4960 - val_mae: 0.9844 - val_mse: 1.4960\n",
      "Epoch 432/1000\n",
      "9021/9021 [==============================] - 0s 30us/sample - loss: 1.4856 - mae: 0.9767 - mse: 1.4856 - val_loss: 1.5144 - val_mae: 0.9991 - val_mse: 1.5144\n",
      "Epoch 433/1000\n",
      "9021/9021 [==============================] - 0s 27us/sample - loss: 1.4854 - mae: 0.9763 - mse: 1.4854 - val_loss: 1.4977 - val_mae: 0.9811 - val_mse: 1.4977\n",
      "Epoch 434/1000\n",
      "9021/9021 [==============================] - 0s 41us/sample - loss: 1.4853 - mae: 0.9770 - mse: 1.4853 - val_loss: 1.5066 - val_mae: 0.9796 - val_mse: 1.5066\n",
      "Epoch 435/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.4857 - mae: 0.9760 - mse: 1.4857 - val_loss: 1.5166 - val_mae: 0.9823 - val_mse: 1.5166\n",
      "Epoch 436/1000\n",
      "9021/9021 [==============================] - 0s 24us/sample - loss: 1.4843 - mae: 0.9762 - mse: 1.4843 - val_loss: 1.4951 - val_mae: 0.9846 - val_mse: 1.4951\n",
      "Epoch 437/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.4837 - mae: 0.9771 - mse: 1.4837 - val_loss: 1.5003 - val_mae: 0.9857 - val_mse: 1.5003\n",
      "Epoch 438/1000\n",
      "9021/9021 [==============================] - 0s 22us/sample - loss: 1.4829 - mae: 0.9752 - mse: 1.4829 - val_loss: 1.5033 - val_mae: 0.9869 - val_mse: 1.5033\n",
      "Epoch 439/1000\n",
      "9021/9021 [==============================] - 0s 19us/sample - loss: 1.4841 - mae: 0.9758 - mse: 1.4841 - val_loss: 1.5097 - val_mae: 0.9903 - val_mse: 1.5097\n",
      "Epoch 440/1000\n",
      "9021/9021 [==============================] - 0s 19us/sample - loss: 1.4855 - mae: 0.9765 - mse: 1.4855 - val_loss: 1.5029 - val_mae: 0.9909 - val_mse: 1.5029\n",
      "Epoch 441/1000\n",
      "9021/9021 [==============================] - 0s 20us/sample - loss: 1.4850 - mae: 0.9759 - mse: 1.4850 - val_loss: 1.4964 - val_mae: 0.9881 - val_mse: 1.4964\n",
      "Epoch 442/1000\n",
      "9021/9021 [==============================] - 0s 20us/sample - loss: 1.4818 - mae: 0.9753 - mse: 1.4818 - val_loss: 1.5047 - val_mae: 0.9885 - val_mse: 1.5047\n",
      "Epoch 443/1000\n",
      "9021/9021 [==============================] - 0s 19us/sample - loss: 1.4822 - mae: 0.9758 - mse: 1.4822 - val_loss: 1.5082 - val_mae: 0.9861 - val_mse: 1.5082\n",
      "Epoch 444/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.4834 - mae: 0.9760 - mse: 1.4834 - val_loss: 1.5038 - val_mae: 0.9814 - val_mse: 1.5038\n",
      "Epoch 445/1000\n",
      "9021/9021 [==============================] - 0s 27us/sample - loss: 1.4839 - mae: 0.9761 - mse: 1.4839 - val_loss: 1.5044 - val_mae: 0.9859 - val_mse: 1.5044\n",
      "Epoch 446/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.4857 - mae: 0.9781 - mse: 1.4857 - val_loss: 1.5025 - val_mae: 0.9882 - val_mse: 1.5025\n",
      "Epoch 447/1000\n",
      "9021/9021 [==============================] - 0s 27us/sample - loss: 1.4846 - mae: 0.9766 - mse: 1.4846 - val_loss: 1.5178 - val_mae: 0.9958 - val_mse: 1.5178\n",
      "Epoch 448/1000\n",
      "9021/9021 [==============================] - 0s 31us/sample - loss: 1.4844 - mae: 0.9758 - mse: 1.4844 - val_loss: 1.5120 - val_mae: 0.9937 - val_mse: 1.5120\n",
      "Epoch 449/1000\n",
      "9021/9021 [==============================] - 0s 30us/sample - loss: 1.4838 - mae: 0.9772 - mse: 1.4838 - val_loss: 1.4987 - val_mae: 0.9856 - val_mse: 1.4987\n",
      "Epoch 450/1000\n",
      "9021/9021 [==============================] - 0s 29us/sample - loss: 1.4856 - mae: 0.9763 - mse: 1.4856 - val_loss: 1.4973 - val_mae: 0.9849 - val_mse: 1.4973\n",
      "Epoch 451/1000\n",
      "9021/9021 [==============================] - 0s 30us/sample - loss: 1.4832 - mae: 0.9760 - mse: 1.4832 - val_loss: 1.5050 - val_mae: 0.9897 - val_mse: 1.5050\n",
      "Epoch 452/1000\n",
      "9021/9021 [==============================] - 0s 29us/sample - loss: 1.4858 - mae: 0.9772 - mse: 1.4858 - val_loss: 1.4994 - val_mae: 0.9891 - val_mse: 1.4994\n",
      "Epoch 453/1000\n",
      "9021/9021 [==============================] - 0s 27us/sample - loss: 1.4827 - mae: 0.9757 - mse: 1.4827 - val_loss: 1.5047 - val_mae: 0.9938 - val_mse: 1.5047\n",
      "Epoch 454/1000\n",
      "9021/9021 [==============================] - 0s 29us/sample - loss: 1.4857 - mae: 0.9777 - mse: 1.4857 - val_loss: 1.5298 - val_mae: 1.0053 - val_mse: 1.5298\n",
      "Epoch 455/1000\n",
      "9021/9021 [==============================] - 0s 41us/sample - loss: 1.4824 - mae: 0.9760 - mse: 1.4824 - val_loss: 1.4929 - val_mae: 0.9806 - val_mse: 1.4929\n",
      "Epoch 456/1000\n",
      "9021/9021 [==============================] - 0s 48us/sample - loss: 1.4849 - mae: 0.9760 - mse: 1.4849 - val_loss: 1.4969 - val_mae: 0.9831 - val_mse: 1.4969\n",
      "Epoch 457/1000\n",
      "9021/9021 [==============================] - 0s 40us/sample - loss: 1.4852 - mae: 0.9756 - mse: 1.4852 - val_loss: 1.5002 - val_mae: 0.9826 - val_mse: 1.5002\n",
      "Epoch 458/1000\n",
      "9021/9021 [==============================] - 0s 41us/sample - loss: 1.4847 - mae: 0.9766 - mse: 1.4847 - val_loss: 1.5009 - val_mae: 0.9833 - val_mse: 1.5009\n",
      "Epoch 459/1000\n",
      "9021/9021 [==============================] - 0s 52us/sample - loss: 1.4840 - mae: 0.9761 - mse: 1.4840 - val_loss: 1.5223 - val_mae: 1.0016 - val_mse: 1.5223\n",
      "Epoch 460/1000\n",
      "9021/9021 [==============================] - 0s 41us/sample - loss: 1.4832 - mae: 0.9760 - mse: 1.4832 - val_loss: 1.5076 - val_mae: 0.9810 - val_mse: 1.5076\n",
      "Epoch 461/1000\n",
      "9021/9021 [==============================] - 0s 41us/sample - loss: 1.4833 - mae: 0.9753 - mse: 1.4833 - val_loss: 1.5219 - val_mae: 0.9993 - val_mse: 1.5219\n",
      "Epoch 462/1000\n",
      "9021/9021 [==============================] - 0s 39us/sample - loss: 1.4840 - mae: 0.9759 - mse: 1.4840 - val_loss: 1.4917 - val_mae: 0.9875 - val_mse: 1.4917\n",
      "Epoch 463/1000\n",
      "9021/9021 [==============================] - 0s 40us/sample - loss: 1.4832 - mae: 0.9750 - mse: 1.4832 - val_loss: 1.4936 - val_mae: 0.9864 - val_mse: 1.4936\n",
      "Epoch 464/1000\n",
      "9021/9021 [==============================] - 0s 37us/sample - loss: 1.4846 - mae: 0.9773 - mse: 1.4846 - val_loss: 1.4992 - val_mae: 0.9910 - val_mse: 1.4992\n",
      "Epoch 465/1000\n",
      "9021/9021 [==============================] - 0s 35us/sample - loss: 1.4824 - mae: 0.9762 - mse: 1.4824 - val_loss: 1.4988 - val_mae: 0.9805 - val_mse: 1.4988\n",
      "Epoch 466/1000\n",
      "9021/9021 [==============================] - 0s 24us/sample - loss: 1.4840 - mae: 0.9767 - mse: 1.4840 - val_loss: 1.4923 - val_mae: 0.9834 - val_mse: 1.4923\n",
      "Epoch 467/1000\n",
      "9021/9021 [==============================] - 0s 32us/sample - loss: 1.4858 - mae: 0.9763 - mse: 1.4858 - val_loss: 1.4976 - val_mae: 0.9888 - val_mse: 1.4976\n",
      "Epoch 468/1000\n",
      "9021/9021 [==============================] - 0s 28us/sample - loss: 1.4858 - mae: 0.9771 - mse: 1.4858 - val_loss: 1.4981 - val_mae: 0.9893 - val_mse: 1.4981\n",
      "Epoch 469/1000\n",
      "9021/9021 [==============================] - 0s 25us/sample - loss: 1.4837 - mae: 0.9761 - mse: 1.4837 - val_loss: 1.5140 - val_mae: 0.9960 - val_mse: 1.5140\n",
      "Epoch 470/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.4831 - mae: 0.9761 - mse: 1.4831 - val_loss: 1.4997 - val_mae: 0.9845 - val_mse: 1.4997\n",
      "Epoch 471/1000\n",
      "9021/9021 [==============================] - 0s 27us/sample - loss: 1.4857 - mae: 0.9766 - mse: 1.4857 - val_loss: 1.5112 - val_mae: 0.9798 - val_mse: 1.5112\n",
      "Epoch 472/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9021/9021 [==============================] - 0s 52us/sample - loss: 1.4863 - mae: 0.9773 - mse: 1.4863 - val_loss: 1.5080 - val_mae: 0.9809 - val_mse: 1.5080\n",
      "Epoch 473/1000\n",
      "9021/9021 [==============================] - 0s 36us/sample - loss: 1.4831 - mae: 0.9750 - mse: 1.4831 - val_loss: 1.4999 - val_mae: 0.9893 - val_mse: 1.4999\n",
      "Epoch 474/1000\n",
      "9021/9021 [==============================] - 0s 33us/sample - loss: 1.4833 - mae: 0.9762 - mse: 1.4833 - val_loss: 1.5094 - val_mae: 0.9932 - val_mse: 1.5094\n",
      "Epoch 475/1000\n",
      "9021/9021 [==============================] - 0s 27us/sample - loss: 1.4817 - mae: 0.9755 - mse: 1.4817 - val_loss: 1.5060 - val_mae: 0.9873 - val_mse: 1.5060\n",
      "Epoch 476/1000\n",
      "9021/9021 [==============================] - 0s 25us/sample - loss: 1.4824 - mae: 0.9750 - mse: 1.4824 - val_loss: 1.5014 - val_mae: 0.9907 - val_mse: 1.5014\n",
      "Epoch 477/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.4824 - mae: 0.9768 - mse: 1.4824 - val_loss: 1.5031 - val_mae: 0.9875 - val_mse: 1.5031\n",
      "Epoch 478/1000\n",
      "9021/9021 [==============================] - 0s 28us/sample - loss: 1.4822 - mae: 0.9754 - mse: 1.4822 - val_loss: 1.5120 - val_mae: 0.9774 - val_mse: 1.5120\n",
      "Epoch 479/1000\n",
      "9021/9021 [==============================] - 0s 29us/sample - loss: 1.4823 - mae: 0.9735 - mse: 1.4823 - val_loss: 1.4941 - val_mae: 0.9833 - val_mse: 1.4941\n",
      "Epoch 480/1000\n",
      "9021/9021 [==============================] - 0s 28us/sample - loss: 1.4844 - mae: 0.9766 - mse: 1.4844 - val_loss: 1.5020 - val_mae: 0.9838 - val_mse: 1.5020\n",
      "Epoch 481/1000\n",
      "9021/9021 [==============================] - 0s 28us/sample - loss: 1.4817 - mae: 0.9760 - mse: 1.4817 - val_loss: 1.4999 - val_mae: 0.9870 - val_mse: 1.4999\n",
      "Epoch 482/1000\n",
      "9021/9021 [==============================] - 0s 31us/sample - loss: 1.4809 - mae: 0.9755 - mse: 1.4809 - val_loss: 1.5077 - val_mae: 0.9829 - val_mse: 1.5077\n",
      "Epoch 483/1000\n",
      "9021/9021 [==============================] - 0s 29us/sample - loss: 1.4860 - mae: 0.9764 - mse: 1.4860 - val_loss: 1.5039 - val_mae: 0.9823 - val_mse: 1.5039\n",
      "Epoch 484/1000\n",
      "9021/9021 [==============================] - 0s 27us/sample - loss: 1.4836 - mae: 0.9764 - mse: 1.4836 - val_loss: 1.5107 - val_mae: 0.9846 - val_mse: 1.5107\n",
      "Epoch 485/1000\n",
      "9021/9021 [==============================] - 0s 29us/sample - loss: 1.4828 - mae: 0.9764 - mse: 1.4828 - val_loss: 1.4979 - val_mae: 0.9806 - val_mse: 1.4979\n",
      "Epoch 486/1000\n",
      "9021/9021 [==============================] - 0s 29us/sample - loss: 1.4861 - mae: 0.9766 - mse: 1.4861 - val_loss: 1.5152 - val_mae: 0.9843 - val_mse: 1.5152\n",
      "Epoch 487/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.4826 - mae: 0.9752 - mse: 1.4826 - val_loss: 1.4944 - val_mae: 0.9835 - val_mse: 1.4944\n",
      "Epoch 488/1000\n",
      "9021/9021 [==============================] - 0s 24us/sample - loss: 1.4835 - mae: 0.9756 - mse: 1.4835 - val_loss: 1.5087 - val_mae: 0.9938 - val_mse: 1.5087\n",
      "Epoch 489/1000\n",
      "9021/9021 [==============================] - 0s 31us/sample - loss: 1.4816 - mae: 0.9741 - mse: 1.4816 - val_loss: 1.5040 - val_mae: 0.9865 - val_mse: 1.5040\n",
      "Epoch 490/1000\n",
      "9021/9021 [==============================] - 0s 27us/sample - loss: 1.4835 - mae: 0.9754 - mse: 1.4835 - val_loss: 1.4996 - val_mae: 0.9892 - val_mse: 1.4996\n",
      "Epoch 491/1000\n",
      "9021/9021 [==============================] - 0s 33us/sample - loss: 1.4831 - mae: 0.9758 - mse: 1.4831 - val_loss: 1.4990 - val_mae: 0.9842 - val_mse: 1.4990\n",
      "Epoch 492/1000\n",
      "9021/9021 [==============================] - 0s 29us/sample - loss: 1.4811 - mae: 0.9758 - mse: 1.4811 - val_loss: 1.5060 - val_mae: 0.9899 - val_mse: 1.5060\n",
      "Epoch 493/1000\n",
      "9021/9021 [==============================] - 0s 27us/sample - loss: 1.4835 - mae: 0.9753 - mse: 1.4835 - val_loss: 1.5052 - val_mae: 0.9900 - val_mse: 1.5052\n",
      "Epoch 494/1000\n",
      "9021/9021 [==============================] - 0s 38us/sample - loss: 1.4818 - mae: 0.9752 - mse: 1.4818 - val_loss: 1.5035 - val_mae: 0.9784 - val_mse: 1.5035\n",
      "Epoch 495/1000\n",
      "9021/9021 [==============================] - 0s 35us/sample - loss: 1.4840 - mae: 0.9764 - mse: 1.4840 - val_loss: 1.4988 - val_mae: 0.9895 - val_mse: 1.4988\n",
      "Epoch 496/1000\n",
      "9021/9021 [==============================] - 0s 42us/sample - loss: 1.4815 - mae: 0.9738 - mse: 1.4815 - val_loss: 1.5146 - val_mae: 0.9977 - val_mse: 1.5146\n",
      "Epoch 497/1000\n",
      "9021/9021 [==============================] - 0s 33us/sample - loss: 1.4844 - mae: 0.9756 - mse: 1.4844 - val_loss: 1.5074 - val_mae: 0.9867 - val_mse: 1.5074\n",
      "Epoch 498/1000\n",
      "9021/9021 [==============================] - 0s 31us/sample - loss: 1.4831 - mae: 0.9760 - mse: 1.4831 - val_loss: 1.5226 - val_mae: 0.9824 - val_mse: 1.5226\n",
      "Epoch 499/1000\n",
      "9021/9021 [==============================] - 0s 43us/sample - loss: 1.4831 - mae: 0.9755 - mse: 1.4831 - val_loss: 1.5020 - val_mae: 0.9862 - val_mse: 1.5020\n",
      "Epoch 500/1000\n",
      "9021/9021 [==============================] - 0s 52us/sample - loss: 1.4802 - mae: 0.9740 - mse: 1.4802 - val_loss: 1.5065 - val_mae: 0.9877 - val_mse: 1.5065\n",
      "Epoch 501/1000\n",
      "9021/9021 [==============================] - 0s 49us/sample - loss: 1.4824 - mae: 0.9769 - mse: 1.4824 - val_loss: 1.5131 - val_mae: 0.9941 - val_mse: 1.5131\n",
      "Epoch 502/1000\n",
      "9021/9021 [==============================] - 1s 56us/sample - loss: 1.4827 - mae: 0.9750 - mse: 1.4827 - val_loss: 1.5015 - val_mae: 0.9902 - val_mse: 1.5015\n",
      "Epoch 503/1000\n",
      "9021/9021 [==============================] - 0s 53us/sample - loss: 1.4830 - mae: 0.9758 - mse: 1.4830 - val_loss: 1.5020 - val_mae: 0.9887 - val_mse: 1.5020\n",
      "Epoch 504/1000\n",
      "9021/9021 [==============================] - 0s 49us/sample - loss: 1.4830 - mae: 0.9763 - mse: 1.4830 - val_loss: 1.4996 - val_mae: 0.9874 - val_mse: 1.4996\n",
      "Epoch 505/1000\n",
      "9021/9021 [==============================] - 0s 47us/sample - loss: 1.4807 - mae: 0.9749 - mse: 1.4807 - val_loss: 1.5012 - val_mae: 0.9871 - val_mse: 1.5012\n",
      "Epoch 506/1000\n",
      "9021/9021 [==============================] - 0s 47us/sample - loss: 1.4824 - mae: 0.9742 - mse: 1.4824 - val_loss: 1.4986 - val_mae: 0.9867 - val_mse: 1.4986\n",
      "Epoch 507/1000\n",
      "9021/9021 [==============================] - 0s 45us/sample - loss: 1.4826 - mae: 0.9746 - mse: 1.4826 - val_loss: 1.5126 - val_mae: 0.9958 - val_mse: 1.5126\n",
      "Epoch 508/1000\n",
      "9021/9021 [==============================] - 0s 52us/sample - loss: 1.4855 - mae: 0.9767 - mse: 1.4855 - val_loss: 1.5065 - val_mae: 0.9849 - val_mse: 1.5065\n",
      "Epoch 509/1000\n",
      "9021/9021 [==============================] - 0s 33us/sample - loss: 1.4822 - mae: 0.9744 - mse: 1.4822 - val_loss: 1.5007 - val_mae: 0.9839 - val_mse: 1.5007\n",
      "Epoch 510/1000\n",
      "9021/9021 [==============================] - 0s 33us/sample - loss: 1.4839 - mae: 0.9763 - mse: 1.4839 - val_loss: 1.5023 - val_mae: 0.9852 - val_mse: 1.5023\n",
      "Epoch 511/1000\n",
      "9021/9021 [==============================] - 0s 31us/sample - loss: 1.4828 - mae: 0.9759 - mse: 1.4828 - val_loss: 1.5070 - val_mae: 0.9928 - val_mse: 1.5070\n",
      "Epoch 512/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.4844 - mae: 0.9753 - mse: 1.4844 - val_loss: 1.5039 - val_mae: 0.9919 - val_mse: 1.5039\n",
      "Epoch 513/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.4814 - mae: 0.9754 - mse: 1.4814 - val_loss: 1.4973 - val_mae: 0.9851 - val_mse: 1.4973\n",
      "Epoch 514/1000\n",
      "9021/9021 [==============================] - 0s 25us/sample - loss: 1.4817 - mae: 0.9745 - mse: 1.4817 - val_loss: 1.5083 - val_mae: 0.9845 - val_mse: 1.5083\n",
      "Epoch 515/1000\n",
      "9021/9021 [==============================] - 0s 28us/sample - loss: 1.4839 - mae: 0.9762 - mse: 1.4839 - val_loss: 1.4967 - val_mae: 0.9832 - val_mse: 1.4967\n",
      "Epoch 516/1000\n",
      "9021/9021 [==============================] - 0s 28us/sample - loss: 1.4832 - mae: 0.9761 - mse: 1.4832 - val_loss: 1.4966 - val_mae: 0.9813 - val_mse: 1.4966\n",
      "Epoch 517/1000\n",
      "9021/9021 [==============================] - 0s 24us/sample - loss: 1.4809 - mae: 0.9746 - mse: 1.4809 - val_loss: 1.4975 - val_mae: 0.9843 - val_mse: 1.4975\n",
      "Epoch 518/1000\n",
      "9021/9021 [==============================] - 0s 25us/sample - loss: 1.4836 - mae: 0.9765 - mse: 1.4836 - val_loss: 1.5015 - val_mae: 0.9892 - val_mse: 1.5015\n",
      "Epoch 519/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.4809 - mae: 0.9743 - mse: 1.4809 - val_loss: 1.5095 - val_mae: 0.9803 - val_mse: 1.5095\n",
      "Epoch 520/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.4837 - mae: 0.9750 - mse: 1.4837 - val_loss: 1.4991 - val_mae: 0.9805 - val_mse: 1.4991\n",
      "Epoch 521/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.4831 - mae: 0.9760 - mse: 1.4831 - val_loss: 1.4978 - val_mae: 0.9858 - val_mse: 1.4978\n",
      "Epoch 522/1000\n",
      "9021/9021 [==============================] - 0s 30us/sample - loss: 1.4840 - mae: 0.9762 - mse: 1.4840 - val_loss: 1.5129 - val_mae: 0.9832 - val_mse: 1.5129\n",
      "Epoch 523/1000\n",
      "9021/9021 [==============================] - 0s 30us/sample - loss: 1.4823 - mae: 0.9752 - mse: 1.4823 - val_loss: 1.5085 - val_mae: 0.9940 - val_mse: 1.5085\n",
      "Epoch 524/1000\n",
      "9021/9021 [==============================] - 0s 27us/sample - loss: 1.4827 - mae: 0.9753 - mse: 1.4827 - val_loss: 1.5003 - val_mae: 0.9913 - val_mse: 1.5003\n",
      "Epoch 525/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.4818 - mae: 0.9749 - mse: 1.4818 - val_loss: 1.4991 - val_mae: 0.9894 - val_mse: 1.4991\n",
      "Epoch 526/1000\n",
      "9021/9021 [==============================] - 0s 25us/sample - loss: 1.4813 - mae: 0.9745 - mse: 1.4813 - val_loss: 1.4979 - val_mae: 0.9874 - val_mse: 1.4979\n",
      "Epoch 527/1000\n",
      "9021/9021 [==============================] - 0s 29us/sample - loss: 1.4835 - mae: 0.9767 - mse: 1.4835 - val_loss: 1.4972 - val_mae: 0.9826 - val_mse: 1.4972\n",
      "Epoch 528/1000\n",
      "9021/9021 [==============================] - 0s 29us/sample - loss: 1.4819 - mae: 0.9750 - mse: 1.4819 - val_loss: 1.5294 - val_mae: 0.9842 - val_mse: 1.5294\n",
      "Epoch 529/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.4815 - mae: 0.9750 - mse: 1.4815 - val_loss: 1.5008 - val_mae: 0.9865 - val_mse: 1.5008\n",
      "Epoch 530/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.4809 - mae: 0.9745 - mse: 1.4809 - val_loss: 1.4940 - val_mae: 0.9877 - val_mse: 1.4940\n",
      "Epoch 531/1000\n",
      "9021/9021 [==============================] - 0s 44us/sample - loss: 1.4820 - mae: 0.9744 - mse: 1.4820 - val_loss: 1.5022 - val_mae: 0.9871 - val_mse: 1.5022\n",
      "Epoch 532/1000\n",
      "9021/9021 [==============================] - 0s 30us/sample - loss: 1.4829 - mae: 0.9755 - mse: 1.4829 - val_loss: 1.5037 - val_mae: 0.9869 - val_mse: 1.5037\n",
      "Epoch 533/1000\n",
      "9021/9021 [==============================] - 0s 33us/sample - loss: 1.4805 - mae: 0.9751 - mse: 1.4805 - val_loss: 1.5081 - val_mae: 0.9857 - val_mse: 1.5081\n",
      "Epoch 534/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.4803 - mae: 0.9738 - mse: 1.4803 - val_loss: 1.5097 - val_mae: 0.9854 - val_mse: 1.5097\n",
      "Epoch 535/1000\n",
      "9021/9021 [==============================] - 0s 25us/sample - loss: 1.4818 - mae: 0.9752 - mse: 1.4818 - val_loss: 1.4996 - val_mae: 0.9850 - val_mse: 1.4996\n",
      "Epoch 536/1000\n",
      "9021/9021 [==============================] - 0s 28us/sample - loss: 1.4853 - mae: 0.9751 - mse: 1.4853 - val_loss: 1.4994 - val_mae: 0.9853 - val_mse: 1.4994\n",
      "Epoch 537/1000\n",
      "9021/9021 [==============================] - 0s 28us/sample - loss: 1.4833 - mae: 0.9757 - mse: 1.4833 - val_loss: 1.4981 - val_mae: 0.9870 - val_mse: 1.4981\n",
      "Epoch 538/1000\n",
      "9021/9021 [==============================] - 0s 28us/sample - loss: 1.4838 - mae: 0.9757 - mse: 1.4838 - val_loss: 1.4951 - val_mae: 0.9904 - val_mse: 1.4951\n",
      "Epoch 539/1000\n",
      "9021/9021 [==============================] - 0s 37us/sample - loss: 1.4831 - mae: 0.9766 - mse: 1.4831 - val_loss: 1.5053 - val_mae: 0.9817 - val_mse: 1.5053\n",
      "Epoch 540/1000\n",
      "9021/9021 [==============================] - 0s 33us/sample - loss: 1.4841 - mae: 0.9753 - mse: 1.4841 - val_loss: 1.5102 - val_mae: 0.9897 - val_mse: 1.5102\n",
      "Epoch 541/1000\n",
      "9021/9021 [==============================] - 0s 33us/sample - loss: 1.4818 - mae: 0.9754 - mse: 1.4818 - val_loss: 1.5109 - val_mae: 0.9916 - val_mse: 1.5109\n",
      "Epoch 542/1000\n",
      "9021/9021 [==============================] - 0s 27us/sample - loss: 1.4800 - mae: 0.9739 - mse: 1.4800 - val_loss: 1.5034 - val_mae: 0.9848 - val_mse: 1.5034\n",
      "Epoch 543/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.4834 - mae: 0.9771 - mse: 1.4834 - val_loss: 1.5097 - val_mae: 0.9802 - val_mse: 1.5097\n",
      "Epoch 544/1000\n",
      "9021/9021 [==============================] - 0s 30us/sample - loss: 1.4826 - mae: 0.9750 - mse: 1.4826 - val_loss: 1.5126 - val_mae: 0.9875 - val_mse: 1.5126\n",
      "Epoch 545/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.4804 - mae: 0.9745 - mse: 1.4804 - val_loss: 1.5002 - val_mae: 0.9781 - val_mse: 1.5002\n",
      "Epoch 546/1000\n",
      "9021/9021 [==============================] - 0s 36us/sample - loss: 1.4829 - mae: 0.9755 - mse: 1.4829 - val_loss: 1.5024 - val_mae: 0.9863 - val_mse: 1.5024\n",
      "Epoch 547/1000\n",
      "9021/9021 [==============================] - 0s 33us/sample - loss: 1.4798 - mae: 0.9738 - mse: 1.4798 - val_loss: 1.5115 - val_mae: 0.9854 - val_mse: 1.5115\n",
      "Epoch 548/1000\n",
      "9021/9021 [==============================] - 0s 40us/sample - loss: 1.4828 - mae: 0.9743 - mse: 1.4828 - val_loss: 1.5115 - val_mae: 0.9836 - val_mse: 1.5115\n",
      "Epoch 549/1000\n",
      "9021/9021 [==============================] - 0s 49us/sample - loss: 1.4821 - mae: 0.9753 - mse: 1.4821 - val_loss: 1.5004 - val_mae: 0.9882 - val_mse: 1.5004\n",
      "Epoch 550/1000\n",
      "9021/9021 [==============================] - 0s 48us/sample - loss: 1.4828 - mae: 0.9762 - mse: 1.4828 - val_loss: 1.5072 - val_mae: 0.9805 - val_mse: 1.5072\n",
      "Epoch 551/1000\n",
      "9021/9021 [==============================] - 0s 34us/sample - loss: 1.4840 - mae: 0.9756 - mse: 1.4840 - val_loss: 1.4980 - val_mae: 0.9820 - val_mse: 1.4980\n",
      "Epoch 552/1000\n",
      "9021/9021 [==============================] - 0s 42us/sample - loss: 1.4793 - mae: 0.9740 - mse: 1.4793 - val_loss: 1.5059 - val_mae: 0.9883 - val_mse: 1.5059\n",
      "Epoch 553/1000\n",
      "9021/9021 [==============================] - 0s 42us/sample - loss: 1.4825 - mae: 0.9756 - mse: 1.4825 - val_loss: 1.5015 - val_mae: 0.9912 - val_mse: 1.5015\n",
      "Epoch 554/1000\n",
      "9021/9021 [==============================] - 0s 30us/sample - loss: 1.4836 - mae: 0.9765 - mse: 1.4836 - val_loss: 1.4907 - val_mae: 0.9816 - val_mse: 1.4907\n",
      "Epoch 555/1000\n",
      "9021/9021 [==============================] - 0s 50us/sample - loss: 1.4798 - mae: 0.9748 - mse: 1.4798 - val_loss: 1.5186 - val_mae: 0.9820 - val_mse: 1.5186\n",
      "Epoch 556/1000\n",
      "9021/9021 [==============================] - 0s 40us/sample - loss: 1.4813 - mae: 0.9754 - mse: 1.4813 - val_loss: 1.5004 - val_mae: 0.9905 - val_mse: 1.5004\n",
      "Epoch 557/1000\n",
      "9021/9021 [==============================] - 0s 31us/sample - loss: 1.4814 - mae: 0.9741 - mse: 1.4814 - val_loss: 1.5021 - val_mae: 0.9862 - val_mse: 1.5021\n",
      "Epoch 558/1000\n",
      "9021/9021 [==============================] - 0s 40us/sample - loss: 1.4811 - mae: 0.9741 - mse: 1.4811 - val_loss: 1.5059 - val_mae: 0.9912 - val_mse: 1.5059\n",
      "Epoch 559/1000\n",
      "9021/9021 [==============================] - 0s 33us/sample - loss: 1.4820 - mae: 0.9759 - mse: 1.4820 - val_loss: 1.5071 - val_mae: 0.9838 - val_mse: 1.5071\n",
      "Epoch 560/1000\n",
      "9021/9021 [==============================] - 0s 31us/sample - loss: 1.4846 - mae: 0.9759 - mse: 1.4846 - val_loss: 1.5050 - val_mae: 0.9815 - val_mse: 1.5050\n",
      "Epoch 561/1000\n",
      "9021/9021 [==============================] - 0s 40us/sample - loss: 1.4824 - mae: 0.9744 - mse: 1.4824 - val_loss: 1.5110 - val_mae: 0.9789 - val_mse: 1.5110\n",
      "Epoch 562/1000\n",
      "9021/9021 [==============================] - 1s 59us/sample - loss: 1.4830 - mae: 0.9747 - mse: 1.4830 - val_loss: 1.5150 - val_mae: 0.9946 - val_mse: 1.5150\n",
      "Epoch 563/1000\n",
      "9021/9021 [==============================] - 0s 33us/sample - loss: 1.4826 - mae: 0.9753 - mse: 1.4826 - val_loss: 1.5084 - val_mae: 0.9934 - val_mse: 1.5084\n",
      "Epoch 564/1000\n",
      "9021/9021 [==============================] - 0s 27us/sample - loss: 1.4831 - mae: 0.9762 - mse: 1.4831 - val_loss: 1.4944 - val_mae: 0.9802 - val_mse: 1.4944\n",
      "Epoch 565/1000\n",
      "9021/9021 [==============================] - 0s 43us/sample - loss: 1.4829 - mae: 0.9761 - mse: 1.4829 - val_loss: 1.4983 - val_mae: 0.9838 - val_mse: 1.4983\n",
      "Epoch 566/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9021/9021 [==============================] - 0s 39us/sample - loss: 1.4788 - mae: 0.9748 - mse: 1.4788 - val_loss: 1.5110 - val_mae: 0.9900 - val_mse: 1.5110\n",
      "Epoch 567/1000\n",
      "9021/9021 [==============================] - 0s 47us/sample - loss: 1.4826 - mae: 0.9759 - mse: 1.4826 - val_loss: 1.4974 - val_mae: 0.9874 - val_mse: 1.4974\n",
      "Epoch 568/1000\n",
      "9021/9021 [==============================] - 0s 44us/sample - loss: 1.4831 - mae: 0.9760 - mse: 1.4831 - val_loss: 1.5097 - val_mae: 0.9838 - val_mse: 1.5097\n",
      "Epoch 569/1000\n",
      "9021/9021 [==============================] - 0s 27us/sample - loss: 1.4781 - mae: 0.9742 - mse: 1.4781 - val_loss: 1.5222 - val_mae: 0.9990 - val_mse: 1.5222\n",
      "Epoch 570/1000\n",
      "9021/9021 [==============================] - 0s 43us/sample - loss: 1.4848 - mae: 0.9770 - mse: 1.4848 - val_loss: 1.5044 - val_mae: 0.9914 - val_mse: 1.5044\n",
      "Epoch 571/1000\n",
      "9021/9021 [==============================] - 0s 54us/sample - loss: 1.4814 - mae: 0.9752 - mse: 1.4814 - val_loss: 1.5117 - val_mae: 0.9832 - val_mse: 1.5117\n",
      "Epoch 572/1000\n",
      "9021/9021 [==============================] - 0s 41us/sample - loss: 1.4787 - mae: 0.9731 - mse: 1.4787 - val_loss: 1.4942 - val_mae: 0.9872 - val_mse: 1.4942\n",
      "Epoch 573/1000\n",
      "9021/9021 [==============================] - 0s 40us/sample - loss: 1.4819 - mae: 0.9754 - mse: 1.4819 - val_loss: 1.5022 - val_mae: 0.9844 - val_mse: 1.5022\n",
      "Epoch 574/1000\n",
      "9021/9021 [==============================] - 0s 38us/sample - loss: 1.4831 - mae: 0.9750 - mse: 1.4831 - val_loss: 1.4989 - val_mae: 0.9834 - val_mse: 1.4989\n",
      "Epoch 575/1000\n",
      "9021/9021 [==============================] - 0s 41us/sample - loss: 1.4815 - mae: 0.9756 - mse: 1.4815 - val_loss: 1.5085 - val_mae: 0.9916 - val_mse: 1.5085\n",
      "Epoch 576/1000\n",
      "9021/9021 [==============================] - 0s 42us/sample - loss: 1.4821 - mae: 0.9763 - mse: 1.4821 - val_loss: 1.5031 - val_mae: 0.9831 - val_mse: 1.5031\n",
      "Epoch 577/1000\n",
      "9021/9021 [==============================] - 1s 73us/sample - loss: 1.4827 - mae: 0.9753 - mse: 1.4827 - val_loss: 1.5009 - val_mae: 0.9872 - val_mse: 1.5009\n",
      "Epoch 578/1000\n",
      "9021/9021 [==============================] - 0s 55us/sample - loss: 1.4805 - mae: 0.9751 - mse: 1.4805 - val_loss: 1.4976 - val_mae: 0.9843 - val_mse: 1.4976\n",
      "Epoch 579/1000\n",
      "9021/9021 [==============================] - 0s 47us/sample - loss: 1.4814 - mae: 0.9755 - mse: 1.4814 - val_loss: 1.5058 - val_mae: 0.9838 - val_mse: 1.5058\n",
      "Epoch 580/1000\n",
      "9021/9021 [==============================] - 0s 42us/sample - loss: 1.4811 - mae: 0.9758 - mse: 1.4811 - val_loss: 1.5061 - val_mae: 0.9866 - val_mse: 1.5061\n",
      "Epoch 581/1000\n",
      "9021/9021 [==============================] - 1s 56us/sample - loss: 1.4801 - mae: 0.9741 - mse: 1.4801 - val_loss: 1.5019 - val_mae: 0.9821 - val_mse: 1.5019\n",
      "Epoch 582/1000\n",
      "9021/9021 [==============================] - 0s 49us/sample - loss: 1.4820 - mae: 0.9735 - mse: 1.4820 - val_loss: 1.5179 - val_mae: 0.9838 - val_mse: 1.5179\n",
      "Epoch 583/1000\n",
      "9021/9021 [==============================] - 0s 44us/sample - loss: 1.4828 - mae: 0.9742 - mse: 1.4828 - val_loss: 1.5039 - val_mae: 0.9865 - val_mse: 1.5039\n",
      "Epoch 584/1000\n",
      "9021/9021 [==============================] - 0s 51us/sample - loss: 1.4831 - mae: 0.9752 - mse: 1.4831 - val_loss: 1.5043 - val_mae: 0.9868 - val_mse: 1.5043\n",
      "Epoch 585/1000\n",
      "9021/9021 [==============================] - 0s 52us/sample - loss: 1.4817 - mae: 0.9755 - mse: 1.4817 - val_loss: 1.5011 - val_mae: 0.9797 - val_mse: 1.5011\n",
      "Epoch 586/1000\n",
      "9021/9021 [==============================] - 1s 58us/sample - loss: 1.4802 - mae: 0.9746 - mse: 1.4802 - val_loss: 1.5055 - val_mae: 0.9862 - val_mse: 1.5055\n",
      "Epoch 587/1000\n",
      "9021/9021 [==============================] - 0s 44us/sample - loss: 1.4831 - mae: 0.9754 - mse: 1.4831 - val_loss: 1.5050 - val_mae: 0.9888 - val_mse: 1.5050\n",
      "Epoch 588/1000\n",
      "9021/9021 [==============================] - 0s 51us/sample - loss: 1.4809 - mae: 0.9742 - mse: 1.4809 - val_loss: 1.5035 - val_mae: 0.9855 - val_mse: 1.5035\n",
      "Epoch 589/1000\n",
      "9021/9021 [==============================] - 0s 45us/sample - loss: 1.4803 - mae: 0.9742 - mse: 1.4803 - val_loss: 1.5106 - val_mae: 0.9808 - val_mse: 1.5106\n",
      "Epoch 590/1000\n",
      "9021/9021 [==============================] - 0s 43us/sample - loss: 1.4799 - mae: 0.9747 - mse: 1.4799 - val_loss: 1.5012 - val_mae: 0.9837 - val_mse: 1.5012\n",
      "Epoch 591/1000\n",
      "9021/9021 [==============================] - 0s 42us/sample - loss: 1.4821 - mae: 0.9739 - mse: 1.4821 - val_loss: 1.5073 - val_mae: 0.9799 - val_mse: 1.5073\n",
      "Epoch 592/1000\n",
      "9021/9021 [==============================] - 0s 36us/sample - loss: 1.4808 - mae: 0.9759 - mse: 1.4808 - val_loss: 1.5076 - val_mae: 0.9930 - val_mse: 1.5076\n",
      "Epoch 593/1000\n",
      "9021/9021 [==============================] - 0s 30us/sample - loss: 1.4817 - mae: 0.9757 - mse: 1.4817 - val_loss: 1.4960 - val_mae: 0.9816 - val_mse: 1.4960\n",
      "Epoch 594/1000\n",
      "9021/9021 [==============================] - 0s 32us/sample - loss: 1.4811 - mae: 0.9744 - mse: 1.4811 - val_loss: 1.4965 - val_mae: 0.9849 - val_mse: 1.4965\n",
      "Epoch 595/1000\n",
      "9021/9021 [==============================] - 0s 29us/sample - loss: 1.4809 - mae: 0.9758 - mse: 1.4809 - val_loss: 1.5153 - val_mae: 0.9989 - val_mse: 1.5153\n",
      "Epoch 596/1000\n",
      "9021/9021 [==============================] - 0s 30us/sample - loss: 1.4811 - mae: 0.9758 - mse: 1.4811 - val_loss: 1.5076 - val_mae: 0.9816 - val_mse: 1.5076\n",
      "Epoch 597/1000\n",
      "9021/9021 [==============================] - 0s 29us/sample - loss: 1.4826 - mae: 0.9750 - mse: 1.4826 - val_loss: 1.5084 - val_mae: 0.9834 - val_mse: 1.5084\n",
      "Epoch 598/1000\n",
      "9021/9021 [==============================] - 0s 30us/sample - loss: 1.4817 - mae: 0.9751 - mse: 1.4817 - val_loss: 1.4979 - val_mae: 0.9823 - val_mse: 1.4979\n",
      "Epoch 599/1000\n",
      "9021/9021 [==============================] - 0s 28us/sample - loss: 1.4817 - mae: 0.9741 - mse: 1.4817 - val_loss: 1.5085 - val_mae: 0.9818 - val_mse: 1.5085\n",
      "Epoch 600/1000\n",
      "9021/9021 [==============================] - 0s 41us/sample - loss: 1.4801 - mae: 0.9750 - mse: 1.4801 - val_loss: 1.5169 - val_mae: 0.9873 - val_mse: 1.5169\n",
      "Epoch 601/1000\n",
      "9021/9021 [==============================] - 0s 43us/sample - loss: 1.4826 - mae: 0.9747 - mse: 1.4826 - val_loss: 1.4967 - val_mae: 0.9801 - val_mse: 1.4967\n",
      "Epoch 602/1000\n",
      "9021/9021 [==============================] - 0s 49us/sample - loss: 1.4803 - mae: 0.9729 - mse: 1.4803 - val_loss: 1.5050 - val_mae: 0.9912 - val_mse: 1.5050\n",
      "Epoch 603/1000\n",
      "9021/9021 [==============================] - 0s 44us/sample - loss: 1.4819 - mae: 0.9745 - mse: 1.4819 - val_loss: 1.4962 - val_mae: 0.9866 - val_mse: 1.4962\n",
      "Epoch 604/1000\n",
      "9021/9021 [==============================] - 0s 41us/sample - loss: 1.4824 - mae: 0.9752 - mse: 1.4824 - val_loss: 1.5052 - val_mae: 0.9853 - val_mse: 1.5052\n",
      "Epoch 605/1000\n",
      "9021/9021 [==============================] - 1s 59us/sample - loss: 1.4823 - mae: 0.9754 - mse: 1.4823 - val_loss: 1.5120 - val_mae: 0.9924 - val_mse: 1.5120\n",
      "Epoch 606/1000\n",
      "9021/9021 [==============================] - 0s 49us/sample - loss: 1.4801 - mae: 0.9738 - mse: 1.4801 - val_loss: 1.5214 - val_mae: 0.9922 - val_mse: 1.5214\n",
      "Epoch 607/1000\n",
      "9021/9021 [==============================] - 0s 31us/sample - loss: 1.4817 - mae: 0.9745 - mse: 1.4817 - val_loss: 1.5186 - val_mae: 0.9832 - val_mse: 1.5186\n",
      "Epoch 608/1000\n",
      "9021/9021 [==============================] - 0s 23us/sample - loss: 1.4813 - mae: 0.9742 - mse: 1.4813 - val_loss: 1.5182 - val_mae: 0.9947 - val_mse: 1.5182\n",
      "Epoch 609/1000\n",
      "9021/9021 [==============================] - 0s 39us/sample - loss: 1.4789 - mae: 0.9756 - mse: 1.4789 - val_loss: 1.5204 - val_mae: 0.9780 - val_mse: 1.5204\n",
      "Epoch 610/1000\n",
      "9021/9021 [==============================] - 0s 40us/sample - loss: 1.4831 - mae: 0.9749 - mse: 1.4831 - val_loss: 1.5075 - val_mae: 0.9815 - val_mse: 1.5075\n",
      "Epoch 611/1000\n",
      "9021/9021 [==============================] - 0s 35us/sample - loss: 1.4816 - mae: 0.9741 - mse: 1.4816 - val_loss: 1.5088 - val_mae: 0.9868 - val_mse: 1.5088\n",
      "Epoch 612/1000\n",
      "9021/9021 [==============================] - 0s 45us/sample - loss: 1.4819 - mae: 0.9749 - mse: 1.4819 - val_loss: 1.5075 - val_mae: 0.9882 - val_mse: 1.5075\n",
      "Epoch 613/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9021/9021 [==============================] - 0s 39us/sample - loss: 1.4803 - mae: 0.9734 - mse: 1.4803 - val_loss: 1.5202 - val_mae: 0.9991 - val_mse: 1.5202\n",
      "Epoch 614/1000\n",
      "9021/9021 [==============================] - 0s 38us/sample - loss: 1.4821 - mae: 0.9760 - mse: 1.4821 - val_loss: 1.5080 - val_mae: 0.9847 - val_mse: 1.5080\n",
      "Epoch 615/1000\n",
      "9021/9021 [==============================] - 0s 40us/sample - loss: 1.4803 - mae: 0.9733 - mse: 1.4803 - val_loss: 1.5104 - val_mae: 0.9960 - val_mse: 1.5104\n",
      "Epoch 616/1000\n",
      "9021/9021 [==============================] - 0s 37us/sample - loss: 1.4826 - mae: 0.9764 - mse: 1.4826 - val_loss: 1.5052 - val_mae: 0.9896 - val_mse: 1.5052\n",
      "Epoch 617/1000\n",
      "9021/9021 [==============================] - 0s 34us/sample - loss: 1.4814 - mae: 0.9743 - mse: 1.4814 - val_loss: 1.5025 - val_mae: 0.9859 - val_mse: 1.5025\n",
      "Epoch 618/1000\n",
      "9021/9021 [==============================] - 0s 45us/sample - loss: 1.4830 - mae: 0.9756 - mse: 1.4830 - val_loss: 1.5095 - val_mae: 0.9857 - val_mse: 1.5095\n",
      "Epoch 619/1000\n",
      "9021/9021 [==============================] - 0s 37us/sample - loss: 1.4800 - mae: 0.9752 - mse: 1.4800 - val_loss: 1.4957 - val_mae: 0.9870 - val_mse: 1.4957\n",
      "Epoch 620/1000\n",
      "9021/9021 [==============================] - 0s 37us/sample - loss: 1.4798 - mae: 0.9744 - mse: 1.4798 - val_loss: 1.4949 - val_mae: 0.9878 - val_mse: 1.4949\n",
      "Epoch 621/1000\n",
      "9021/9021 [==============================] - 0s 35us/sample - loss: 1.4834 - mae: 0.9759 - mse: 1.4834 - val_loss: 1.5148 - val_mae: 0.9809 - val_mse: 1.5148\n",
      "Epoch 622/1000\n",
      "9021/9021 [==============================] - 0s 43us/sample - loss: 1.4793 - mae: 0.9743 - mse: 1.4793 - val_loss: 1.5072 - val_mae: 0.9909 - val_mse: 1.5072\n",
      "Epoch 623/1000\n",
      "9021/9021 [==============================] - 0s 38us/sample - loss: 1.4807 - mae: 0.9749 - mse: 1.4807 - val_loss: 1.5200 - val_mae: 0.9880 - val_mse: 1.5200\n",
      "Epoch 624/1000\n",
      "9021/9021 [==============================] - 0s 39us/sample - loss: 1.4823 - mae: 0.9753 - mse: 1.4823 - val_loss: 1.5065 - val_mae: 0.9880 - val_mse: 1.5065\n",
      "Epoch 625/1000\n",
      "9021/9021 [==============================] - 0s 38us/sample - loss: 1.4803 - mae: 0.9748 - mse: 1.4803 - val_loss: 1.5053 - val_mae: 0.9816 - val_mse: 1.5053\n",
      "Epoch 626/1000\n",
      "9021/9021 [==============================] - 0s 28us/sample - loss: 1.4818 - mae: 0.9754 - mse: 1.4818 - val_loss: 1.5072 - val_mae: 0.9887 - val_mse: 1.5072\n",
      "Epoch 627/1000\n",
      "9021/9021 [==============================] - 0s 32us/sample - loss: 1.4798 - mae: 0.9747 - mse: 1.4798 - val_loss: 1.5046 - val_mae: 0.9908 - val_mse: 1.5046\n",
      "Epoch 628/1000\n",
      "9021/9021 [==============================] - 0s 27us/sample - loss: 1.4816 - mae: 0.9758 - mse: 1.4816 - val_loss: 1.4933 - val_mae: 0.9832 - val_mse: 1.4933\n",
      "Epoch 629/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.4807 - mae: 0.9744 - mse: 1.4807 - val_loss: 1.5019 - val_mae: 0.9820 - val_mse: 1.5019\n",
      "Epoch 630/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.4801 - mae: 0.9752 - mse: 1.4801 - val_loss: 1.4964 - val_mae: 0.9831 - val_mse: 1.4964\n",
      "Epoch 631/1000\n",
      "9021/9021 [==============================] - 0s 30us/sample - loss: 1.4810 - mae: 0.9745 - mse: 1.4810 - val_loss: 1.5044 - val_mae: 0.9928 - val_mse: 1.5044\n",
      "Epoch 632/1000\n",
      "9021/9021 [==============================] - 0s 30us/sample - loss: 1.4811 - mae: 0.9760 - mse: 1.4811 - val_loss: 1.5144 - val_mae: 0.9856 - val_mse: 1.5144\n",
      "Epoch 633/1000\n",
      "9021/9021 [==============================] - 0s 24us/sample - loss: 1.4832 - mae: 0.9754 - mse: 1.4832 - val_loss: 1.5047 - val_mae: 0.9853 - val_mse: 1.5047\n",
      "Epoch 634/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.4803 - mae: 0.9739 - mse: 1.4803 - val_loss: 1.5015 - val_mae: 0.9936 - val_mse: 1.5015\n",
      "Epoch 635/1000\n",
      "9021/9021 [==============================] - 0s 43us/sample - loss: 1.4801 - mae: 0.9748 - mse: 1.4801 - val_loss: 1.5004 - val_mae: 0.9832 - val_mse: 1.5004\n",
      "Epoch 636/1000\n",
      "9021/9021 [==============================] - 0s 39us/sample - loss: 1.4811 - mae: 0.9734 - mse: 1.4811 - val_loss: 1.5000 - val_mae: 0.9864 - val_mse: 1.5000\n",
      "Epoch 637/1000\n",
      "9021/9021 [==============================] - 0s 36us/sample - loss: 1.4809 - mae: 0.9742 - mse: 1.4809 - val_loss: 1.5119 - val_mae: 0.9807 - val_mse: 1.5119\n",
      "Epoch 638/1000\n",
      "9021/9021 [==============================] - 0s 50us/sample - loss: 1.4812 - mae: 0.9756 - mse: 1.4812 - val_loss: 1.5003 - val_mae: 0.9905 - val_mse: 1.5003\n",
      "Epoch 639/1000\n",
      "9021/9021 [==============================] - 0s 45us/sample - loss: 1.4814 - mae: 0.9746 - mse: 1.4814 - val_loss: 1.5081 - val_mae: 0.9940 - val_mse: 1.5081\n",
      "Epoch 640/1000\n",
      "9021/9021 [==============================] - 0s 47us/sample - loss: 1.4832 - mae: 0.9763 - mse: 1.4832 - val_loss: 1.4995 - val_mae: 0.9902 - val_mse: 1.4995\n",
      "Epoch 641/1000\n",
      "9021/9021 [==============================] - 0s 48us/sample - loss: 1.4782 - mae: 0.9738 - mse: 1.4782 - val_loss: 1.5046 - val_mae: 0.9832 - val_mse: 1.5046\n",
      "Epoch 642/1000\n",
      "9021/9021 [==============================] - 0s 30us/sample - loss: 1.4798 - mae: 0.9744 - mse: 1.4798 - val_loss: 1.4972 - val_mae: 0.9804 - val_mse: 1.4972\n",
      "Epoch 643/1000\n",
      "9021/9021 [==============================] - 0s 36us/sample - loss: 1.4795 - mae: 0.9741 - mse: 1.4795 - val_loss: 1.5075 - val_mae: 0.9882 - val_mse: 1.5075\n",
      "Epoch 644/1000\n",
      "9021/9021 [==============================] - 0s 33us/sample - loss: 1.4823 - mae: 0.9749 - mse: 1.4823 - val_loss: 1.4993 - val_mae: 0.9865 - val_mse: 1.4993\n",
      "Epoch 645/1000\n",
      "9021/9021 [==============================] - 0s 30us/sample - loss: 1.4808 - mae: 0.9744 - mse: 1.4808 - val_loss: 1.4982 - val_mae: 0.9869 - val_mse: 1.4982\n",
      "Epoch 646/1000\n",
      "9021/9021 [==============================] - 0s 37us/sample - loss: 1.4795 - mae: 0.9748 - mse: 1.4795 - val_loss: 1.4992 - val_mae: 0.9824 - val_mse: 1.4992\n",
      "Epoch 647/1000\n",
      "9021/9021 [==============================] - 0s 34us/sample - loss: 1.4805 - mae: 0.9743 - mse: 1.4805 - val_loss: 1.5081 - val_mae: 0.9870 - val_mse: 1.5081\n",
      "Epoch 648/1000\n",
      "9021/9021 [==============================] - 0s 32us/sample - loss: 1.4801 - mae: 0.9746 - mse: 1.4801 - val_loss: 1.5213 - val_mae: 0.9763 - val_mse: 1.5213\n",
      "Epoch 649/1000\n",
      "9021/9021 [==============================] - 0s 38us/sample - loss: 1.4814 - mae: 0.9740 - mse: 1.4814 - val_loss: 1.5084 - val_mae: 0.9854 - val_mse: 1.5084\n",
      "Epoch 650/1000\n",
      "9021/9021 [==============================] - 0s 43us/sample - loss: 1.4813 - mae: 0.9752 - mse: 1.4813 - val_loss: 1.5233 - val_mae: 0.9816 - val_mse: 1.5233\n",
      "Epoch 651/1000\n",
      "9021/9021 [==============================] - 0s 47us/sample - loss: 1.4776 - mae: 0.9724 - mse: 1.4776 - val_loss: 1.5104 - val_mae: 0.9846 - val_mse: 1.5104\n",
      "Epoch 652/1000\n",
      "9021/9021 [==============================] - 1s 63us/sample - loss: 1.4786 - mae: 0.9737 - mse: 1.4786 - val_loss: 1.5018 - val_mae: 0.9917 - val_mse: 1.5018\n",
      "Epoch 653/1000\n",
      "9021/9021 [==============================] - 0s 39us/sample - loss: 1.4830 - mae: 0.9767 - mse: 1.4830 - val_loss: 1.5054 - val_mae: 0.9848 - val_mse: 1.5054\n",
      "Epoch 654/1000\n",
      "9021/9021 [==============================] - 0s 46us/sample - loss: 1.4788 - mae: 0.9733 - mse: 1.4788 - val_loss: 1.5195 - val_mae: 0.9806 - val_mse: 1.5195\n",
      "Epoch 655/1000\n",
      "9021/9021 [==============================] - 0s 42us/sample - loss: 1.4809 - mae: 0.9755 - mse: 1.4809 - val_loss: 1.5155 - val_mae: 0.9819 - val_mse: 1.5155\n",
      "Epoch 656/1000\n",
      "9021/9021 [==============================] - 0s 46us/sample - loss: 1.4785 - mae: 0.9726 - mse: 1.4785 - val_loss: 1.4978 - val_mae: 0.9839 - val_mse: 1.4978\n",
      "Epoch 657/1000\n",
      "9021/9021 [==============================] - 0s 34us/sample - loss: 1.4813 - mae: 0.9749 - mse: 1.4813 - val_loss: 1.5024 - val_mae: 0.9894 - val_mse: 1.5024\n",
      "Epoch 658/1000\n",
      "9021/9021 [==============================] - 0s 33us/sample - loss: 1.4820 - mae: 0.9752 - mse: 1.4820 - val_loss: 1.5068 - val_mae: 0.9891 - val_mse: 1.5068\n",
      "Epoch 659/1000\n",
      "9021/9021 [==============================] - 0s 27us/sample - loss: 1.4806 - mae: 0.9748 - mse: 1.4806 - val_loss: 1.5088 - val_mae: 0.9822 - val_mse: 1.5088\n",
      "Epoch 660/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9021/9021 [==============================] - 0s 28us/sample - loss: 1.4786 - mae: 0.9731 - mse: 1.4786 - val_loss: 1.5007 - val_mae: 0.9878 - val_mse: 1.5007\n",
      "Epoch 661/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.4792 - mae: 0.9737 - mse: 1.4792 - val_loss: 1.5128 - val_mae: 0.9940 - val_mse: 1.5128\n",
      "Epoch 662/1000\n",
      "9021/9021 [==============================] - 0s 27us/sample - loss: 1.4785 - mae: 0.9748 - mse: 1.4785 - val_loss: 1.5092 - val_mae: 0.9846 - val_mse: 1.5092\n",
      "Epoch 663/1000\n",
      "9021/9021 [==============================] - 0s 36us/sample - loss: 1.4824 - mae: 0.9750 - mse: 1.4824 - val_loss: 1.5262 - val_mae: 0.9829 - val_mse: 1.5262\n",
      "Epoch 664/1000\n",
      "9021/9021 [==============================] - 0s 34us/sample - loss: 1.4837 - mae: 0.9758 - mse: 1.4837 - val_loss: 1.5126 - val_mae: 0.9968 - val_mse: 1.5126\n",
      "Epoch 665/1000\n",
      "9021/9021 [==============================] - 0s 33us/sample - loss: 1.4791 - mae: 0.9747 - mse: 1.4791 - val_loss: 1.4989 - val_mae: 0.9871 - val_mse: 1.4989\n",
      "Epoch 666/1000\n",
      "9021/9021 [==============================] - 0s 27us/sample - loss: 1.4794 - mae: 0.9750 - mse: 1.4794 - val_loss: 1.5548 - val_mae: 0.9763 - val_mse: 1.5548\n",
      "Epoch 667/1000\n",
      "9021/9021 [==============================] - 0s 30us/sample - loss: 1.4812 - mae: 0.9742 - mse: 1.4812 - val_loss: 1.5107 - val_mae: 0.9824 - val_mse: 1.5107\n",
      "Epoch 668/1000\n",
      "9021/9021 [==============================] - 0s 41us/sample - loss: 1.4801 - mae: 0.9747 - mse: 1.4801 - val_loss: 1.5018 - val_mae: 0.9922 - val_mse: 1.5018\n",
      "Epoch 669/1000\n",
      "9021/9021 [==============================] - 0s 29us/sample - loss: 1.4808 - mae: 0.9753 - mse: 1.4808 - val_loss: 1.4932 - val_mae: 0.9857 - val_mse: 1.4932\n",
      "Epoch 670/1000\n",
      "9021/9021 [==============================] - 0s 32us/sample - loss: 1.4803 - mae: 0.9745 - mse: 1.4803 - val_loss: 1.4948 - val_mae: 0.9880 - val_mse: 1.4948\n",
      "Epoch 671/1000\n",
      "9021/9021 [==============================] - 0s 29us/sample - loss: 1.4809 - mae: 0.9758 - mse: 1.4809 - val_loss: 1.5264 - val_mae: 0.9785 - val_mse: 1.5264\n",
      "Epoch 672/1000\n",
      "9021/9021 [==============================] - 0s 46us/sample - loss: 1.4817 - mae: 0.9744 - mse: 1.4817 - val_loss: 1.4998 - val_mae: 0.9879 - val_mse: 1.4998\n",
      "Epoch 673/1000\n",
      "9021/9021 [==============================] - 0s 35us/sample - loss: 1.4810 - mae: 0.9750 - mse: 1.4810 - val_loss: 1.5074 - val_mae: 0.9917 - val_mse: 1.5074\n",
      "Epoch 674/1000\n",
      "9021/9021 [==============================] - 0s 34us/sample - loss: 1.4811 - mae: 0.9760 - mse: 1.4811 - val_loss: 1.5099 - val_mae: 0.9860 - val_mse: 1.5099\n",
      "Epoch 675/1000\n",
      "9021/9021 [==============================] - 0s 35us/sample - loss: 1.4807 - mae: 0.9748 - mse: 1.4807 - val_loss: 1.4991 - val_mae: 0.9861 - val_mse: 1.4991\n",
      "Epoch 676/1000\n",
      "9021/9021 [==============================] - 0s 35us/sample - loss: 1.4780 - mae: 0.9736 - mse: 1.4780 - val_loss: 1.5106 - val_mae: 0.9910 - val_mse: 1.5106\n",
      "Epoch 677/1000\n",
      "9021/9021 [==============================] - 0s 31us/sample - loss: 1.4817 - mae: 0.9743 - mse: 1.4817 - val_loss: 1.5038 - val_mae: 0.9873 - val_mse: 1.5038\n",
      "Epoch 678/1000\n",
      "9021/9021 [==============================] - 0s 29us/sample - loss: 1.4799 - mae: 0.9751 - mse: 1.4799 - val_loss: 1.5077 - val_mae: 0.9815 - val_mse: 1.5077\n",
      "Epoch 679/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.4819 - mae: 0.9754 - mse: 1.4819 - val_loss: 1.5024 - val_mae: 0.9826 - val_mse: 1.5024\n",
      "Epoch 680/1000\n",
      "9021/9021 [==============================] - 0s 35us/sample - loss: 1.4786 - mae: 0.9737 - mse: 1.4786 - val_loss: 1.5053 - val_mae: 0.9859 - val_mse: 1.5053\n",
      "Epoch 681/1000\n",
      "9021/9021 [==============================] - 0s 35us/sample - loss: 1.4819 - mae: 0.9758 - mse: 1.4819 - val_loss: 1.5097 - val_mae: 0.9854 - val_mse: 1.5097\n",
      "Epoch 682/1000\n",
      "9021/9021 [==============================] - 0s 44us/sample - loss: 1.4792 - mae: 0.9746 - mse: 1.4792 - val_loss: 1.5160 - val_mae: 0.9820 - val_mse: 1.5160\n",
      "Epoch 683/1000\n",
      "9021/9021 [==============================] - 0s 43us/sample - loss: 1.4794 - mae: 0.9741 - mse: 1.4794 - val_loss: 1.5058 - val_mae: 0.9851 - val_mse: 1.5058\n",
      "Epoch 684/1000\n",
      "9021/9021 [==============================] - 0s 45us/sample - loss: 1.4823 - mae: 0.9763 - mse: 1.4823 - val_loss: 1.5072 - val_mae: 0.9855 - val_mse: 1.5072\n",
      "Epoch 685/1000\n",
      "9021/9021 [==============================] - 0s 33us/sample - loss: 1.4787 - mae: 0.9742 - mse: 1.4787 - val_loss: 1.5037 - val_mae: 0.9871 - val_mse: 1.5037\n",
      "Epoch 686/1000\n",
      "9021/9021 [==============================] - 0s 37us/sample - loss: 1.4797 - mae: 0.9746 - mse: 1.4797 - val_loss: 1.5074 - val_mae: 0.9860 - val_mse: 1.5074\n",
      "Epoch 687/1000\n",
      "9021/9021 [==============================] - 0s 49us/sample - loss: 1.4790 - mae: 0.9739 - mse: 1.4790 - val_loss: 1.5069 - val_mae: 0.9867 - val_mse: 1.5069\n",
      "Epoch 688/1000\n",
      "9021/9021 [==============================] - 0s 33us/sample - loss: 1.4825 - mae: 0.9747 - mse: 1.4825 - val_loss: 1.5133 - val_mae: 0.9856 - val_mse: 1.5133\n",
      "Epoch 689/1000\n",
      "9021/9021 [==============================] - 0s 52us/sample - loss: 1.4799 - mae: 0.9753 - mse: 1.4799 - val_loss: 1.5102 - val_mae: 0.9859 - val_mse: 1.5102\n",
      "Epoch 690/1000\n",
      "9021/9021 [==============================] - 0s 48us/sample - loss: 1.4797 - mae: 0.9723 - mse: 1.4797 - val_loss: 1.4987 - val_mae: 0.9870 - val_mse: 1.4987\n",
      "Epoch 691/1000\n",
      "9021/9021 [==============================] - 1s 59us/sample - loss: 1.4827 - mae: 0.9757 - mse: 1.4827 - val_loss: 1.5082 - val_mae: 0.9918 - val_mse: 1.5082\n",
      "Epoch 692/1000\n",
      "9021/9021 [==============================] - 0s 43us/sample - loss: 1.4783 - mae: 0.9742 - mse: 1.4783 - val_loss: 1.5056 - val_mae: 0.9844 - val_mse: 1.5056\n",
      "Epoch 693/1000\n",
      "9021/9021 [==============================] - 0s 46us/sample - loss: 1.4813 - mae: 0.9747 - mse: 1.4813 - val_loss: 1.5061 - val_mae: 0.9810 - val_mse: 1.5061\n",
      "Epoch 694/1000\n",
      "9021/9021 [==============================] - 0s 45us/sample - loss: 1.4814 - mae: 0.9739 - mse: 1.4814 - val_loss: 1.5145 - val_mae: 0.9910 - val_mse: 1.5145\n",
      "Epoch 695/1000\n",
      "9021/9021 [==============================] - 0s 42us/sample - loss: 1.4810 - mae: 0.9746 - mse: 1.4810 - val_loss: 1.5053 - val_mae: 0.9896 - val_mse: 1.5053\n",
      "Epoch 696/1000\n",
      "9021/9021 [==============================] - 0s 42us/sample - loss: 1.4805 - mae: 0.9749 - mse: 1.4805 - val_loss: 1.5125 - val_mae: 0.9943 - val_mse: 1.5125\n",
      "Epoch 697/1000\n",
      "9021/9021 [==============================] - 0s 35us/sample - loss: 1.4805 - mae: 0.9757 - mse: 1.4805 - val_loss: 1.5123 - val_mae: 0.9902 - val_mse: 1.5123\n",
      "Epoch 698/1000\n",
      "9021/9021 [==============================] - 0s 41us/sample - loss: 1.4799 - mae: 0.9745 - mse: 1.4799 - val_loss: 1.5111 - val_mae: 0.9973 - val_mse: 1.5111\n",
      "Epoch 699/1000\n",
      "9021/9021 [==============================] - 0s 42us/sample - loss: 1.4802 - mae: 0.9751 - mse: 1.4802 - val_loss: 1.5036 - val_mae: 0.9819 - val_mse: 1.5036\n",
      "Epoch 700/1000\n",
      "9021/9021 [==============================] - 0s 40us/sample - loss: 1.4802 - mae: 0.9745 - mse: 1.4802 - val_loss: 1.5057 - val_mae: 0.9838 - val_mse: 1.5057\n",
      "Epoch 701/1000\n",
      "9021/9021 [==============================] - 0s 40us/sample - loss: 1.4793 - mae: 0.9735 - mse: 1.4793 - val_loss: 1.5012 - val_mae: 0.9802 - val_mse: 1.5012\n",
      "Epoch 702/1000\n",
      "9021/9021 [==============================] - 1s 78us/sample - loss: 1.4802 - mae: 0.9740 - mse: 1.4802 - val_loss: 1.5080 - val_mae: 0.9848 - val_mse: 1.5080\n",
      "Epoch 703/1000\n",
      "9021/9021 [==============================] - 0s 54us/sample - loss: 1.4800 - mae: 0.9744 - mse: 1.4800 - val_loss: 1.5087 - val_mae: 0.9820 - val_mse: 1.5087\n",
      "Epoch 704/1000\n",
      "9021/9021 [==============================] - 0s 38us/sample - loss: 1.4787 - mae: 0.9727 - mse: 1.4787 - val_loss: 1.5092 - val_mae: 0.9877 - val_mse: 1.5092\n",
      "Epoch 705/1000\n",
      "9021/9021 [==============================] - 0s 48us/sample - loss: 1.4791 - mae: 0.9739 - mse: 1.4791 - val_loss: 1.5084 - val_mae: 0.9816 - val_mse: 1.5084\n",
      "Epoch 706/1000\n",
      "9021/9021 [==============================] - 0s 48us/sample - loss: 1.4777 - mae: 0.9727 - mse: 1.4777 - val_loss: 1.5199 - val_mae: 0.9798 - val_mse: 1.5199\n",
      "Epoch 707/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9021/9021 [==============================] - 0s 47us/sample - loss: 1.4812 - mae: 0.9745 - mse: 1.4812 - val_loss: 1.5088 - val_mae: 0.9862 - val_mse: 1.5088\n",
      "Epoch 708/1000\n",
      "9021/9021 [==============================] - 0s 37us/sample - loss: 1.4805 - mae: 0.9734 - mse: 1.4805 - val_loss: 1.5009 - val_mae: 0.9863 - val_mse: 1.5009\n",
      "Epoch 709/1000\n",
      "9021/9021 [==============================] - 0s 48us/sample - loss: 1.4800 - mae: 0.9746 - mse: 1.4800 - val_loss: 1.4955 - val_mae: 0.9799 - val_mse: 1.4955\n",
      "Epoch 710/1000\n",
      "9021/9021 [==============================] - 0s 42us/sample - loss: 1.4819 - mae: 0.9750 - mse: 1.4819 - val_loss: 1.5092 - val_mae: 0.9930 - val_mse: 1.5092\n",
      "Epoch 711/1000\n",
      "9021/9021 [==============================] - 0s 46us/sample - loss: 1.4785 - mae: 0.9757 - mse: 1.4785 - val_loss: 1.5139 - val_mae: 0.9910 - val_mse: 1.5139\n",
      "Epoch 712/1000\n",
      "9021/9021 [==============================] - 0s 50us/sample - loss: 1.4843 - mae: 0.9754 - mse: 1.4843 - val_loss: 1.5211 - val_mae: 0.9817 - val_mse: 1.5211\n",
      "Epoch 713/1000\n",
      "9021/9021 [==============================] - 0s 51us/sample - loss: 1.4777 - mae: 0.9749 - mse: 1.4777 - val_loss: 1.5259 - val_mae: 0.9872 - val_mse: 1.5259\n",
      "Epoch 714/1000\n",
      "9021/9021 [==============================] - 0s 54us/sample - loss: 1.4783 - mae: 0.9742 - mse: 1.4783 - val_loss: 1.5211 - val_mae: 0.9792 - val_mse: 1.5211\n",
      "Epoch 715/1000\n",
      "9021/9021 [==============================] - 1s 56us/sample - loss: 1.4808 - mae: 0.9738 - mse: 1.4808 - val_loss: 1.4957 - val_mae: 0.9840 - val_mse: 1.4957\n",
      "Epoch 716/1000\n",
      "9021/9021 [==============================] - 1s 64us/sample - loss: 1.4797 - mae: 0.9746 - mse: 1.4797 - val_loss: 1.5012 - val_mae: 0.9839 - val_mse: 1.5012\n",
      "Epoch 717/1000\n",
      "9021/9021 [==============================] - 1s 64us/sample - loss: 1.4807 - mae: 0.9752 - mse: 1.4807 - val_loss: 1.5105 - val_mae: 0.9859 - val_mse: 1.5105\n",
      "Epoch 718/1000\n",
      "9021/9021 [==============================] - 0s 54us/sample - loss: 1.4812 - mae: 0.9742 - mse: 1.4812 - val_loss: 1.5038 - val_mae: 0.9908 - val_mse: 1.5038\n",
      "Epoch 719/1000\n",
      "9021/9021 [==============================] - 1s 73us/sample - loss: 1.4790 - mae: 0.9727 - mse: 1.4790 - val_loss: 1.5286 - val_mae: 1.0030 - val_mse: 1.5286\n",
      "Epoch 720/1000\n",
      "9021/9021 [==============================] - 0s 48us/sample - loss: 1.4814 - mae: 0.9754 - mse: 1.4814 - val_loss: 1.5088 - val_mae: 0.9896 - val_mse: 1.5088\n",
      "Epoch 721/1000\n",
      "9021/9021 [==============================] - 0s 54us/sample - loss: 1.4799 - mae: 0.9736 - mse: 1.4799 - val_loss: 1.5091 - val_mae: 0.9935 - val_mse: 1.5091\n",
      "Epoch 722/1000\n",
      "9021/9021 [==============================] - 1s 67us/sample - loss: 1.4803 - mae: 0.9745 - mse: 1.4803 - val_loss: 1.5015 - val_mae: 0.9845 - val_mse: 1.5015\n",
      "Epoch 723/1000\n",
      "9021/9021 [==============================] - 1s 62us/sample - loss: 1.4788 - mae: 0.9734 - mse: 1.4788 - val_loss: 1.5045 - val_mae: 0.9849 - val_mse: 1.5045\n",
      "Epoch 724/1000\n",
      "9021/9021 [==============================] - 1s 57us/sample - loss: 1.4827 - mae: 0.9750 - mse: 1.4827 - val_loss: 1.5089 - val_mae: 0.9927 - val_mse: 1.5089\n",
      "Epoch 725/1000\n",
      "9021/9021 [==============================] - 0s 54us/sample - loss: 1.4814 - mae: 0.9753 - mse: 1.4814 - val_loss: 1.5022 - val_mae: 0.9889 - val_mse: 1.5022\n",
      "Epoch 726/1000\n",
      "9021/9021 [==============================] - 0s 44us/sample - loss: 1.4797 - mae: 0.9744 - mse: 1.4797 - val_loss: 1.5108 - val_mae: 0.9933 - val_mse: 1.5108\n",
      "Epoch 727/1000\n",
      "9021/9021 [==============================] - 0s 48us/sample - loss: 1.4789 - mae: 0.9741 - mse: 1.4789 - val_loss: 1.4997 - val_mae: 0.9814 - val_mse: 1.4997\n",
      "Epoch 728/1000\n",
      "9021/9021 [==============================] - 0s 47us/sample - loss: 1.4809 - mae: 0.9755 - mse: 1.4809 - val_loss: 1.5022 - val_mae: 0.9797 - val_mse: 1.5022\n",
      "Epoch 729/1000\n",
      "9021/9021 [==============================] - 0s 34us/sample - loss: 1.4809 - mae: 0.9740 - mse: 1.4809 - val_loss: 1.5003 - val_mae: 0.9909 - val_mse: 1.5003\n",
      "Epoch 730/1000\n",
      "9021/9021 [==============================] - 0s 41us/sample - loss: 1.4800 - mae: 0.9748 - mse: 1.4800 - val_loss: 1.5226 - val_mae: 0.9999 - val_mse: 1.5226\n",
      "Epoch 731/1000\n",
      "9021/9021 [==============================] - 0s 42us/sample - loss: 1.4815 - mae: 0.9751 - mse: 1.4815 - val_loss: 1.5067 - val_mae: 0.9951 - val_mse: 1.5067\n",
      "Epoch 732/1000\n",
      "9021/9021 [==============================] - 0s 43us/sample - loss: 1.4807 - mae: 0.9750 - mse: 1.4807 - val_loss: 1.5061 - val_mae: 0.9916 - val_mse: 1.5061\n",
      "Epoch 733/1000\n",
      "9021/9021 [==============================] - 0s 52us/sample - loss: 1.4801 - mae: 0.9743 - mse: 1.4801 - val_loss: 1.5024 - val_mae: 0.9880 - val_mse: 1.5024\n",
      "Epoch 734/1000\n",
      "9021/9021 [==============================] - 1s 61us/sample - loss: 1.4808 - mae: 0.9749 - mse: 1.4808 - val_loss: 1.5091 - val_mae: 0.9919 - val_mse: 1.5091\n",
      "Epoch 735/1000\n",
      "9021/9021 [==============================] - 0s 49us/sample - loss: 1.4779 - mae: 0.9742 - mse: 1.4779 - val_loss: 1.5214 - val_mae: 0.9822 - val_mse: 1.5214\n",
      "Epoch 736/1000\n",
      "9021/9021 [==============================] - 1s 57us/sample - loss: 1.4805 - mae: 0.9746 - mse: 1.4805 - val_loss: 1.4968 - val_mae: 0.9854 - val_mse: 1.4968\n",
      "Epoch 737/1000\n",
      "9021/9021 [==============================] - 1s 61us/sample - loss: 1.4799 - mae: 0.9742 - mse: 1.4799 - val_loss: 1.5122 - val_mae: 0.9945 - val_mse: 1.5122\n",
      "Epoch 738/1000\n",
      "9021/9021 [==============================] - 1s 68us/sample - loss: 1.4805 - mae: 0.9734 - mse: 1.4805 - val_loss: 1.5039 - val_mae: 0.9911 - val_mse: 1.5039\n",
      "Epoch 739/1000\n",
      "9021/9021 [==============================] - 0s 45us/sample - loss: 1.4813 - mae: 0.9746 - mse: 1.4813 - val_loss: 1.5013 - val_mae: 0.9900 - val_mse: 1.5013\n",
      "Epoch 740/1000\n",
      "9021/9021 [==============================] - 0s 35us/sample - loss: 1.4826 - mae: 0.9750 - mse: 1.4826 - val_loss: 1.5093 - val_mae: 0.9880 - val_mse: 1.5093\n",
      "Epoch 741/1000\n",
      "9021/9021 [==============================] - 0s 52us/sample - loss: 1.4804 - mae: 0.9741 - mse: 1.4804 - val_loss: 1.5076 - val_mae: 0.9922 - val_mse: 1.5076\n",
      "Epoch 742/1000\n",
      "9021/9021 [==============================] - 0s 46us/sample - loss: 1.4820 - mae: 0.9760 - mse: 1.4820 - val_loss: 1.4997 - val_mae: 0.9889 - val_mse: 1.4997\n",
      "Epoch 743/1000\n",
      "9021/9021 [==============================] - 0s 30us/sample - loss: 1.4781 - mae: 0.9741 - mse: 1.4781 - val_loss: 1.5242 - val_mae: 0.9849 - val_mse: 1.5242\n",
      "Epoch 744/1000\n",
      "9021/9021 [==============================] - 0s 33us/sample - loss: 1.4792 - mae: 0.9742 - mse: 1.4792 - val_loss: 1.5163 - val_mae: 0.9806 - val_mse: 1.5163\n",
      "Epoch 745/1000\n",
      "9021/9021 [==============================] - 0s 42us/sample - loss: 1.4814 - mae: 0.9739 - mse: 1.4814 - val_loss: 1.5123 - val_mae: 0.9925 - val_mse: 1.5123\n",
      "Epoch 746/1000\n",
      "9021/9021 [==============================] - 0s 44us/sample - loss: 1.4795 - mae: 0.9732 - mse: 1.4795 - val_loss: 1.5063 - val_mae: 0.9891 - val_mse: 1.5063\n",
      "Epoch 747/1000\n",
      "9021/9021 [==============================] - 0s 33us/sample - loss: 1.4791 - mae: 0.9739 - mse: 1.4791 - val_loss: 1.5180 - val_mae: 0.9812 - val_mse: 1.5180\n",
      "Epoch 748/1000\n",
      "9021/9021 [==============================] - 0s 32us/sample - loss: 1.4799 - mae: 0.9744 - mse: 1.4799 - val_loss: 1.5022 - val_mae: 0.9834 - val_mse: 1.5022\n",
      "Epoch 749/1000\n",
      "9021/9021 [==============================] - 0s 47us/sample - loss: 1.4782 - mae: 0.9734 - mse: 1.4782 - val_loss: 1.4963 - val_mae: 0.9841 - val_mse: 1.4963\n",
      "Epoch 750/1000\n",
      "9021/9021 [==============================] - 0s 49us/sample - loss: 1.4797 - mae: 0.9743 - mse: 1.4797 - val_loss: 1.4963 - val_mae: 0.9834 - val_mse: 1.4963\n",
      "Epoch 751/1000\n",
      "9021/9021 [==============================] - 0s 51us/sample - loss: 1.4791 - mae: 0.9741 - mse: 1.4791 - val_loss: 1.4992 - val_mae: 0.9893 - val_mse: 1.4992\n",
      "Epoch 752/1000\n",
      "9021/9021 [==============================] - 0s 43us/sample - loss: 1.4809 - mae: 0.9762 - mse: 1.4809 - val_loss: 1.5108 - val_mae: 0.9864 - val_mse: 1.5108\n",
      "Epoch 753/1000\n",
      "9021/9021 [==============================] - 0s 49us/sample - loss: 1.4804 - mae: 0.9737 - mse: 1.4804 - val_loss: 1.5032 - val_mae: 0.9852 - val_mse: 1.5032\n",
      "Epoch 754/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9021/9021 [==============================] - 0s 52us/sample - loss: 1.4790 - mae: 0.9747 - mse: 1.4790 - val_loss: 1.5084 - val_mae: 0.9899 - val_mse: 1.5084\n",
      "Epoch 755/1000\n",
      "9021/9021 [==============================] - 1s 56us/sample - loss: 1.4786 - mae: 0.9751 - mse: 1.4786 - val_loss: 1.5045 - val_mae: 0.9838 - val_mse: 1.5045\n",
      "Epoch 756/1000\n",
      "9021/9021 [==============================] - 1s 64us/sample - loss: 1.4820 - mae: 0.9752 - mse: 1.4820 - val_loss: 1.5044 - val_mae: 0.9813 - val_mse: 1.5044\n",
      "Epoch 757/1000\n",
      "9021/9021 [==============================] - 0s 48us/sample - loss: 1.4807 - mae: 0.9740 - mse: 1.4807 - val_loss: 1.5180 - val_mae: 0.9941 - val_mse: 1.5180\n",
      "Epoch 758/1000\n",
      "9021/9021 [==============================] - 1s 66us/sample - loss: 1.4833 - mae: 0.9758 - mse: 1.4833 - val_loss: 1.5271 - val_mae: 0.9991 - val_mse: 1.5271\n",
      "Epoch 759/1000\n",
      "9021/9021 [==============================] - 0s 40us/sample - loss: 1.4784 - mae: 0.9743 - mse: 1.4784 - val_loss: 1.5077 - val_mae: 0.9905 - val_mse: 1.5077\n",
      "Epoch 760/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.4788 - mae: 0.9743 - mse: 1.4788 - val_loss: 1.5119 - val_mae: 0.9918 - val_mse: 1.5119\n",
      "Epoch 761/1000\n",
      "9021/9021 [==============================] - 0s 34us/sample - loss: 1.4794 - mae: 0.9734 - mse: 1.4794 - val_loss: 1.5184 - val_mae: 0.9950 - val_mse: 1.5184\n",
      "Epoch 762/1000\n",
      "9021/9021 [==============================] - 0s 32us/sample - loss: 1.4797 - mae: 0.9730 - mse: 1.4797 - val_loss: 1.5045 - val_mae: 0.9811 - val_mse: 1.5045\n",
      "Epoch 763/1000\n",
      "9021/9021 [==============================] - 0s 37us/sample - loss: 1.4797 - mae: 0.9743 - mse: 1.4797 - val_loss: 1.4964 - val_mae: 0.9865 - val_mse: 1.4964\n",
      "Epoch 764/1000\n",
      "9021/9021 [==============================] - 0s 54us/sample - loss: 1.4796 - mae: 0.9734 - mse: 1.4796 - val_loss: 1.4994 - val_mae: 0.9868 - val_mse: 1.4994\n",
      "Epoch 765/1000\n",
      "9021/9021 [==============================] - 0s 39us/sample - loss: 1.4809 - mae: 0.9753 - mse: 1.4809 - val_loss: 1.5055 - val_mae: 0.9878 - val_mse: 1.5055\n",
      "Epoch 766/1000\n",
      "9021/9021 [==============================] - 0s 37us/sample - loss: 1.4796 - mae: 0.9730 - mse: 1.4796 - val_loss: 1.5026 - val_mae: 0.9912 - val_mse: 1.5026\n",
      "Epoch 767/1000\n",
      "9021/9021 [==============================] - 0s 35us/sample - loss: 1.4798 - mae: 0.9741 - mse: 1.4798 - val_loss: 1.5239 - val_mae: 0.9985 - val_mse: 1.5239\n",
      "Epoch 768/1000\n",
      "9021/9021 [==============================] - 0s 37us/sample - loss: 1.4789 - mae: 0.9732 - mse: 1.4789 - val_loss: 1.5080 - val_mae: 0.9863 - val_mse: 1.5080\n",
      "Epoch 769/1000\n",
      "9021/9021 [==============================] - 0s 47us/sample - loss: 1.4800 - mae: 0.9743 - mse: 1.4800 - val_loss: 1.5062 - val_mae: 0.9832 - val_mse: 1.5062\n",
      "Epoch 770/1000\n",
      "9021/9021 [==============================] - 0s 42us/sample - loss: 1.4807 - mae: 0.9752 - mse: 1.4807 - val_loss: 1.5052 - val_mae: 0.9861 - val_mse: 1.5052\n",
      "Epoch 771/1000\n",
      "9021/9021 [==============================] - 0s 38us/sample - loss: 1.4810 - mae: 0.9743 - mse: 1.4810 - val_loss: 1.5089 - val_mae: 0.9823 - val_mse: 1.5089\n",
      "Epoch 772/1000\n",
      "9021/9021 [==============================] - 0s 32us/sample - loss: 1.4802 - mae: 0.9747 - mse: 1.4802 - val_loss: 1.5265 - val_mae: 0.9827 - val_mse: 1.5265\n",
      "Epoch 773/1000\n",
      "9021/9021 [==============================] - 0s 35us/sample - loss: 1.4812 - mae: 0.9753 - mse: 1.4812 - val_loss: 1.5021 - val_mae: 0.9852 - val_mse: 1.5021\n",
      "Epoch 774/1000\n",
      "9021/9021 [==============================] - 0s 32us/sample - loss: 1.4785 - mae: 0.9738 - mse: 1.4785 - val_loss: 1.5112 - val_mae: 0.9949 - val_mse: 1.5112\n",
      "Epoch 775/1000\n",
      "9021/9021 [==============================] - 0s 31us/sample - loss: 1.4807 - mae: 0.9750 - mse: 1.4807 - val_loss: 1.5042 - val_mae: 0.9875 - val_mse: 1.5042\n",
      "Epoch 776/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.4778 - mae: 0.9736 - mse: 1.4778 - val_loss: 1.5195 - val_mae: 0.9806 - val_mse: 1.5195\n",
      "Epoch 777/1000\n",
      "9021/9021 [==============================] - 0s 33us/sample - loss: 1.4792 - mae: 0.9740 - mse: 1.4792 - val_loss: 1.5104 - val_mae: 0.9931 - val_mse: 1.5104\n",
      "Epoch 778/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.4798 - mae: 0.9750 - mse: 1.4798 - val_loss: 1.4995 - val_mae: 0.9854 - val_mse: 1.4995\n",
      "Epoch 779/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.4789 - mae: 0.9736 - mse: 1.4789 - val_loss: 1.5086 - val_mae: 0.9898 - val_mse: 1.5086\n",
      "Epoch 780/1000\n",
      "9021/9021 [==============================] - 0s 29us/sample - loss: 1.4785 - mae: 0.9738 - mse: 1.4785 - val_loss: 1.4994 - val_mae: 0.9900 - val_mse: 1.4994\n",
      "Epoch 781/1000\n",
      "9021/9021 [==============================] - 0s 37us/sample - loss: 1.4794 - mae: 0.9752 - mse: 1.4794 - val_loss: 1.4995 - val_mae: 0.9906 - val_mse: 1.4995\n",
      "Epoch 782/1000\n",
      "9021/9021 [==============================] - 0s 40us/sample - loss: 1.4808 - mae: 0.9755 - mse: 1.4808 - val_loss: 1.5193 - val_mae: 0.9966 - val_mse: 1.5193\n",
      "Epoch 783/1000\n",
      "9021/9021 [==============================] - 0s 38us/sample - loss: 1.4806 - mae: 0.9758 - mse: 1.4806 - val_loss: 1.5081 - val_mae: 0.9857 - val_mse: 1.5081\n",
      "Epoch 784/1000\n",
      "9021/9021 [==============================] - 0s 33us/sample - loss: 1.4799 - mae: 0.9737 - mse: 1.4799 - val_loss: 1.5202 - val_mae: 0.9820 - val_mse: 1.5202\n",
      "Epoch 785/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.4808 - mae: 0.9741 - mse: 1.4808 - val_loss: 1.5057 - val_mae: 0.9881 - val_mse: 1.5057\n",
      "Epoch 786/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.4788 - mae: 0.9742 - mse: 1.4788 - val_loss: 1.5002 - val_mae: 0.9834 - val_mse: 1.5002\n",
      "Epoch 787/1000\n",
      "9021/9021 [==============================] - 0s 27us/sample - loss: 1.4775 - mae: 0.9723 - mse: 1.4775 - val_loss: 1.5114 - val_mae: 0.9855 - val_mse: 1.5114\n",
      "Epoch 788/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.4796 - mae: 0.9737 - mse: 1.4796 - val_loss: 1.5154 - val_mae: 0.9822 - val_mse: 1.5154\n",
      "Epoch 789/1000\n",
      "9021/9021 [==============================] - 0s 27us/sample - loss: 1.4787 - mae: 0.9746 - mse: 1.4787 - val_loss: 1.5096 - val_mae: 0.9881 - val_mse: 1.5096\n",
      "Epoch 790/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.4784 - mae: 0.9745 - mse: 1.4784 - val_loss: 1.4996 - val_mae: 0.9875 - val_mse: 1.4996\n",
      "Epoch 791/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.4826 - mae: 0.9759 - mse: 1.4826 - val_loss: 1.5066 - val_mae: 0.9923 - val_mse: 1.5066\n",
      "Epoch 792/1000\n",
      "9021/9021 [==============================] - 0s 28us/sample - loss: 1.4785 - mae: 0.9742 - mse: 1.4785 - val_loss: 1.5091 - val_mae: 0.9822 - val_mse: 1.5091\n",
      "Epoch 793/1000\n",
      "9021/9021 [==============================] - 0s 29us/sample - loss: 1.4803 - mae: 0.9745 - mse: 1.4803 - val_loss: 1.5006 - val_mae: 0.9836 - val_mse: 1.5006\n",
      "Epoch 794/1000\n",
      "9021/9021 [==============================] - 0s 29us/sample - loss: 1.4785 - mae: 0.9736 - mse: 1.4785 - val_loss: 1.4989 - val_mae: 0.9844 - val_mse: 1.4989\n",
      "Epoch 795/1000\n",
      "9021/9021 [==============================] - 0s 36us/sample - loss: 1.4790 - mae: 0.9741 - mse: 1.4790 - val_loss: 1.5042 - val_mae: 0.9824 - val_mse: 1.5042\n",
      "Epoch 796/1000\n",
      "9021/9021 [==============================] - 0s 42us/sample - loss: 1.4798 - mae: 0.9750 - mse: 1.4798 - val_loss: 1.5053 - val_mae: 0.9791 - val_mse: 1.5053\n",
      "Epoch 797/1000\n",
      "9021/9021 [==============================] - 0s 32us/sample - loss: 1.4791 - mae: 0.9729 - mse: 1.4791 - val_loss: 1.5331 - val_mae: 1.0023 - val_mse: 1.5331\n",
      "Epoch 798/1000\n",
      "9021/9021 [==============================] - 0s 43us/sample - loss: 1.4794 - mae: 0.9738 - mse: 1.4794 - val_loss: 1.5047 - val_mae: 0.9930 - val_mse: 1.5047\n",
      "Epoch 799/1000\n",
      "9021/9021 [==============================] - 0s 47us/sample - loss: 1.4796 - mae: 0.9744 - mse: 1.4796 - val_loss: 1.4959 - val_mae: 0.9853 - val_mse: 1.4959\n",
      "Epoch 800/1000\n",
      "9021/9021 [==============================] - 0s 33us/sample - loss: 1.4770 - mae: 0.9733 - mse: 1.4770 - val_loss: 1.5133 - val_mae: 0.9870 - val_mse: 1.5133\n",
      "Epoch 801/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9021/9021 [==============================] - 0s 42us/sample - loss: 1.4794 - mae: 0.9740 - mse: 1.4794 - val_loss: 1.5010 - val_mae: 0.9904 - val_mse: 1.5010\n",
      "Epoch 802/1000\n",
      "9021/9021 [==============================] - 0s 33us/sample - loss: 1.4807 - mae: 0.9748 - mse: 1.4807 - val_loss: 1.5129 - val_mae: 0.9927 - val_mse: 1.5129\n",
      "Epoch 803/1000\n",
      "9021/9021 [==============================] - 0s 34us/sample - loss: 1.4787 - mae: 0.9755 - mse: 1.4787 - val_loss: 1.5110 - val_mae: 0.9900 - val_mse: 1.5110\n",
      "Epoch 804/1000\n",
      "9021/9021 [==============================] - 0s 38us/sample - loss: 1.4781 - mae: 0.9735 - mse: 1.4781 - val_loss: 1.5053 - val_mae: 0.9854 - val_mse: 1.5053\n",
      "Epoch 805/1000\n",
      "9021/9021 [==============================] - 0s 35us/sample - loss: 1.4779 - mae: 0.9730 - mse: 1.4779 - val_loss: 1.5100 - val_mae: 0.9828 - val_mse: 1.5100\n",
      "Epoch 806/1000\n",
      "9021/9021 [==============================] - 0s 34us/sample - loss: 1.4789 - mae: 0.9745 - mse: 1.4789 - val_loss: 1.5209 - val_mae: 0.9795 - val_mse: 1.5209\n",
      "Epoch 807/1000\n",
      "9021/9021 [==============================] - 0s 36us/sample - loss: 1.4804 - mae: 0.9743 - mse: 1.4804 - val_loss: 1.4973 - val_mae: 0.9866 - val_mse: 1.4973\n",
      "Epoch 808/1000\n",
      "9021/9021 [==============================] - 0s 31us/sample - loss: 1.4801 - mae: 0.9738 - mse: 1.4801 - val_loss: 1.5081 - val_mae: 0.9847 - val_mse: 1.5081\n",
      "Epoch 809/1000\n",
      "9021/9021 [==============================] - 0s 27us/sample - loss: 1.4791 - mae: 0.9739 - mse: 1.4791 - val_loss: 1.5115 - val_mae: 0.9829 - val_mse: 1.5115\n",
      "Epoch 810/1000\n",
      "9021/9021 [==============================] - 0s 29us/sample - loss: 1.4795 - mae: 0.9745 - mse: 1.4795 - val_loss: 1.5131 - val_mae: 0.9869 - val_mse: 1.5131\n",
      "Epoch 811/1000\n",
      "9021/9021 [==============================] - 0s 40us/sample - loss: 1.4783 - mae: 0.9739 - mse: 1.4783 - val_loss: 1.5112 - val_mae: 0.9901 - val_mse: 1.5112\n",
      "Epoch 812/1000\n",
      "9021/9021 [==============================] - 0s 40us/sample - loss: 1.4790 - mae: 0.9742 - mse: 1.4790 - val_loss: 1.5040 - val_mae: 0.9857 - val_mse: 1.5040\n",
      "Epoch 813/1000\n",
      "9021/9021 [==============================] - 0s 50us/sample - loss: 1.4790 - mae: 0.9739 - mse: 1.4790 - val_loss: 1.5069 - val_mae: 0.9857 - val_mse: 1.5069\n",
      "Epoch 814/1000\n",
      "9021/9021 [==============================] - 0s 40us/sample - loss: 1.4777 - mae: 0.9721 - mse: 1.4777 - val_loss: 1.5012 - val_mae: 0.9861 - val_mse: 1.5012\n",
      "Epoch 815/1000\n",
      "9021/9021 [==============================] - 0s 47us/sample - loss: 1.4797 - mae: 0.9742 - mse: 1.4797 - val_loss: 1.4996 - val_mae: 0.9861 - val_mse: 1.4996\n",
      "Epoch 816/1000\n",
      "9021/9021 [==============================] - 0s 40us/sample - loss: 1.4794 - mae: 0.9740 - mse: 1.4794 - val_loss: 1.4981 - val_mae: 0.9864 - val_mse: 1.4981\n",
      "Epoch 817/1000\n",
      "9021/9021 [==============================] - 0s 35us/sample - loss: 1.4795 - mae: 0.9727 - mse: 1.4795 - val_loss: 1.5008 - val_mae: 0.9858 - val_mse: 1.5008\n",
      "Epoch 818/1000\n",
      "9021/9021 [==============================] - 0s 41us/sample - loss: 1.4786 - mae: 0.9750 - mse: 1.4786 - val_loss: 1.5122 - val_mae: 0.9927 - val_mse: 1.5122\n",
      "Epoch 819/1000\n",
      "9021/9021 [==============================] - 0s 39us/sample - loss: 1.4807 - mae: 0.9751 - mse: 1.4807 - val_loss: 1.5135 - val_mae: 0.9822 - val_mse: 1.5135\n",
      "Epoch 820/1000\n",
      "9021/9021 [==============================] - 0s 51us/sample - loss: 1.4786 - mae: 0.9750 - mse: 1.4786 - val_loss: 1.4992 - val_mae: 0.9832 - val_mse: 1.4992\n",
      "Epoch 821/1000\n",
      "9021/9021 [==============================] - 0s 42us/sample - loss: 1.4781 - mae: 0.9735 - mse: 1.4781 - val_loss: 1.5280 - val_mae: 1.0003 - val_mse: 1.5280\n",
      "Epoch 822/1000\n",
      "9021/9021 [==============================] - 0s 51us/sample - loss: 1.4782 - mae: 0.9743 - mse: 1.4782 - val_loss: 1.4988 - val_mae: 0.9843 - val_mse: 1.4988\n",
      "Epoch 823/1000\n",
      "9021/9021 [==============================] - 0s 38us/sample - loss: 1.4807 - mae: 0.9743 - mse: 1.4807 - val_loss: 1.5083 - val_mae: 0.9890 - val_mse: 1.5083\n",
      "Epoch 824/1000\n",
      "9021/9021 [==============================] - 0s 37us/sample - loss: 1.4781 - mae: 0.9726 - mse: 1.4781 - val_loss: 1.5031 - val_mae: 0.9909 - val_mse: 1.5031\n",
      "Epoch 825/1000\n",
      "9021/9021 [==============================] - 0s 34us/sample - loss: 1.4800 - mae: 0.9756 - mse: 1.4800 - val_loss: 1.5059 - val_mae: 0.9873 - val_mse: 1.5059\n",
      "Epoch 826/1000\n",
      "9021/9021 [==============================] - 0s 39us/sample - loss: 1.4782 - mae: 0.9739 - mse: 1.4782 - val_loss: 1.4972 - val_mae: 0.9864 - val_mse: 1.4972\n",
      "Epoch 827/1000\n",
      "9021/9021 [==============================] - 0s 34us/sample - loss: 1.4790 - mae: 0.9756 - mse: 1.4790 - val_loss: 1.5048 - val_mae: 0.9875 - val_mse: 1.5048\n",
      "Epoch 828/1000\n",
      "9021/9021 [==============================] - 0s 36us/sample - loss: 1.4791 - mae: 0.9733 - mse: 1.4791 - val_loss: 1.5042 - val_mae: 0.9853 - val_mse: 1.5042\n",
      "Epoch 829/1000\n",
      "9021/9021 [==============================] - 0s 38us/sample - loss: 1.4799 - mae: 0.9734 - mse: 1.4799 - val_loss: 1.4997 - val_mae: 0.9846 - val_mse: 1.4997\n",
      "Epoch 830/1000\n",
      "9021/9021 [==============================] - 0s 36us/sample - loss: 1.4817 - mae: 0.9744 - mse: 1.4817 - val_loss: 1.5201 - val_mae: 0.9846 - val_mse: 1.5201\n",
      "Epoch 831/1000\n",
      "9021/9021 [==============================] - 0s 38us/sample - loss: 1.4795 - mae: 0.9749 - mse: 1.4795 - val_loss: 1.5201 - val_mae: 0.9865 - val_mse: 1.5201\n",
      "Epoch 832/1000\n",
      "9021/9021 [==============================] - 0s 43us/sample - loss: 1.4810 - mae: 0.9741 - mse: 1.4810 - val_loss: 1.5043 - val_mae: 0.9862 - val_mse: 1.5043\n",
      "Epoch 833/1000\n",
      "9021/9021 [==============================] - 0s 34us/sample - loss: 1.4787 - mae: 0.9739 - mse: 1.4787 - val_loss: 1.5018 - val_mae: 0.9889 - val_mse: 1.5018\n",
      "Epoch 834/1000\n",
      "9021/9021 [==============================] - 0s 40us/sample - loss: 1.4794 - mae: 0.9749 - mse: 1.4794 - val_loss: 1.5192 - val_mae: 0.9848 - val_mse: 1.5192\n",
      "Epoch 835/1000\n",
      "9021/9021 [==============================] - 0s 47us/sample - loss: 1.4800 - mae: 0.9744 - mse: 1.4800 - val_loss: 1.5028 - val_mae: 0.9905 - val_mse: 1.5028\n",
      "Epoch 836/1000\n",
      "9021/9021 [==============================] - 1s 65us/sample - loss: 1.4789 - mae: 0.9743 - mse: 1.4789 - val_loss: 1.5100 - val_mae: 0.9825 - val_mse: 1.5100\n",
      "Epoch 837/1000\n",
      "9021/9021 [==============================] - 0s 34us/sample - loss: 1.4789 - mae: 0.9734 - mse: 1.4789 - val_loss: 1.5121 - val_mae: 0.9825 - val_mse: 1.5121\n",
      "Epoch 838/1000\n",
      "9021/9021 [==============================] - 0s 30us/sample - loss: 1.4790 - mae: 0.9734 - mse: 1.4790 - val_loss: 1.5092 - val_mae: 0.9949 - val_mse: 1.5092\n",
      "Epoch 839/1000\n",
      "9021/9021 [==============================] - 0s 32us/sample - loss: 1.4793 - mae: 0.9728 - mse: 1.4793 - val_loss: 1.5095 - val_mae: 0.9918 - val_mse: 1.5095\n",
      "Epoch 840/1000\n",
      "9021/9021 [==============================] - 0s 32us/sample - loss: 1.4788 - mae: 0.9738 - mse: 1.4788 - val_loss: 1.5168 - val_mae: 0.9952 - val_mse: 1.5168\n",
      "Epoch 841/1000\n",
      "9021/9021 [==============================] - 0s 40us/sample - loss: 1.4797 - mae: 0.9761 - mse: 1.4797 - val_loss: 1.5050 - val_mae: 0.9883 - val_mse: 1.5050\n",
      "Epoch 842/1000\n",
      "9021/9021 [==============================] - 0s 37us/sample - loss: 1.4780 - mae: 0.9734 - mse: 1.4780 - val_loss: 1.5041 - val_mae: 0.9890 - val_mse: 1.5041\n",
      "Epoch 843/1000\n",
      "9021/9021 [==============================] - 0s 33us/sample - loss: 1.4793 - mae: 0.9741 - mse: 1.4793 - val_loss: 1.5095 - val_mae: 0.9825 - val_mse: 1.5095\n",
      "Epoch 844/1000\n",
      "9021/9021 [==============================] - 0s 34us/sample - loss: 1.4770 - mae: 0.9735 - mse: 1.4770 - val_loss: 1.5123 - val_mae: 0.9822 - val_mse: 1.5123\n",
      "Epoch 845/1000\n",
      "9021/9021 [==============================] - 0s 35us/sample - loss: 1.4811 - mae: 0.9732 - mse: 1.4811 - val_loss: 1.5143 - val_mae: 0.9911 - val_mse: 1.5143\n",
      "Epoch 846/1000\n",
      "9021/9021 [==============================] - 0s 29us/sample - loss: 1.4812 - mae: 0.9749 - mse: 1.4812 - val_loss: 1.5018 - val_mae: 0.9881 - val_mse: 1.5018\n",
      "Epoch 847/1000\n",
      "9021/9021 [==============================] - 0s 30us/sample - loss: 1.4783 - mae: 0.9750 - mse: 1.4783 - val_loss: 1.4989 - val_mae: 0.9810 - val_mse: 1.4989\n",
      "Epoch 848/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9021/9021 [==============================] - 0s 28us/sample - loss: 1.4766 - mae: 0.9724 - mse: 1.4766 - val_loss: 1.5044 - val_mae: 0.9898 - val_mse: 1.5044\n",
      "Epoch 849/1000\n",
      "9021/9021 [==============================] - 0s 32us/sample - loss: 1.4793 - mae: 0.9743 - mse: 1.4793 - val_loss: 1.4961 - val_mae: 0.9883 - val_mse: 1.4961\n",
      "Epoch 850/1000\n",
      "9021/9021 [==============================] - 0s 29us/sample - loss: 1.4817 - mae: 0.9755 - mse: 1.4817 - val_loss: 1.5095 - val_mae: 0.9912 - val_mse: 1.5095\n",
      "Epoch 851/1000\n",
      "9021/9021 [==============================] - 0s 42us/sample - loss: 1.4797 - mae: 0.9745 - mse: 1.4797 - val_loss: 1.4998 - val_mae: 0.9833 - val_mse: 1.4998\n",
      "Epoch 852/1000\n",
      "9021/9021 [==============================] - 0s 47us/sample - loss: 1.4790 - mae: 0.9751 - mse: 1.4790 - val_loss: 1.5123 - val_mae: 0.9890 - val_mse: 1.5123\n",
      "Epoch 853/1000\n",
      "9021/9021 [==============================] - 0s 35us/sample - loss: 1.4797 - mae: 0.9744 - mse: 1.4797 - val_loss: 1.5163 - val_mae: 0.9952 - val_mse: 1.5163\n",
      "Epoch 854/1000\n",
      "9021/9021 [==============================] - 0s 28us/sample - loss: 1.4818 - mae: 0.9757 - mse: 1.4818 - val_loss: 1.5123 - val_mae: 0.9913 - val_mse: 1.5123\n",
      "Epoch 855/1000\n",
      "9021/9021 [==============================] - 0s 31us/sample - loss: 1.4754 - mae: 0.9740 - mse: 1.4754 - val_loss: 1.5015 - val_mae: 0.9863 - val_mse: 1.5015\n",
      "Epoch 856/1000\n",
      "9021/9021 [==============================] - 0s 28us/sample - loss: 1.4812 - mae: 0.9761 - mse: 1.4812 - val_loss: 1.5135 - val_mae: 0.9830 - val_mse: 1.5135\n",
      "Epoch 857/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.4786 - mae: 0.9742 - mse: 1.4786 - val_loss: 1.5053 - val_mae: 0.9843 - val_mse: 1.5053\n",
      "Epoch 858/1000\n",
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.4778 - mae: 0.9737 - mse: 1.4778 - val_loss: 1.5146 - val_mae: 0.9941 - val_mse: 1.5146\n",
      "Epoch 859/1000\n",
      "9021/9021 [==============================] - 0s 25us/sample - loss: 1.4796 - mae: 0.9739 - mse: 1.4796 - val_loss: 1.5169 - val_mae: 0.9840 - val_mse: 1.5169\n",
      "Epoch 860/1000\n",
      "9021/9021 [==============================] - 0s 28us/sample - loss: 1.4773 - mae: 0.9736 - mse: 1.4773 - val_loss: 1.5170 - val_mae: 0.9807 - val_mse: 1.5170\n",
      "Epoch 861/1000\n",
      "9021/9021 [==============================] - 0s 28us/sample - loss: 1.4801 - mae: 0.9744 - mse: 1.4801 - val_loss: 1.5159 - val_mae: 0.9815 - val_mse: 1.5159\n",
      "Epoch 862/1000\n",
      "9021/9021 [==============================] - 0s 35us/sample - loss: 1.4781 - mae: 0.9731 - mse: 1.4781 - val_loss: 1.5103 - val_mae: 0.9860 - val_mse: 1.5103\n",
      "Epoch 863/1000\n",
      "9021/9021 [==============================] - 0s 44us/sample - loss: 1.4769 - mae: 0.9719 - mse: 1.4769 - val_loss: 1.5172 - val_mae: 0.9949 - val_mse: 1.5172\n",
      "Epoch 864/1000\n",
      "9021/9021 [==============================] - 0s 50us/sample - loss: 1.4776 - mae: 0.9742 - mse: 1.4776 - val_loss: 1.5067 - val_mae: 0.9849 - val_mse: 1.5067\n",
      "Epoch 865/1000\n",
      "9021/9021 [==============================] - 1s 66us/sample - loss: 1.4807 - mae: 0.9740 - mse: 1.4807 - val_loss: 1.5044 - val_mae: 0.9896 - val_mse: 1.5044\n",
      "Epoch 866/1000\n",
      "9021/9021 [==============================] - 1s 60us/sample - loss: 1.4775 - mae: 0.9740 - mse: 1.4775 - val_loss: 1.5048 - val_mae: 0.9872 - val_mse: 1.5048\n",
      "Epoch 867/1000\n",
      "9021/9021 [==============================] - 0s 51us/sample - loss: 1.4814 - mae: 0.9751 - mse: 1.4814 - val_loss: 1.5030 - val_mae: 0.9836 - val_mse: 1.5030\n",
      "Epoch 868/1000\n",
      "9021/9021 [==============================] - 0s 51us/sample - loss: 1.4765 - mae: 0.9732 - mse: 1.4765 - val_loss: 1.4995 - val_mae: 0.9849 - val_mse: 1.4995\n",
      "Epoch 869/1000\n",
      "9021/9021 [==============================] - 0s 43us/sample - loss: 1.4759 - mae: 0.9731 - mse: 1.4759 - val_loss: 1.5178 - val_mae: 0.9850 - val_mse: 1.5178\n",
      "Epoch 870/1000\n",
      "9021/9021 [==============================] - 0s 43us/sample - loss: 1.4817 - mae: 0.9760 - mse: 1.4817 - val_loss: 1.5072 - val_mae: 0.9881 - val_mse: 1.5072\n",
      "Epoch 871/1000\n",
      "9021/9021 [==============================] - 0s 43us/sample - loss: 1.4785 - mae: 0.9738 - mse: 1.4785 - val_loss: 1.4987 - val_mae: 0.9890 - val_mse: 1.4987\n",
      "Epoch 872/1000\n",
      "9021/9021 [==============================] - 0s 53us/sample - loss: 1.4797 - mae: 0.9739 - mse: 1.4797 - val_loss: 1.5048 - val_mae: 0.9878 - val_mse: 1.5048\n",
      "Epoch 873/1000\n",
      "9021/9021 [==============================] - 0s 50us/sample - loss: 1.4787 - mae: 0.9731 - mse: 1.4787 - val_loss: 1.5008 - val_mae: 0.9860 - val_mse: 1.5008\n",
      "Epoch 874/1000\n",
      "9021/9021 [==============================] - 0s 36us/sample - loss: 1.4789 - mae: 0.9749 - mse: 1.4789 - val_loss: 1.5091 - val_mae: 0.9877 - val_mse: 1.5091\n",
      "Epoch 875/1000\n",
      "9021/9021 [==============================] - 0s 47us/sample - loss: 1.4758 - mae: 0.9731 - mse: 1.4758 - val_loss: 1.5132 - val_mae: 0.9886 - val_mse: 1.5132\n",
      "Epoch 876/1000\n",
      "9021/9021 [==============================] - 0s 47us/sample - loss: 1.4790 - mae: 0.9734 - mse: 1.4790 - val_loss: 1.5051 - val_mae: 0.9889 - val_mse: 1.5051\n",
      "Epoch 877/1000\n",
      "9021/9021 [==============================] - 0s 41us/sample - loss: 1.4778 - mae: 0.9720 - mse: 1.4778 - val_loss: 1.5054 - val_mae: 0.9907 - val_mse: 1.5054\n",
      "Epoch 878/1000\n",
      "9021/9021 [==============================] - 0s 49us/sample - loss: 1.4785 - mae: 0.9742 - mse: 1.4785 - val_loss: 1.5070 - val_mae: 0.9871 - val_mse: 1.5070\n",
      "Epoch 879/1000\n",
      "9021/9021 [==============================] - 0s 49us/sample - loss: 1.4789 - mae: 0.9728 - mse: 1.4789 - val_loss: 1.5007 - val_mae: 0.9845 - val_mse: 1.5007\n",
      "Epoch 880/1000\n",
      "9021/9021 [==============================] - 0s 51us/sample - loss: 1.4790 - mae: 0.9747 - mse: 1.4790 - val_loss: 1.4974 - val_mae: 0.9891 - val_mse: 1.4974\n",
      "Epoch 881/1000\n",
      "9021/9021 [==============================] - 0s 51us/sample - loss: 1.4790 - mae: 0.9745 - mse: 1.4790 - val_loss: 1.5084 - val_mae: 0.9818 - val_mse: 1.5084\n",
      "Epoch 882/1000\n",
      "9021/9021 [==============================] - 0s 53us/sample - loss: 1.4777 - mae: 0.9728 - mse: 1.4777 - val_loss: 1.4986 - val_mae: 0.9889 - val_mse: 1.4986\n",
      "Epoch 883/1000\n",
      "9021/9021 [==============================] - 0s 47us/sample - loss: 1.4785 - mae: 0.9745 - mse: 1.4785 - val_loss: 1.5060 - val_mae: 0.9895 - val_mse: 1.5060\n",
      "Epoch 884/1000\n",
      "9021/9021 [==============================] - 0s 41us/sample - loss: 1.4788 - mae: 0.9734 - mse: 1.4788 - val_loss: 1.4991 - val_mae: 0.9855 - val_mse: 1.4991\n",
      "Epoch 885/1000\n",
      "9021/9021 [==============================] - 0s 33us/sample - loss: 1.4786 - mae: 0.9745 - mse: 1.4786 - val_loss: 1.5076 - val_mae: 0.9851 - val_mse: 1.5076\n",
      "Epoch 886/1000\n",
      "9021/9021 [==============================] - 0s 41us/sample - loss: 1.4772 - mae: 0.9746 - mse: 1.4772 - val_loss: 1.5129 - val_mae: 0.9900 - val_mse: 1.5129\n",
      "Epoch 887/1000\n",
      "9021/9021 [==============================] - 0s 42us/sample - loss: 1.4797 - mae: 0.9741 - mse: 1.4797 - val_loss: 1.5054 - val_mae: 0.9837 - val_mse: 1.5054\n",
      "Epoch 888/1000\n",
      "9021/9021 [==============================] - 0s 38us/sample - loss: 1.4772 - mae: 0.9730 - mse: 1.4772 - val_loss: 1.4960 - val_mae: 0.9866 - val_mse: 1.4960\n",
      "Epoch 889/1000\n",
      "9021/9021 [==============================] - 0s 41us/sample - loss: 1.4778 - mae: 0.9735 - mse: 1.4778 - val_loss: 1.5165 - val_mae: 0.9847 - val_mse: 1.5165\n",
      "Epoch 890/1000\n",
      "9021/9021 [==============================] - 0s 38us/sample - loss: 1.4806 - mae: 0.9741 - mse: 1.4806 - val_loss: 1.5033 - val_mae: 0.9902 - val_mse: 1.5033\n",
      "Epoch 891/1000\n",
      "9021/9021 [==============================] - 1s 59us/sample - loss: 1.4775 - mae: 0.9736 - mse: 1.4775 - val_loss: 1.5061 - val_mae: 0.9820 - val_mse: 1.5061\n",
      "Epoch 892/1000\n",
      "9021/9021 [==============================] - 1s 84us/sample - loss: 1.4793 - mae: 0.9733 - mse: 1.4793 - val_loss: 1.5017 - val_mae: 0.9922 - val_mse: 1.5017\n",
      "Epoch 893/1000\n",
      "9021/9021 [==============================] - 1s 66us/sample - loss: 1.4765 - mae: 0.9739 - mse: 1.4765 - val_loss: 1.5146 - val_mae: 0.9831 - val_mse: 1.5146\n",
      "Epoch 894/1000\n",
      "9021/9021 [==============================] - 1s 66us/sample - loss: 1.4780 - mae: 0.9720 - mse: 1.4780 - val_loss: 1.5013 - val_mae: 0.9897 - val_mse: 1.5013\n",
      "Epoch 895/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9021/9021 [==============================] - 1s 75us/sample - loss: 1.4806 - mae: 0.9750 - mse: 1.4806 - val_loss: 1.5024 - val_mae: 0.9869 - val_mse: 1.5024\n",
      "Epoch 896/1000\n",
      "9021/9021 [==============================] - 0s 39us/sample - loss: 1.4739 - mae: 0.9718 - mse: 1.4739 - val_loss: 1.5092 - val_mae: 0.9883 - val_mse: 1.5092\n",
      "Epoch 897/1000\n",
      "9021/9021 [==============================] - 1s 66us/sample - loss: 1.4801 - mae: 0.9743 - mse: 1.4801 - val_loss: 1.4941 - val_mae: 0.9814 - val_mse: 1.4941\n",
      "Epoch 898/1000\n",
      "9021/9021 [==============================] - 1s 58us/sample - loss: 1.4790 - mae: 0.9739 - mse: 1.4790 - val_loss: 1.5075 - val_mae: 0.9898 - val_mse: 1.5075\n",
      "Epoch 899/1000\n",
      "9021/9021 [==============================] - 0s 46us/sample - loss: 1.4785 - mae: 0.9738 - mse: 1.4785 - val_loss: 1.5004 - val_mae: 0.9858 - val_mse: 1.5004\n",
      "Epoch 900/1000\n",
      "9021/9021 [==============================] - 0s 43us/sample - loss: 1.4783 - mae: 0.9748 - mse: 1.4783 - val_loss: 1.4939 - val_mae: 0.9832 - val_mse: 1.4939\n",
      "Epoch 901/1000\n",
      "9021/9021 [==============================] - 0s 55us/sample - loss: 1.4820 - mae: 0.9741 - mse: 1.4820 - val_loss: 1.5097 - val_mae: 0.9964 - val_mse: 1.5097\n",
      "Epoch 902/1000\n",
      "9021/9021 [==============================] - 0s 49us/sample - loss: 1.4775 - mae: 0.9731 - mse: 1.4775 - val_loss: 1.5137 - val_mae: 0.9906 - val_mse: 1.5137\n",
      "Epoch 903/1000\n",
      "9021/9021 [==============================] - 0s 41us/sample - loss: 1.4801 - mae: 0.9739 - mse: 1.4801 - val_loss: 1.4996 - val_mae: 0.9896 - val_mse: 1.4996\n",
      "Epoch 904/1000\n",
      "9021/9021 [==============================] - 0s 38us/sample - loss: 1.4801 - mae: 0.9751 - mse: 1.4801 - val_loss: 1.5042 - val_mae: 0.9876 - val_mse: 1.5042\n",
      "Epoch 905/1000\n",
      "9021/9021 [==============================] - 0s 37us/sample - loss: 1.4790 - mae: 0.9739 - mse: 1.4790 - val_loss: 1.4964 - val_mae: 0.9837 - val_mse: 1.4964\n",
      "Epoch 906/1000\n",
      "9021/9021 [==============================] - 0s 43us/sample - loss: 1.4794 - mae: 0.9746 - mse: 1.4794 - val_loss: 1.5016 - val_mae: 0.9807 - val_mse: 1.5016\n",
      "Epoch 907/1000\n",
      "9021/9021 [==============================] - 1s 59us/sample - loss: 1.4777 - mae: 0.9742 - mse: 1.4777 - val_loss: 1.5032 - val_mae: 0.9887 - val_mse: 1.5032\n",
      "Epoch 908/1000\n",
      "9021/9021 [==============================] - 1s 62us/sample - loss: 1.4784 - mae: 0.9731 - mse: 1.4784 - val_loss: 1.5127 - val_mae: 0.9871 - val_mse: 1.5127\n",
      "Epoch 909/1000\n",
      "9021/9021 [==============================] - 0s 42us/sample - loss: 1.4789 - mae: 0.9740 - mse: 1.4789 - val_loss: 1.5021 - val_mae: 0.9911 - val_mse: 1.5021\n",
      "Epoch 910/1000\n",
      "9021/9021 [==============================] - 0s 40us/sample - loss: 1.4779 - mae: 0.9745 - mse: 1.4779 - val_loss: 1.5015 - val_mae: 0.9854 - val_mse: 1.5015\n",
      "Epoch 911/1000\n",
      "9021/9021 [==============================] - 0s 47us/sample - loss: 1.4785 - mae: 0.9729 - mse: 1.4785 - val_loss: 1.4992 - val_mae: 0.9844 - val_mse: 1.4992\n",
      "Epoch 912/1000\n",
      "9021/9021 [==============================] - 0s 41us/sample - loss: 1.4789 - mae: 0.9750 - mse: 1.4789 - val_loss: 1.5002 - val_mae: 0.9831 - val_mse: 1.5002\n",
      "Epoch 913/1000\n",
      "9021/9021 [==============================] - 0s 42us/sample - loss: 1.4786 - mae: 0.9735 - mse: 1.4786 - val_loss: 1.5079 - val_mae: 0.9826 - val_mse: 1.5079\n",
      "Epoch 914/1000\n",
      "9021/9021 [==============================] - 0s 53us/sample - loss: 1.4783 - mae: 0.9732 - mse: 1.4783 - val_loss: 1.5077 - val_mae: 0.9899 - val_mse: 1.5077\n",
      "Epoch 915/1000\n",
      "9021/9021 [==============================] - 0s 46us/sample - loss: 1.4774 - mae: 0.9743 - mse: 1.4774 - val_loss: 1.5138 - val_mae: 0.9824 - val_mse: 1.5138\n",
      "Epoch 916/1000\n",
      "9021/9021 [==============================] - 0s 33us/sample - loss: 1.4788 - mae: 0.9746 - mse: 1.4788 - val_loss: 1.5145 - val_mae: 0.9819 - val_mse: 1.5145\n",
      "Epoch 917/1000\n",
      "9021/9021 [==============================] - 0s 42us/sample - loss: 1.4789 - mae: 0.9753 - mse: 1.4789 - val_loss: 1.5074 - val_mae: 0.9885 - val_mse: 1.5074\n",
      "Epoch 918/1000\n",
      "9021/9021 [==============================] - 0s 39us/sample - loss: 1.4785 - mae: 0.9751 - mse: 1.4785 - val_loss: 1.5026 - val_mae: 0.9846 - val_mse: 1.5026\n",
      "Epoch 919/1000\n",
      "9021/9021 [==============================] - 0s 53us/sample - loss: 1.4799 - mae: 0.9727 - mse: 1.4799 - val_loss: 1.5097 - val_mae: 0.9925 - val_mse: 1.5097\n",
      "Epoch 920/1000\n",
      "9021/9021 [==============================] - 1s 63us/sample - loss: 1.4784 - mae: 0.9747 - mse: 1.4784 - val_loss: 1.5022 - val_mae: 0.9938 - val_mse: 1.5022\n",
      "Epoch 921/1000\n",
      "9021/9021 [==============================] - 1s 60us/sample - loss: 1.4798 - mae: 0.9754 - mse: 1.4798 - val_loss: 1.5125 - val_mae: 0.9826 - val_mse: 1.5125\n",
      "Epoch 922/1000\n",
      "9021/9021 [==============================] - 1s 59us/sample - loss: 1.4770 - mae: 0.9741 - mse: 1.4770 - val_loss: 1.5165 - val_mae: 0.9836 - val_mse: 1.5165\n",
      "Epoch 923/1000\n",
      "9021/9021 [==============================] - 1s 57us/sample - loss: 1.4786 - mae: 0.9735 - mse: 1.4786 - val_loss: 1.5236 - val_mae: 0.9844 - val_mse: 1.5236\n",
      "Epoch 924/1000\n",
      "9021/9021 [==============================] - 0s 49us/sample - loss: 1.4786 - mae: 0.9739 - mse: 1.4786 - val_loss: 1.5053 - val_mae: 0.9906 - val_mse: 1.5053\n",
      "Epoch 925/1000\n",
      "9021/9021 [==============================] - 0s 41us/sample - loss: 1.4770 - mae: 0.9715 - mse: 1.4770 - val_loss: 1.4999 - val_mae: 0.9861 - val_mse: 1.4999\n",
      "Epoch 926/1000\n",
      "9021/9021 [==============================] - 0s 43us/sample - loss: 1.4782 - mae: 0.9733 - mse: 1.4782 - val_loss: 1.5039 - val_mae: 0.9930 - val_mse: 1.5039\n",
      "Epoch 927/1000\n",
      "9021/9021 [==============================] - 1s 59us/sample - loss: 1.4797 - mae: 0.9757 - mse: 1.4797 - val_loss: 1.5137 - val_mae: 0.9821 - val_mse: 1.5137\n",
      "Epoch 928/1000\n",
      "9021/9021 [==============================] - 0s 55us/sample - loss: 1.4773 - mae: 0.9733 - mse: 1.4773 - val_loss: 1.5181 - val_mae: 0.9839 - val_mse: 1.5181\n",
      "Epoch 929/1000\n",
      "9021/9021 [==============================] - 0s 37us/sample - loss: 1.4762 - mae: 0.9729 - mse: 1.4762 - val_loss: 1.5017 - val_mae: 0.9880 - val_mse: 1.5017\n",
      "Epoch 930/1000\n",
      "9021/9021 [==============================] - 0s 51us/sample - loss: 1.4740 - mae: 0.9721 - mse: 1.4740 - val_loss: 1.5072 - val_mae: 0.9899 - val_mse: 1.5072\n",
      "Epoch 931/1000\n",
      "9021/9021 [==============================] - 1s 68us/sample - loss: 1.4787 - mae: 0.9746 - mse: 1.4787 - val_loss: 1.5086 - val_mae: 0.9829 - val_mse: 1.5086\n",
      "Epoch 932/1000\n",
      "9021/9021 [==============================] - 1s 60us/sample - loss: 1.4784 - mae: 0.9733 - mse: 1.4784 - val_loss: 1.5072 - val_mae: 0.9896 - val_mse: 1.5072\n",
      "Epoch 933/1000\n",
      "9021/9021 [==============================] - 0s 38us/sample - loss: 1.4790 - mae: 0.9733 - mse: 1.4790 - val_loss: 1.5081 - val_mae: 0.9892 - val_mse: 1.5081\n",
      "Epoch 934/1000\n",
      "9021/9021 [==============================] - 0s 44us/sample - loss: 1.4784 - mae: 0.9744 - mse: 1.4784 - val_loss: 1.5048 - val_mae: 0.9892 - val_mse: 1.5048\n",
      "Epoch 935/1000\n",
      "9021/9021 [==============================] - 0s 45us/sample - loss: 1.4774 - mae: 0.9740 - mse: 1.4774 - val_loss: 1.5032 - val_mae: 0.9904 - val_mse: 1.5032\n",
      "Epoch 936/1000\n",
      "9021/9021 [==============================] - 0s 47us/sample - loss: 1.4794 - mae: 0.9745 - mse: 1.4794 - val_loss: 1.5056 - val_mae: 0.9847 - val_mse: 1.5056\n",
      "Epoch 937/1000\n",
      "9021/9021 [==============================] - 0s 43us/sample - loss: 1.4780 - mae: 0.9743 - mse: 1.4780 - val_loss: 1.5215 - val_mae: 0.9883 - val_mse: 1.5215\n",
      "Epoch 938/1000\n",
      "9021/9021 [==============================] - 0s 42us/sample - loss: 1.4781 - mae: 0.9734 - mse: 1.4781 - val_loss: 1.5037 - val_mae: 0.9880 - val_mse: 1.5037\n",
      "Epoch 939/1000\n",
      "9021/9021 [==============================] - 0s 39us/sample - loss: 1.4783 - mae: 0.9748 - mse: 1.4783 - val_loss: 1.5005 - val_mae: 0.9864 - val_mse: 1.5005\n",
      "Epoch 940/1000\n",
      "9021/9021 [==============================] - 0s 33us/sample - loss: 1.4770 - mae: 0.9733 - mse: 1.4770 - val_loss: 1.4997 - val_mae: 0.9834 - val_mse: 1.4997\n",
      "Epoch 941/1000\n",
      "9021/9021 [==============================] - 1s 56us/sample - loss: 1.4798 - mae: 0.9742 - mse: 1.4798 - val_loss: 1.5089 - val_mae: 0.9817 - val_mse: 1.5089\n",
      "Epoch 942/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9021/9021 [==============================] - 0s 45us/sample - loss: 1.4764 - mae: 0.9730 - mse: 1.4764 - val_loss: 1.5072 - val_mae: 0.9901 - val_mse: 1.5072\n",
      "Epoch 943/1000\n",
      "9021/9021 [==============================] - 0s 46us/sample - loss: 1.4787 - mae: 0.9744 - mse: 1.4787 - val_loss: 1.5041 - val_mae: 0.9858 - val_mse: 1.5041\n",
      "Epoch 944/1000\n",
      "9021/9021 [==============================] - 0s 50us/sample - loss: 1.4774 - mae: 0.9726 - mse: 1.4774 - val_loss: 1.5135 - val_mae: 0.9931 - val_mse: 1.5135\n",
      "Epoch 945/1000\n",
      "9021/9021 [==============================] - 0s 52us/sample - loss: 1.4784 - mae: 0.9742 - mse: 1.4784 - val_loss: 1.5033 - val_mae: 0.9891 - val_mse: 1.5033\n",
      "Epoch 946/1000\n",
      "9021/9021 [==============================] - 0s 55us/sample - loss: 1.4799 - mae: 0.9740 - mse: 1.4799 - val_loss: 1.5033 - val_mae: 0.9865 - val_mse: 1.5033\n",
      "Epoch 947/1000\n",
      "9021/9021 [==============================] - 1s 59us/sample - loss: 1.4784 - mae: 0.9744 - mse: 1.4784 - val_loss: 1.5005 - val_mae: 0.9874 - val_mse: 1.5005\n",
      "Epoch 948/1000\n",
      "9021/9021 [==============================] - 0s 50us/sample - loss: 1.4799 - mae: 0.9739 - mse: 1.4799 - val_loss: 1.5104 - val_mae: 0.9940 - val_mse: 1.5104\n",
      "Epoch 949/1000\n",
      "9021/9021 [==============================] - 1s 62us/sample - loss: 1.4780 - mae: 0.9738 - mse: 1.4780 - val_loss: 1.5075 - val_mae: 0.9820 - val_mse: 1.5075\n",
      "Epoch 950/1000\n",
      "9021/9021 [==============================] - 1s 62us/sample - loss: 1.4784 - mae: 0.9742 - mse: 1.4784 - val_loss: 1.5011 - val_mae: 0.9837 - val_mse: 1.5011\n",
      "Epoch 951/1000\n",
      "9021/9021 [==============================] - 0s 50us/sample - loss: 1.4787 - mae: 0.9738 - mse: 1.4787 - val_loss: 1.5085 - val_mae: 0.9815 - val_mse: 1.5085\n",
      "Epoch 952/1000\n",
      "9021/9021 [==============================] - 0s 51us/sample - loss: 1.4760 - mae: 0.9737 - mse: 1.4760 - val_loss: 1.4984 - val_mae: 0.9881 - val_mse: 1.4984\n",
      "Epoch 953/1000\n",
      "9021/9021 [==============================] - 0s 41us/sample - loss: 1.4796 - mae: 0.9742 - mse: 1.4796 - val_loss: 1.4985 - val_mae: 0.9790 - val_mse: 1.4985\n",
      "Epoch 954/1000\n",
      "9021/9021 [==============================] - 0s 44us/sample - loss: 1.4783 - mae: 0.9730 - mse: 1.4783 - val_loss: 1.5079 - val_mae: 0.9924 - val_mse: 1.5079\n",
      "Epoch 955/1000\n",
      "9021/9021 [==============================] - 0s 47us/sample - loss: 1.4756 - mae: 0.9744 - mse: 1.4756 - val_loss: 1.5076 - val_mae: 0.9799 - val_mse: 1.5076\n",
      "Epoch 956/1000\n",
      "9021/9021 [==============================] - 1s 63us/sample - loss: 1.4799 - mae: 0.9739 - mse: 1.4799 - val_loss: 1.5032 - val_mae: 0.9875 - val_mse: 1.5032\n",
      "Epoch 957/1000\n",
      "9021/9021 [==============================] - 0s 45us/sample - loss: 1.4767 - mae: 0.9722 - mse: 1.4767 - val_loss: 1.4984 - val_mae: 0.9863 - val_mse: 1.4984\n",
      "Epoch 958/1000\n",
      "9021/9021 [==============================] - 0s 35us/sample - loss: 1.4780 - mae: 0.9734 - mse: 1.4780 - val_loss: 1.5013 - val_mae: 0.9871 - val_mse: 1.5013\n",
      "Epoch 959/1000\n",
      "9021/9021 [==============================] - 0s 27us/sample - loss: 1.4788 - mae: 0.9751 - mse: 1.4788 - val_loss: 1.5059 - val_mae: 0.9875 - val_mse: 1.5059\n",
      "Epoch 960/1000\n",
      "9021/9021 [==============================] - 0s 29us/sample - loss: 1.4795 - mae: 0.9737 - mse: 1.4795 - val_loss: 1.5146 - val_mae: 0.9840 - val_mse: 1.5146\n",
      "Epoch 961/1000\n",
      "9021/9021 [==============================] - 0s 40us/sample - loss: 1.4790 - mae: 0.9738 - mse: 1.4790 - val_loss: 1.5020 - val_mae: 0.9880 - val_mse: 1.5020\n",
      "Epoch 962/1000\n",
      "9021/9021 [==============================] - 0s 51us/sample - loss: 1.4765 - mae: 0.9728 - mse: 1.4765 - val_loss: 1.5129 - val_mae: 0.9905 - val_mse: 1.5129\n",
      "Epoch 963/1000\n",
      "9021/9021 [==============================] - 0s 52us/sample - loss: 1.4790 - mae: 0.9748 - mse: 1.4790 - val_loss: 1.5084 - val_mae: 0.9898 - val_mse: 1.5084\n",
      "Epoch 964/1000\n",
      "9021/9021 [==============================] - 0s 52us/sample - loss: 1.4788 - mae: 0.9734 - mse: 1.4788 - val_loss: 1.5037 - val_mae: 0.9834 - val_mse: 1.5037\n",
      "Epoch 965/1000\n",
      "9021/9021 [==============================] - 0s 51us/sample - loss: 1.4786 - mae: 0.9732 - mse: 1.4786 - val_loss: 1.5050 - val_mae: 0.9915 - val_mse: 1.5050\n",
      "Epoch 966/1000\n",
      "9021/9021 [==============================] - 0s 42us/sample - loss: 1.4777 - mae: 0.9737 - mse: 1.4777 - val_loss: 1.5061 - val_mae: 0.9842 - val_mse: 1.5061\n",
      "Epoch 967/1000\n",
      "9021/9021 [==============================] - 0s 39us/sample - loss: 1.4768 - mae: 0.9734 - mse: 1.4768 - val_loss: 1.5070 - val_mae: 0.9842 - val_mse: 1.5070\n",
      "Epoch 968/1000\n",
      "9021/9021 [==============================] - 0s 41us/sample - loss: 1.4778 - mae: 0.9731 - mse: 1.4778 - val_loss: 1.5048 - val_mae: 0.9860 - val_mse: 1.5048\n",
      "Epoch 969/1000\n",
      "9021/9021 [==============================] - 0s 51us/sample - loss: 1.4778 - mae: 0.9738 - mse: 1.4778 - val_loss: 1.5076 - val_mae: 0.9898 - val_mse: 1.5076\n",
      "Epoch 970/1000\n",
      "9021/9021 [==============================] - 1s 59us/sample - loss: 1.4794 - mae: 0.9736 - mse: 1.4794 - val_loss: 1.5096 - val_mae: 0.9837 - val_mse: 1.5096\n",
      "Epoch 971/1000\n",
      "9021/9021 [==============================] - 0s 44us/sample - loss: 1.4760 - mae: 0.9731 - mse: 1.4760 - val_loss: 1.5060 - val_mae: 0.9831 - val_mse: 1.5060\n",
      "Epoch 972/1000\n",
      "9021/9021 [==============================] - 0s 36us/sample - loss: 1.4767 - mae: 0.9732 - mse: 1.4767 - val_loss: 1.5081 - val_mae: 0.9811 - val_mse: 1.5081\n",
      "Epoch 973/1000\n",
      "9021/9021 [==============================] - 0s 45us/sample - loss: 1.4757 - mae: 0.9732 - mse: 1.4757 - val_loss: 1.5077 - val_mae: 0.9808 - val_mse: 1.5077\n",
      "Epoch 974/1000\n",
      "9021/9021 [==============================] - 0s 46us/sample - loss: 1.4794 - mae: 0.9739 - mse: 1.4794 - val_loss: 1.5156 - val_mae: 0.9953 - val_mse: 1.5156\n",
      "Epoch 975/1000\n",
      "9021/9021 [==============================] - 0s 32us/sample - loss: 1.4771 - mae: 0.9728 - mse: 1.4771 - val_loss: 1.5134 - val_mae: 0.9928 - val_mse: 1.5134\n",
      "Epoch 976/1000\n",
      "9021/9021 [==============================] - 0s 38us/sample - loss: 1.4752 - mae: 0.9730 - mse: 1.4752 - val_loss: 1.5109 - val_mae: 0.9821 - val_mse: 1.5109\n",
      "Epoch 977/1000\n",
      "9021/9021 [==============================] - 0s 34us/sample - loss: 1.4777 - mae: 0.9741 - mse: 1.4777 - val_loss: 1.5083 - val_mae: 0.9854 - val_mse: 1.5083\n",
      "Epoch 978/1000\n",
      "9021/9021 [==============================] - 0s 43us/sample - loss: 1.4782 - mae: 0.9734 - mse: 1.4782 - val_loss: 1.4976 - val_mae: 0.9877 - val_mse: 1.4976\n",
      "Epoch 979/1000\n",
      "9021/9021 [==============================] - 0s 48us/sample - loss: 1.4759 - mae: 0.9738 - mse: 1.4759 - val_loss: 1.5044 - val_mae: 0.9832 - val_mse: 1.5044\n",
      "Epoch 980/1000\n",
      "9021/9021 [==============================] - 1s 56us/sample - loss: 1.4759 - mae: 0.9720 - mse: 1.4759 - val_loss: 1.5145 - val_mae: 0.9924 - val_mse: 1.5145\n",
      "Epoch 981/1000\n",
      "9021/9021 [==============================] - 0s 52us/sample - loss: 1.4789 - mae: 0.9739 - mse: 1.4789 - val_loss: 1.5060 - val_mae: 0.9866 - val_mse: 1.5060\n",
      "Epoch 982/1000\n",
      "9021/9021 [==============================] - 0s 49us/sample - loss: 1.4770 - mae: 0.9730 - mse: 1.4770 - val_loss: 1.4999 - val_mae: 0.9828 - val_mse: 1.4999\n",
      "Epoch 983/1000\n",
      "9021/9021 [==============================] - 0s 41us/sample - loss: 1.4769 - mae: 0.9738 - mse: 1.4769 - val_loss: 1.5031 - val_mae: 0.9841 - val_mse: 1.5031\n",
      "Epoch 984/1000\n",
      "9021/9021 [==============================] - 0s 38us/sample - loss: 1.4787 - mae: 0.9737 - mse: 1.4787 - val_loss: 1.5114 - val_mae: 0.9863 - val_mse: 1.5114\n",
      "Epoch 985/1000\n",
      "9021/9021 [==============================] - 0s 28us/sample - loss: 1.4772 - mae: 0.9739 - mse: 1.4772 - val_loss: 1.5043 - val_mae: 0.9831 - val_mse: 1.5043\n",
      "Epoch 986/1000\n",
      "9021/9021 [==============================] - 0s 30us/sample - loss: 1.4787 - mae: 0.9730 - mse: 1.4787 - val_loss: 1.4983 - val_mae: 0.9849 - val_mse: 1.4983\n",
      "Epoch 987/1000\n",
      "9021/9021 [==============================] - 0s 25us/sample - loss: 1.4781 - mae: 0.9733 - mse: 1.4781 - val_loss: 1.5173 - val_mae: 0.9805 - val_mse: 1.5173\n",
      "Epoch 988/1000\n",
      "9021/9021 [==============================] - 0s 32us/sample - loss: 1.4783 - mae: 0.9729 - mse: 1.4783 - val_loss: 1.5048 - val_mae: 0.9853 - val_mse: 1.5048\n",
      "Epoch 989/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9021/9021 [==============================] - 0s 26us/sample - loss: 1.4782 - mae: 0.9730 - mse: 1.4782 - val_loss: 1.4961 - val_mae: 0.9857 - val_mse: 1.4961\n",
      "Epoch 990/1000\n",
      "9021/9021 [==============================] - 0s 27us/sample - loss: 1.4802 - mae: 0.9760 - mse: 1.4802 - val_loss: 1.5019 - val_mae: 0.9886 - val_mse: 1.5019\n",
      "Epoch 991/1000\n",
      "9021/9021 [==============================] - 0s 27us/sample - loss: 1.4777 - mae: 0.9748 - mse: 1.4777 - val_loss: 1.5033 - val_mae: 0.9837 - val_mse: 1.5033\n",
      "Epoch 992/1000\n",
      "9021/9021 [==============================] - 0s 47us/sample - loss: 1.4757 - mae: 0.9730 - mse: 1.4757 - val_loss: 1.5086 - val_mae: 0.9900 - val_mse: 1.5086\n",
      "Epoch 993/1000\n",
      "9021/9021 [==============================] - 0s 34us/sample - loss: 1.4754 - mae: 0.9728 - mse: 1.4754 - val_loss: 1.5030 - val_mae: 0.9908 - val_mse: 1.5030\n",
      "Epoch 994/1000\n",
      "9021/9021 [==============================] - 0s 44us/sample - loss: 1.4775 - mae: 0.9745 - mse: 1.4775 - val_loss: 1.5150 - val_mae: 0.9891 - val_mse: 1.5150\n",
      "Epoch 995/1000\n",
      "9021/9021 [==============================] - 0s 43us/sample - loss: 1.4784 - mae: 0.9737 - mse: 1.4784 - val_loss: 1.5049 - val_mae: 0.9874 - val_mse: 1.5049\n",
      "Epoch 996/1000\n",
      "9021/9021 [==============================] - 0s 43us/sample - loss: 1.4765 - mae: 0.9730 - mse: 1.4764 - val_loss: 1.5043 - val_mae: 0.9865 - val_mse: 1.5043\n",
      "Epoch 997/1000\n",
      "9021/9021 [==============================] - 0s 46us/sample - loss: 1.4780 - mae: 0.9750 - mse: 1.4780 - val_loss: 1.5160 - val_mae: 0.9819 - val_mse: 1.5160\n",
      "Epoch 998/1000\n",
      "9021/9021 [==============================] - 0s 46us/sample - loss: 1.4785 - mae: 0.9733 - mse: 1.4785 - val_loss: 1.5218 - val_mae: 0.9819 - val_mse: 1.5218\n",
      "Epoch 999/1000\n",
      "9021/9021 [==============================] - 0s 48us/sample - loss: 1.4789 - mae: 0.9738 - mse: 1.4789 - val_loss: 1.4972 - val_mae: 0.9875 - val_mse: 1.4972\n",
      "Epoch 1000/1000\n",
      "9021/9021 [==============================] - 0s 44us/sample - loss: 1.4773 - mae: 0.9733 - mse: 1.4773 - val_loss: 1.5044 - val_mae: 0.9873 - val_mse: 1.5044\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 1000\n",
    "history = ks.fit(X_train,\n",
    "                 y_train,\n",
    "                 epochs=EPOCHS,\n",
    "                 batch_size=128,\n",
    "                 validation_split = 0.2,\n",
    "                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(a,b):\n",
    "    #print('pred :',a,'actual :',b)\n",
    "    if a == b:\n",
    "        result = 1\n",
    "    else:\n",
    "        result = 0\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.01645190829802634\n",
      "dt 0.038245839363242884\n",
      "rf 0.06393244945485976\n",
      "vr 0.050413008261131265\n",
      "ks 0.97206867\n"
     ]
    }
   ],
   "source": [
    "print('lr',lr.score(X_train, y_train))\n",
    "print('dt',dt.score(X_train, y_train))\n",
    "print('rf',rf.score(X_train, y_train))\n",
    "print('vr',vr.score(X_train, y_train))\n",
    "ks_test = ks.evaluate(X_train, y_train,verbose=0)\n",
    "print('ks',ks_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_pred_results(result,num):\n",
    "    score = check(result,y_test.loc[num])\n",
    "    return score\n",
    "\n",
    "def predictionTest(num,model):\n",
    "    p = X_test.loc[num].tolist()\n",
    "    result = model.predict([p]).flatten().round()\n",
    "    prediction = print_pred_results(int(result[0]),num)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = X_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random_nums = random.choices(numbers, k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vr score:  10 \n",
      "dt score:  10 \n",
      "rf score:  9 \n",
      "ks score:  9\n"
     ]
    }
   ],
   "source": [
    "a,b,c,d = [],[],[],[]\n",
    "for i in random_nums:\n",
    "    a.append(predictionTest(i,vr))\n",
    "    b.append(predictionTest(i,dt))\n",
    "    c.append(predictionTest(i,rf))\n",
    "    d.append(predictionTest(i,ks))\n",
    "print('vr score: ',sum(a),'\\ndt score: ',sum(b),'\\nrf score: ',sum(c),'\\nks score: ',sum(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cycle_prob_test(num,model):\n",
    "    p = X_test.iloc[num].tolist()\n",
    "    e = model.predict([p]).flatten()\n",
    "    e = e[0]\n",
    "    if e < 1:\n",
    "        e = 0\n",
    "    elif e < 2:\n",
    "        e = 1\n",
    "    return e\n",
    "\n",
    "def model_pred_test(model):\n",
    "    b = []\n",
    "    prob = []\n",
    "    random_nums = np.random.randint(low=1, high=58, size=(20))\n",
    "    for i in random_nums:\n",
    "        prob.append(cycle_prob_test(i,model))\n",
    "    df = pd.DataFrame(prob)\n",
    "    df = df.values\n",
    "    print('scores :\\n',df)\n",
    "    #print(df)\n",
    "    #return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'models/cpl_score_regressor.sav'\n",
    "pickle.dump(dt, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import cpl_main as cpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = '2020'\n",
    "team_ref = pd.read_csv('datasets/teams.csv')\n",
    "results = pd.read_csv(f'datasets/{year}/cpl-{year}-results.csv')\n",
    "stats = pd.read_csv(f'datasets/{year}/cpl-{year}-stats.csv')\n",
    "player_info = pd.read_csv(f'datasets/{year}/player-{year}-info.csv')\n",
    "results_brief = pd.read_csv(f'datasets/{year}/cpl-{year}-results_brief.csv')\n",
    "team_stats = pd.read_csv(f'datasets/{year}/cpl-{year}-team_stats.csv')\n",
    "schedule = pd.read_csv(f'datasets/{year}/cpl-{year}-schedule.csv')\n",
    "rated_forwards = pd.read_csv(f'datasets/{year}/cpl-{year}-forwards.csv')\n",
    "rated_midfielders = pd.read_csv(f'datasets/{year}/cpl-{year}-midfielders.csv')\n",
    "rated_defenders = pd.read_csv(f'datasets/{year}/cpl-{year}-defenders.csv')\n",
    "rated_keepers = pd.read_csv(f'datasets/{year}/cpl-{year}-keepers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'models/cpl_score_regressor.sav'\n",
    "cpl_score_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_pred_test(cpl_classifier_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valour FC Atletico Ottawa\n"
     ]
    }
   ],
   "source": [
    "# home side\n",
    "q1 = schedule.iloc[3]['home']\n",
    "# away side\n",
    "q2 = schedule.iloc[3]['away']\n",
    "print(q1,q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare = cpl.get_team_comparison(results_brief,q1,q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_x, t1_y = cpl.get_NB_data(compare,q1)\n",
    "t2_x, t2_y = cpl.get_NB_data(compare,q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game</th>\n",
       "      <th>home</th>\n",
       "      <th>away</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>II4</td>\n",
       "      <td>Valour FC</td>\n",
       "      <td>Atletico Ottawa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  game       home             away\n",
       "3  II4  Valour FC  Atletico Ottawa"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_info = schedule[schedule['home'] == q1]\n",
    "game_info = game_info[game_info['away'] == q2]\n",
    "game_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = game_info.iloc[0]['game']\n",
    "game_h = cpl.get_home_away_comparison(stats,game,q1)\n",
    "game_a = cpl.get_home_away_comparison(stats,game,q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/todd/anaconda3/lib/python3.7/site-packages/pandas/core/ops/array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n"
     ]
    }
   ],
   "source": [
    "home_roster = cpl.get_compare_roster(results,q1,team_stats,team_ref,rated_forwards,rated_midfielders,rated_defenders,rated_keepers,player_info)\n",
    "away_roster = cpl.get_compare_roster(results,q2,team_stats,team_ref,rated_forwards,rated_midfielders,rated_defenders,rated_keepers,player_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_overall_roster(game_roster):\n",
    "    b = []\n",
    "    for i in range(game_roster.shape[0]):\n",
    "        b.append(game_roster.iloc[i]['overall']) # get the player overall score for each player in the game\n",
    "    if len(b) < 16:\n",
    "        i = int(16 - len(b))\n",
    "        for j in range(0,i):\n",
    "            b.append(0)\n",
    "    db = pd.DataFrame(b[0:14])\n",
    "    db = db.T\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2    3    4     5     6     7     8    9    10 11 12 13\n",
       "0  0.55  0.45  0.21  0.0  0.0  0.41  0.35  0.33  0.16  0.3  0.05  0  0  0"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_roster = get_overall_roster(home_roster)\n",
    "q1_roster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2     3     4     5    6    7  8  9 10 11 12 13\n",
       "0  0.0  0.0  0.0  0.69  0.35  0.22  0.0  0.0  0  0  0  0  0  0"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_roster = get_overall_roster(away_roster)\n",
    "q2_roster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roster_regressor_pred(model,array):\n",
    "    prediction = model.predict([array]).flatten()\n",
    "    df = pd.DataFrame(prediction)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_win, draw, away_win = cpl.get_match_prediction(q1,q2,t1_x,t1_y,t2_x,t2_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = 'models/cpl_roster_classifier.sav'\n",
    "cpl_classifier_model = pickle.load(open(classifier, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_win_new, away_win_new, draw_new = cpl.get_final_game_prediction(cpl_classifier_model,q1_roster,q2_roster,home_win,away_win,draw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valour FC \n",
      "win probability:  0.39\n"
     ]
    }
   ],
   "source": [
    "print(q1,'\\nwin probability: ', round(home_win_new,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atletico Ottawa \n",
      "win probability:  0.31\n"
     ]
    }
   ],
   "source": [
    "print(q2,'\\nwin probability: ', round(away_win_new,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Draw probability:  0.3\n"
     ]
    }
   ],
   "source": [
    "print('Draw probability: ', round(draw_new,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_score_prediction(model,q1_roster,q2_roster,home_win_new,away_win_new):\n",
    "    \n",
    "    def final_score_fix(home_score,away_score,home_win_new,away_win_new):\n",
    "        if home_win_new > away_win_new: # fix the score prediction - if the probability of home win > away win\n",
    "            home_score = away_score + 1 # change the predicted score to reflect that\n",
    "            return home_score,away_score \n",
    "        elif home_win_new < away_win_new: # else the probability of home win < away win\n",
    "            away_score = home_score + 1 # change the predicted score to reflect that\n",
    "            return home_score,away_score  \n",
    "    \n",
    "    def score(num): #improve this later for greater predictions\n",
    "        new_score = int(round(num,0)) # convert the float value to int and round it\n",
    "        return new_score\n",
    "    \n",
    "    q1_pred = roster_pred(model,q1_roster)\n",
    "    q1_s = score(q1_pred.iloc[0][0])\n",
    "    q2_pred = roster_pred(model,q2_roster)\n",
    "    q2_s = score(q2_pred.iloc[0][0])\n",
    "    home_score, away_score = final_score_fix(q1_s, q2_s,home_win_new,away_win_new)\n",
    "    return home_score, away_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roster_pred(model,array):\n",
    "    prediction = model.predict([array]).flatten()\n",
    "    df = pd.DataFrame(prediction)\n",
    "    #print('score :',prediction)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_score, away_score = get_final_score_prediction(cpl_score_model,q1_roster,q2_roster,home_win_new,away_win_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 1\n"
     ]
    }
   ],
   "source": [
    "print(home_score, away_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_score_fix(home_score,away_score,home_win_new,away_win_new):\n",
    "    if home_win_new > away_win_new:\n",
    "        print('greater')\n",
    "        home_score = away_score + 1\n",
    "        return home_score,away_score \n",
    "    elif home_win_new < away_win_new:\n",
    "        print('less than')\n",
    "        away_score = home_score + 1\n",
    "        return home_score,away_score    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "greater\n"
     ]
    }
   ],
   "source": [
    "home_score, away_score = final_score_fix(home_score,away_score,home_win_new,away_win_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "home_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "away_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
