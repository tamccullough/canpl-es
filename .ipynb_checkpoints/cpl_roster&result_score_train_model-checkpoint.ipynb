{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cpl_main as cpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_ref = pd.read_csv('datasets/teams.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = '2019'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if year == '2019':\n",
    "    team_ref = team_ref[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team</th>\n",
       "      <th>city</th>\n",
       "      <th>province</th>\n",
       "      <th>short</th>\n",
       "      <th>colour</th>\n",
       "      <th>crest</th>\n",
       "      <th>link</th>\n",
       "      <th>wiki</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cavalry FC</td>\n",
       "      <td>Calgary</td>\n",
       "      <td>AB</td>\n",
       "      <td>CFC</td>\n",
       "      <td>cpl-cfc</td>\n",
       "      <td>cavalry_fc_nav.png</td>\n",
       "      <td>https://cavalryfc.canpl.ca/</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Cavalry_FC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FC Edmonton</td>\n",
       "      <td>Edmonton</td>\n",
       "      <td>AB</td>\n",
       "      <td>FCE</td>\n",
       "      <td>cpl-fce</td>\n",
       "      <td>FC_Edmonton_nav.png</td>\n",
       "      <td>https://fcedmonton.canpl.ca/</td>\n",
       "      <td>https://en.wikipedia.org/wiki/FC_Edmonton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Forge FC</td>\n",
       "      <td>Hamilton</td>\n",
       "      <td>ON</td>\n",
       "      <td>FFC</td>\n",
       "      <td>cpl-ffc</td>\n",
       "      <td>Forge_FC_nav.png</td>\n",
       "      <td>https://forgefc.canpl.ca/</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Forge_FC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HFX Wanderers FC</td>\n",
       "      <td>Halifax</td>\n",
       "      <td>NS</td>\n",
       "      <td>HFX</td>\n",
       "      <td>cpl-hfx</td>\n",
       "      <td>HFX_Wanderers_FC.png</td>\n",
       "      <td>https://hfxwanderersfc.canpl.ca/</td>\n",
       "      <td>https://en.wikipedia.org/wiki/HFX_Wanderers_FC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pacific FC</td>\n",
       "      <td>Langford</td>\n",
       "      <td>BC</td>\n",
       "      <td>PFC</td>\n",
       "      <td>cpl-pfc</td>\n",
       "      <td>Pacific_FC_nav.png</td>\n",
       "      <td>https://pacificfc.canpl.ca/</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Pacific_FC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Valour FC</td>\n",
       "      <td>Winnipeg</td>\n",
       "      <td>MB</td>\n",
       "      <td>VFC</td>\n",
       "      <td>cpl-vfc</td>\n",
       "      <td>Valour_FC_nav.png</td>\n",
       "      <td>https://valourfc.canpl.ca/</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Valour_FC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>York9 FC</td>\n",
       "      <td>York Region</td>\n",
       "      <td>ON</td>\n",
       "      <td>Y9</td>\n",
       "      <td>cpl-y9</td>\n",
       "      <td>York_9_FC_nav.png</td>\n",
       "      <td>https://york9fc.canpl.ca/</td>\n",
       "      <td>https://en.wikipedia.org/wiki/York9_FC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               team         city province short   colour  \\\n",
       "1        Cavalry FC      Calgary       AB   CFC  cpl-cfc   \n",
       "2       FC Edmonton     Edmonton       AB   FCE  cpl-fce   \n",
       "3          Forge FC     Hamilton       ON   FFC  cpl-ffc   \n",
       "4  HFX Wanderers FC      Halifax       NS   HFX  cpl-hfx   \n",
       "5        Pacific FC     Langford       BC   PFC  cpl-pfc   \n",
       "6         Valour FC     Winnipeg       MB   VFC  cpl-vfc   \n",
       "7          York9 FC  York Region       ON    Y9   cpl-y9   \n",
       "\n",
       "                  crest                              link  \\\n",
       "1    cavalry_fc_nav.png       https://cavalryfc.canpl.ca/   \n",
       "2   FC_Edmonton_nav.png      https://fcedmonton.canpl.ca/   \n",
       "3      Forge_FC_nav.png         https://forgefc.canpl.ca/   \n",
       "4  HFX_Wanderers_FC.png  https://hfxwanderersfc.canpl.ca/   \n",
       "5    Pacific_FC_nav.png       https://pacificfc.canpl.ca/   \n",
       "6     Valour_FC_nav.png        https://valourfc.canpl.ca/   \n",
       "7     York_9_FC_nav.png         https://york9fc.canpl.ca/   \n",
       "\n",
       "                                             wiki  \n",
       "1        https://en.wikipedia.org/wiki/Cavalry_FC  \n",
       "2       https://en.wikipedia.org/wiki/FC_Edmonton  \n",
       "3          https://en.wikipedia.org/wiki/Forge_FC  \n",
       "4  https://en.wikipedia.org/wiki/HFX_Wanderers_FC  \n",
       "5        https://en.wikipedia.org/wiki/Pacific_FC  \n",
       "6         https://en.wikipedia.org/wiki/Valour_FC  \n",
       "7          https://en.wikipedia.org/wiki/York9_FC  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(f'datasets/{year}/cpl-{year}-results.csv')\n",
    "stats = pd.read_csv(f'datasets/{year}/cpl-{year}-stats.csv')\n",
    "player_info = pd.read_csv(f'datasets/{year}/player-{year}-info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game</th>\n",
       "      <th>s</th>\n",
       "      <th>d</th>\n",
       "      <th>m</th>\n",
       "      <th>hs</th>\n",
       "      <th>as</th>\n",
       "      <th>home</th>\n",
       "      <th>hr</th>\n",
       "      <th>away</th>\n",
       "      <th>ar</th>\n",
       "      <th>csh</th>\n",
       "      <th>csa</th>\n",
       "      <th>combined</th>\n",
       "      <th>venue</th>\n",
       "      <th>links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I1</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Forge FC</td>\n",
       "      <td>D</td>\n",
       "      <td>York9 FC</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4-27-2019 Forge FC D 1-1 D York9 FC</td>\n",
       "      <td>Tim Hortons Field</td>\n",
       "      <td>https://canpl.ca/matchcentre/4ilfbdmlp4zuj7k3c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I2</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Pacific FC</td>\n",
       "      <td>W</td>\n",
       "      <td>HFX Wanderers FC</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4-28-2019 Pacific FC W 1-0 L HFX Wanderers FC</td>\n",
       "      <td>Westhills Stadium</td>\n",
       "      <td>https://canpl.ca/matchcentre/4itgc6bq5l5c7iv5k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Pacific FC</td>\n",
       "      <td>L</td>\n",
       "      <td>Valour FC</td>\n",
       "      <td>W</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5-1-2019 Pacific FC L 1-2 W Valour FC</td>\n",
       "      <td>Westhills Stadium</td>\n",
       "      <td>https://canpl.ca/matchcentre/4j6hzym2ji5zgrm0w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>HFX Wanderers FC</td>\n",
       "      <td>W</td>\n",
       "      <td>Forge FC</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5-4-2019 HFX Wanderers FC W 2-1 L Forge FC</td>\n",
       "      <td>Wanderers Grounds</td>\n",
       "      <td>https://canpl.ca/matchcentre/4jopa68wp2k7cntkj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Cavalry FC</td>\n",
       "      <td>W</td>\n",
       "      <td>York9 FC</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5-4-2019 Cavalry FC W 2-1 L York9 FC</td>\n",
       "      <td>ATCO Field</td>\n",
       "      <td>https://canpl.ca/matchcentre/4kj2hnlgvv3ncwouf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>I96</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>York9 FC</td>\n",
       "      <td>L</td>\n",
       "      <td>HFX Wanderers FC</td>\n",
       "      <td>W</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10-19-2019 York9 FC L 0-2 W HFX Wanderers FC</td>\n",
       "      <td>York Lions Stadium</td>\n",
       "      <td>https://canpl.ca/matchcentre/5opkqc01qgmjdcbho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>I97</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Cavalry FC</td>\n",
       "      <td>W</td>\n",
       "      <td>FC Edmonton</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10-19-2019 Cavalry FC W 3-1 L FC Edmonton</td>\n",
       "      <td>ATCO Field</td>\n",
       "      <td>https://canpl.ca/matchcentre/5nw6ub2q95ptd6n71...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>I98</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Pacific FC</td>\n",
       "      <td>W</td>\n",
       "      <td>Valour FC</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10-19-2019 Pacific FC W 2-0 L Valour FC</td>\n",
       "      <td>Westhills Stadium</td>\n",
       "      <td>https://canpl.ca/matchcentre/5opkqc01qgmjdcbho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>I99</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Forge FC</td>\n",
       "      <td>W</td>\n",
       "      <td>Cavalry FC</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10-26-2019 Forge FC W 1-0 L Cavalry FC</td>\n",
       "      <td>Tim Hortons Field</td>\n",
       "      <td>https://canpl.ca/matchcentre/7exzoqwijjljpmysg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>I100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cavalry FC</td>\n",
       "      <td>L</td>\n",
       "      <td>Forge FC</td>\n",
       "      <td>W</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11-2-2019 Cavalry FC L 0-1 W Forge FC</td>\n",
       "      <td>ATCO Field</td>\n",
       "      <td>https://canpl.ca/matchcentre/7f2xl06opfb8koy1j...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    game  s   d   m  hs  as              home hr              away ar  csh  \\\n",
       "0     I1  0  27   4   1   1          Forge FC  D          York9 FC  D    0   \n",
       "1     I2  0  28   4   1   0        Pacific FC  W  HFX Wanderers FC  L    1   \n",
       "2     I3  0   1   5   1   2        Pacific FC  L         Valour FC  W    0   \n",
       "3     I4  0   4   5   2   1  HFX Wanderers FC  W          Forge FC  L    0   \n",
       "4     I5  0   4   5   2   1        Cavalry FC  W          York9 FC  L    0   \n",
       "..   ... ..  ..  ..  ..  ..               ... ..               ... ..  ...   \n",
       "95   I96  1  19  10   0   2          York9 FC  L  HFX Wanderers FC  W    0   \n",
       "96   I97  1  19  10   3   1        Cavalry FC  W       FC Edmonton  L    0   \n",
       "97   I98  1  19  10   2   0        Pacific FC  W         Valour FC  L    1   \n",
       "98   I99  2  26  10   1   0          Forge FC  W        Cavalry FC  L    1   \n",
       "99  I100  2   2  11   0   1        Cavalry FC  L          Forge FC  W    0   \n",
       "\n",
       "    csa                                       combined               venue  \\\n",
       "0     0            4-27-2019 Forge FC D 1-1 D York9 FC   Tim Hortons Field   \n",
       "1     0  4-28-2019 Pacific FC W 1-0 L HFX Wanderers FC   Westhills Stadium   \n",
       "2     0          5-1-2019 Pacific FC L 1-2 W Valour FC   Westhills Stadium   \n",
       "3     0     5-4-2019 HFX Wanderers FC W 2-1 L Forge FC   Wanderers Grounds   \n",
       "4     0           5-4-2019 Cavalry FC W 2-1 L York9 FC          ATCO Field   \n",
       "..  ...                                            ...                 ...   \n",
       "95    1   10-19-2019 York9 FC L 0-2 W HFX Wanderers FC  York Lions Stadium   \n",
       "96    0      10-19-2019 Cavalry FC W 3-1 L FC Edmonton          ATCO Field   \n",
       "97    0        10-19-2019 Pacific FC W 2-0 L Valour FC   Westhills Stadium   \n",
       "98    0         10-26-2019 Forge FC W 1-0 L Cavalry FC   Tim Hortons Field   \n",
       "99    1          11-2-2019 Cavalry FC L 0-1 W Forge FC          ATCO Field   \n",
       "\n",
       "                                                links  \n",
       "0   https://canpl.ca/matchcentre/4ilfbdmlp4zuj7k3c...  \n",
       "1   https://canpl.ca/matchcentre/4itgc6bq5l5c7iv5k...  \n",
       "2   https://canpl.ca/matchcentre/4j6hzym2ji5zgrm0w...  \n",
       "3   https://canpl.ca/matchcentre/4jopa68wp2k7cntkj...  \n",
       "4   https://canpl.ca/matchcentre/4kj2hnlgvv3ncwouf...  \n",
       "..                                                ...  \n",
       "95  https://canpl.ca/matchcentre/5opkqc01qgmjdcbho...  \n",
       "96  https://canpl.ca/matchcentre/5nw6ub2q95ptd6n71...  \n",
       "97  https://canpl.ca/matchcentre/5opkqc01qgmjdcbho...  \n",
       "98  https://canpl.ca/matchcentre/7exzoqwijjljpmysg...  \n",
       "99  https://canpl.ca/matchcentre/7f2xl06opfb8koy1j...  \n",
       "\n",
       "[100 rows x 15 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_brief = pd.read_csv(f'datasets/{year}/cpl-{year}-results_brief.csv')\n",
    "team_stats = pd.read_csv(f'datasets/{year}/cpl-{year}-team_stats.csv')\n",
    "schedule = pd.read_csv(f'datasets/{year}/cpl-{year}-schedule.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rated_forwards = pd.read_csv(f'datasets/{year}/cpl-{year}-forwards.csv')\n",
    "rated_midfielders = pd.read_csv(f'datasets/{year}/cpl-{year}-midfielders.csv')\n",
    "rated_defenders = pd.read_csv(f'datasets/{year}/cpl-{year}-defenders.csv')\n",
    "rated_keepers = pd.read_csv(f'datasets/{year}/cpl-{year}-keepers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_games = results['game']\n",
    "if year == '2019':\n",
    "    get_games = get_games[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = cpl.get_game_roster_prediction(stats,get_games,rated_forwards,rated_midfielders,rated_defenders,rated_keepers,results,team_stats,team_ref,player_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = pd.DataFrame(array,columns=['game','team','p1','p2','p3','p4','p5','p6','p7','p8','p9','p9','p10','p11','p12','p13','r','s'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game</th>\n",
       "      <th>team</th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>p5</th>\n",
       "      <th>p6</th>\n",
       "      <th>p7</th>\n",
       "      <th>p8</th>\n",
       "      <th>p9</th>\n",
       "      <th>p9</th>\n",
       "      <th>p10</th>\n",
       "      <th>p11</th>\n",
       "      <th>p12</th>\n",
       "      <th>p13</th>\n",
       "      <th>r</th>\n",
       "      <th>s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I1</td>\n",
       "      <td>Forge FC</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I1</td>\n",
       "      <td>York9 FC</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I2</td>\n",
       "      <td>Pacific FC</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I2</td>\n",
       "      <td>HFX Wanderers FC</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I3</td>\n",
       "      <td>Pacific FC</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>I96</td>\n",
       "      <td>HFX Wanderers FC</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>I97</td>\n",
       "      <td>Cavalry FC</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>I97</td>\n",
       "      <td>FC Edmonton</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>I98</td>\n",
       "      <td>Pacific FC</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>I98</td>\n",
       "      <td>Valour FC</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    game              team    p1    p2    p3    p4    p5    p6    p7    p8  \\\n",
       "0     I1          Forge FC  0.71  0.89  0.74  0.71  0.48  0.89  0.77  0.52   \n",
       "1     I1          York9 FC  0.93  0.92  0.91  0.86  0.41  0.78  0.65  0.64   \n",
       "2     I2        Pacific FC  0.54  0.78  0.69  0.50  0.39  0.72  0.69  0.57   \n",
       "3     I2  HFX Wanderers FC  0.54  0.92  0.77  0.67  0.62  0.57  0.52  0.47   \n",
       "4     I3        Pacific FC  0.54  0.78  0.69  0.50  0.39  0.72  0.69  0.57   \n",
       "..   ...               ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "191  I96  HFX Wanderers FC  0.54  0.92  0.77  0.67  0.62  0.57  0.52  0.47   \n",
       "192  I97        Cavalry FC  0.79  0.91  0.75  0.37  0.33  0.87  0.66  0.66   \n",
       "193  I97       FC Edmonton  0.70  0.96  0.66  0.62  0.60  0.44  0.35  0.32   \n",
       "194  I98        Pacific FC  0.54  0.78  0.69  0.50  0.39  0.72  0.69  0.57   \n",
       "195  I98         Valour FC  0.55  0.73  0.71  0.60  0.45  0.90  0.64  0.60   \n",
       "\n",
       "       p9    p9   p10  p11  p12  p13  r  s  \n",
       "0    0.50  0.48  0.42    0    0    0  2  1  \n",
       "1    0.46  0.70  0.47    0    0    0  2  1  \n",
       "2    0.51  0.79  0.27    0    0    0  3  1  \n",
       "3    0.37  0.77  0.28    0    0    0  1  0  \n",
       "4    0.51  0.79  0.27    0    0    0  1  1  \n",
       "..    ...   ...   ...  ...  ...  ... .. ..  \n",
       "191  0.37  0.77  0.28    0    0    0  3  2  \n",
       "192  0.62  0.73  0.64    0    0    0  3  3  \n",
       "193  0.29  0.60  0.52    0    0    0  1  1  \n",
       "194  0.51  0.79  0.27    0    0    0  3  2  \n",
       "195  0.41  0.30  0.25    0    0    0  1  0  \n",
       "\n",
       "[196 rows x 18 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(196, 18)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pump_it_up(db):\n",
    "    df = db.copy()\n",
    "    dc = df.copy()\n",
    "    m = df['p1'].copy()\n",
    "    n = df['p2'].copy()\n",
    "    o = df['p3'].copy()\n",
    "    p = df['p4'].copy()\n",
    "    q = df['p5'].copy()\n",
    "    r = df['p6'].copy()\n",
    "    df['p1'] = dc.pop('p8')\n",
    "    df['p2'] = dc.pop('p10')\n",
    "    df['p3'] = dc.pop('p12')\n",
    "    df['p4'] = dc.pop('p9')\n",
    "    df['p5'] = dc.pop('p11')\n",
    "    df['p6'] = dc.pop('p13')\n",
    "    df['p7'] = m\n",
    "    df['p8'] = n\n",
    "    df['p9'] = o\n",
    "    df['p10'] = p\n",
    "    df['p11'] = q\n",
    "    df['p12'] = r\n",
    "    df['p13'] = dc.pop('p7')\n",
    "    dc = df.copy()\n",
    "    db = pd.concat([db,df])\n",
    "    df = dc.copy()\n",
    "    m = df['p13'].copy()\n",
    "    n = df['p12'].copy()\n",
    "    o = df['p11'].copy()\n",
    "    p = df['p10'].copy()\n",
    "    q = df['p9'].copy()\n",
    "    r = df['p8'].copy()\n",
    "    df['p13'] = dc.pop('p8')\n",
    "    df['p12'] = dc.pop('p10')\n",
    "    df['p11'] = dc.pop('p12')\n",
    "    df['p10'] = dc.pop('p9')\n",
    "    df['p9'] = dc.pop('p11')\n",
    "    df['p8'] = dc.pop('p13')\n",
    "    df['p7'] = m\n",
    "    df['p6'] = n\n",
    "    df['p5'] = o\n",
    "    df['p4'] = p\n",
    "    df['p3'] = q\n",
    "    df['p2'] = r\n",
    "    df['p1'] = dc.pop('p7')\n",
    "    #dc = df.copy()\n",
    "    db = pd.concat([db,df])\n",
    "    db = cpl.index_reset(db)\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(588, 18)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pump_it_up(db)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1764, 18)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = pump_it_up(df)\n",
    "db.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5292, 18)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pump_it_up(db)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15876, 18)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = pump_it_up(df)\n",
    "db.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.pop('game')\n",
    "db.pop('team')\n",
    "db.pop('r')\n",
    "y = db.pop('s')\n",
    "X = db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>p5</th>\n",
       "      <th>p6</th>\n",
       "      <th>p7</th>\n",
       "      <th>p8</th>\n",
       "      <th>p9</th>\n",
       "      <th>p9</th>\n",
       "      <th>p10</th>\n",
       "      <th>p11</th>\n",
       "      <th>p12</th>\n",
       "      <th>p13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     p1    p2    p3    p4    p5    p6    p7    p8    p9    p9   p10  p11  p12  \\\n",
       "0  0.71  0.89  0.74  0.71  0.48  0.89  0.77  0.52  0.50  0.48  0.42  0.0  0.0   \n",
       "1  0.93  0.92  0.91  0.86  0.41  0.78  0.65  0.64  0.46  0.70  0.47  0.0  0.0   \n",
       "\n",
       "   p13  \n",
       "0  0.0  \n",
       "1  0.0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries from sklearn\n",
    "from sklearn import tree\n",
    "#from sklearn.datasets import make_classification\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler#,Imputer\n",
    "from sklearn import metrics\n",
    "#colours = sns.set_palette('pastel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import algorithm modules\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeRegressor \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Model\n",
      "\n",
      "RMSE:  1.1736507648470385\n",
      "\n",
      "Score 5.12\n"
     ]
    }
   ],
   "source": [
    "#Linear Regression Model\n",
    "def linearRegression():\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "lr = linearRegression()\n",
    "\n",
    "print('Linear Regression Model')\n",
    "\n",
    "print('\\nRMSE: ', sqrt(mean_squared_error(y_test,lr.predict(X_test))))\n",
    "print('\\nScore',round(lr.score(X_test, y_test)*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Regression Model\n",
      "\n",
      "RMSE:  1.1642324472952517\n",
      "\n",
      "Score 6.64\n"
     ]
    }
   ],
   "source": [
    "#DecisionTreeRegressor\n",
    "def decisionTree():\n",
    "    model = DecisionTreeRegressor(criterion='mse', splitter='random', max_depth=8, max_features='log2')\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "dt = decisionTree()\n",
    "\n",
    "print('Decision Tree Regression Model')\n",
    "\n",
    "print('\\nRMSE: ', sqrt(mean_squared_error(y_test, dt.predict(X_test))))\n",
    "print('\\nScore',round(dt.score(X_test, y_test)*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regression Model\n",
      "\n",
      "RMSE:  1.1591353597954883\n",
      "\n",
      "Score 7.45\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Regression\n",
    "def forestRegression():\n",
    "    model = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "    \n",
    "rf = forestRegression()\n",
    "\n",
    "print('Random Forest Regression Model')\n",
    "\n",
    "print('\\nRMSE: ', sqrt(mean_squared_error(y_test,rf.predict(X_test))))\n",
    "print('\\nScore',round(rf.score(X_test, y_test)*100,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K_train = np.asarray(X_train).astype(np.float32)\n",
    "s_train = np.asarray(y_train).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingRegressor\n",
    "vr = VotingRegressor(estimators=[('lr', lr), ('dt', dt), ('rf', rf)])\n",
    "vr = vr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                960       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 5,185\n",
      "Trainable params: 5,185\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def kerasSequential():\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(64, activation='relu', input_shape=[X_train.shape[1]]),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "    model.compile(loss='mse',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['mae', 'mse'])\n",
    "    \n",
    "    return model\n",
    "ks = kerasSequential()\n",
    "\n",
    "ks.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_shapes(): # can make yours to take inputs; this'll use local variable values\n",
    "    print(\"Expected: (num_samples, timesteps, channels)\")\n",
    "    print(\"Sequences: {}\".format(Sequences.shape))\n",
    "    print(\"Targets:   {}\".format(Targets.shape))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.51019025],\n",
       "       [0.44022638],\n",
       "       [0.41147974],\n",
       "       [0.28481516],\n",
       "       [0.76664627],\n",
       "       [0.48423052],\n",
       "       [0.5113209 ],\n",
       "       [0.26493493],\n",
       "       [0.5837297 ],\n",
       "       [0.19780385]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_batch = X_train[:10]\n",
    "example_result = ks.predict(example_batch)\n",
    "example_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8890 samples, validate on 2223 samples\n",
      "Epoch 1/1000\n",
      "8890/8890 [==============================] - 2s 175us/sample - loss: 1.3994 - mae: 0.8985 - mse: 1.3994 - val_loss: 1.4011 - val_mae: 0.8835 - val_mse: 1.4011\n",
      "Epoch 2/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3593 - mae: 0.8891 - mse: 1.3593 - val_loss: 1.3929 - val_mae: 0.8861 - val_mse: 1.3929\n",
      "Epoch 3/1000\n",
      "8890/8890 [==============================] - 0s 41us/sample - loss: 1.3548 - mae: 0.8897 - mse: 1.3548 - val_loss: 1.4010 - val_mae: 0.9223 - val_mse: 1.4010\n",
      "Epoch 4/1000\n",
      "8890/8890 [==============================] - 0s 44us/sample - loss: 1.3487 - mae: 0.8877 - mse: 1.3487 - val_loss: 1.4200 - val_mae: 0.8630 - val_mse: 1.4200\n",
      "Epoch 5/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3470 - mae: 0.8846 - mse: 1.3470 - val_loss: 1.3817 - val_mae: 0.8999 - val_mse: 1.3817\n",
      "Epoch 6/1000\n",
      "8890/8890 [==============================] - 0s 42us/sample - loss: 1.3431 - mae: 0.8833 - mse: 1.3431 - val_loss: 1.3779 - val_mae: 0.8969 - val_mse: 1.3779\n",
      "Epoch 7/1000\n",
      "8890/8890 [==============================] - 0s 46us/sample - loss: 1.3399 - mae: 0.8815 - mse: 1.3399 - val_loss: 1.3780 - val_mae: 0.8787 - val_mse: 1.3780\n",
      "Epoch 8/1000\n",
      "8890/8890 [==============================] - 0s 45us/sample - loss: 1.3415 - mae: 0.8831 - mse: 1.3415 - val_loss: 1.3691 - val_mae: 0.8802 - val_mse: 1.3691\n",
      "Epoch 9/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3372 - mae: 0.8804 - mse: 1.3372 - val_loss: 1.3947 - val_mae: 0.8653 - val_mse: 1.3947\n",
      "Epoch 10/1000\n",
      "8890/8890 [==============================] - 0s 39us/sample - loss: 1.3373 - mae: 0.8807 - mse: 1.3373 - val_loss: 1.3672 - val_mae: 0.8804 - val_mse: 1.3672\n",
      "Epoch 11/1000\n",
      "8890/8890 [==============================] - 0s 41us/sample - loss: 1.3367 - mae: 0.8817 - mse: 1.3367 - val_loss: 1.3725 - val_mae: 0.8734 - val_mse: 1.3725\n",
      "Epoch 12/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3348 - mae: 0.8801 - mse: 1.3348 - val_loss: 1.3767 - val_mae: 0.8721 - val_mse: 1.3767\n",
      "Epoch 13/1000\n",
      "8890/8890 [==============================] - 0s 49us/sample - loss: 1.3317 - mae: 0.8787 - mse: 1.3317 - val_loss: 1.3679 - val_mae: 0.8941 - val_mse: 1.3679\n",
      "Epoch 14/1000\n",
      "8890/8890 [==============================] - 0s 52us/sample - loss: 1.3330 - mae: 0.8787 - mse: 1.3330 - val_loss: 1.3755 - val_mae: 0.9021 - val_mse: 1.3755\n",
      "Epoch 15/1000\n",
      "8890/8890 [==============================] - 1s 83us/sample - loss: 1.3315 - mae: 0.8803 - mse: 1.3315 - val_loss: 1.3683 - val_mae: 0.8895 - val_mse: 1.3683\n",
      "Epoch 16/1000\n",
      "8890/8890 [==============================] - 1s 95us/sample - loss: 1.3309 - mae: 0.8795 - mse: 1.3309 - val_loss: 1.3808 - val_mae: 0.8652 - val_mse: 1.3808\n",
      "Epoch 17/1000\n",
      "8890/8890 [==============================] - 1s 58us/sample - loss: 1.3301 - mae: 0.8779 - mse: 1.3301 - val_loss: 1.3685 - val_mae: 0.8773 - val_mse: 1.3685\n",
      "Epoch 18/1000\n",
      "8890/8890 [==============================] - 0s 51us/sample - loss: 1.3278 - mae: 0.8768 - mse: 1.3278 - val_loss: 1.3783 - val_mae: 0.8677 - val_mse: 1.3783\n",
      "Epoch 19/1000\n",
      "8890/8890 [==============================] - 1s 60us/sample - loss: 1.3268 - mae: 0.8770 - mse: 1.3268 - val_loss: 1.3668 - val_mae: 0.8739 - val_mse: 1.3668\n",
      "Epoch 20/1000\n",
      "8890/8890 [==============================] - 1s 69us/sample - loss: 1.3259 - mae: 0.8777 - mse: 1.3259 - val_loss: 1.3676 - val_mae: 0.8790 - val_mse: 1.3676\n",
      "Epoch 21/1000\n",
      "8890/8890 [==============================] - 1s 71us/sample - loss: 1.3247 - mae: 0.8773 - mse: 1.3247 - val_loss: 1.3643 - val_mae: 0.8739 - val_mse: 1.3643\n",
      "Epoch 22/1000\n",
      "8890/8890 [==============================] - 1s 131us/sample - loss: 1.3266 - mae: 0.8780 - mse: 1.3266 - val_loss: 1.3607 - val_mae: 0.8823 - val_mse: 1.3607\n",
      "Epoch 23/1000\n",
      "8890/8890 [==============================] - 1s 79us/sample - loss: 1.3287 - mae: 0.8781 - mse: 1.3287 - val_loss: 1.3703 - val_mae: 0.8872 - val_mse: 1.3703\n",
      "Epoch 24/1000\n",
      "8890/8890 [==============================] - 0s 48us/sample - loss: 1.3266 - mae: 0.8770 - mse: 1.3266 - val_loss: 1.3750 - val_mae: 0.9060 - val_mse: 1.3750\n",
      "Epoch 25/1000\n",
      "8890/8890 [==============================] - 0s 56us/sample - loss: 1.3246 - mae: 0.8780 - mse: 1.3246 - val_loss: 1.3634 - val_mae: 0.8757 - val_mse: 1.3634\n",
      "Epoch 26/1000\n",
      "8890/8890 [==============================] - 0s 47us/sample - loss: 1.3246 - mae: 0.8759 - mse: 1.3246 - val_loss: 1.3745 - val_mae: 0.9053 - val_mse: 1.3745\n",
      "Epoch 27/1000\n",
      "8890/8890 [==============================] - 0s 49us/sample - loss: 1.3233 - mae: 0.8771 - mse: 1.3233 - val_loss: 1.3653 - val_mae: 0.8754 - val_mse: 1.3653\n",
      "Epoch 28/1000\n",
      "8890/8890 [==============================] - 1s 77us/sample - loss: 1.3246 - mae: 0.8755 - mse: 1.3246 - val_loss: 1.3704 - val_mae: 0.8799 - val_mse: 1.3704\n",
      "Epoch 29/1000\n",
      "8890/8890 [==============================] - 1s 64us/sample - loss: 1.3252 - mae: 0.8764 - mse: 1.3252 - val_loss: 1.3571 - val_mae: 0.8835 - val_mse: 1.3571\n",
      "Epoch 30/1000\n",
      "8890/8890 [==============================] - 1s 76us/sample - loss: 1.3240 - mae: 0.8772 - mse: 1.3240 - val_loss: 1.3720 - val_mae: 0.9042 - val_mse: 1.3720\n",
      "Epoch 31/1000\n",
      "8890/8890 [==============================] - 1s 58us/sample - loss: 1.3243 - mae: 0.8781 - mse: 1.3243 - val_loss: 1.3803 - val_mae: 0.9110 - val_mse: 1.3803\n",
      "Epoch 32/1000\n",
      "8890/8890 [==============================] - 0s 53us/sample - loss: 1.3199 - mae: 0.8765 - mse: 1.3199 - val_loss: 1.3816 - val_mae: 0.9105 - val_mse: 1.3816\n",
      "Epoch 33/1000\n",
      "8890/8890 [==============================] - 1s 60us/sample - loss: 1.3225 - mae: 0.8775 - mse: 1.3225 - val_loss: 1.3594 - val_mae: 0.8895 - val_mse: 1.3594\n",
      "Epoch 34/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3234 - mae: 0.8768 - mse: 1.3234 - val_loss: 1.3660 - val_mae: 0.8872 - val_mse: 1.3660\n",
      "Epoch 35/1000\n",
      "8890/8890 [==============================] - 1s 65us/sample - loss: 1.3210 - mae: 0.8759 - mse: 1.3210 - val_loss: 1.3661 - val_mae: 0.8752 - val_mse: 1.3661\n",
      "Epoch 36/1000\n",
      "8890/8890 [==============================] - 1s 69us/sample - loss: 1.3222 - mae: 0.8753 - mse: 1.3222 - val_loss: 1.3608 - val_mae: 0.8831 - val_mse: 1.3608\n",
      "Epoch 37/1000\n",
      "8890/8890 [==============================] - 1s 57us/sample - loss: 1.3201 - mae: 0.8757 - mse: 1.3201 - val_loss: 1.3668 - val_mae: 0.8834 - val_mse: 1.3668\n",
      "Epoch 38/1000\n",
      "8890/8890 [==============================] - 0s 47us/sample - loss: 1.3196 - mae: 0.8760 - mse: 1.3196 - val_loss: 1.3629 - val_mae: 0.8715 - val_mse: 1.3629\n",
      "Epoch 39/1000\n",
      "8890/8890 [==============================] - 0s 56us/sample - loss: 1.3216 - mae: 0.8761 - mse: 1.3216 - val_loss: 1.3615 - val_mae: 0.8929 - val_mse: 1.3615\n",
      "Epoch 40/1000\n",
      "8890/8890 [==============================] - 0s 55us/sample - loss: 1.3182 - mae: 0.8751 - mse: 1.3182 - val_loss: 1.3584 - val_mae: 0.8907 - val_mse: 1.3584\n",
      "Epoch 41/1000\n",
      "8890/8890 [==============================] - 0s 50us/sample - loss: 1.3196 - mae: 0.8756 - mse: 1.3196 - val_loss: 1.3634 - val_mae: 0.8860 - val_mse: 1.3634\n",
      "Epoch 42/1000\n",
      "8890/8890 [==============================] - 0s 48us/sample - loss: 1.3181 - mae: 0.8752 - mse: 1.3181 - val_loss: 1.4117 - val_mae: 0.8711 - val_mse: 1.4117\n",
      "Epoch 43/1000\n",
      "8890/8890 [==============================] - 0s 44us/sample - loss: 1.3199 - mae: 0.8760 - mse: 1.3199 - val_loss: 1.3663 - val_mae: 0.9004 - val_mse: 1.3663\n",
      "Epoch 44/1000\n",
      "8890/8890 [==============================] - 0s 44us/sample - loss: 1.3194 - mae: 0.8771 - mse: 1.3194 - val_loss: 1.3629 - val_mae: 0.8930 - val_mse: 1.3629\n",
      "Epoch 45/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3179 - mae: 0.8758 - mse: 1.3179 - val_loss: 1.3748 - val_mae: 0.9067 - val_mse: 1.3748\n",
      "Epoch 46/1000\n",
      "8890/8890 [==============================] - 0s 46us/sample - loss: 1.3194 - mae: 0.8771 - mse: 1.3194 - val_loss: 1.3606 - val_mae: 0.8854 - val_mse: 1.3606\n",
      "Epoch 47/1000\n",
      "8890/8890 [==============================] - ETA: 0s - loss: 1.3090 - mae: 0.8743 - mse: 1.309 - 0s 55us/sample - loss: 1.3180 - mae: 0.8759 - mse: 1.3180 - val_loss: 1.3626 - val_mae: 0.8855 - val_mse: 1.3626\n",
      "Epoch 48/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8890/8890 [==============================] - 1s 66us/sample - loss: 1.3178 - mae: 0.8759 - mse: 1.3178 - val_loss: 1.3636 - val_mae: 0.8872 - val_mse: 1.3636\n",
      "Epoch 49/1000\n",
      "8890/8890 [==============================] - 0s 55us/sample - loss: 1.3179 - mae: 0.8764 - mse: 1.3179 - val_loss: 1.3585 - val_mae: 0.8883 - val_mse: 1.3585\n",
      "Epoch 50/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3154 - mae: 0.8760 - mse: 1.3154 - val_loss: 1.3620 - val_mae: 0.8833 - val_mse: 1.3620\n",
      "Epoch 51/1000\n",
      "8890/8890 [==============================] - 1s 57us/sample - loss: 1.3186 - mae: 0.8763 - mse: 1.3186 - val_loss: 1.3624 - val_mae: 0.8912 - val_mse: 1.3624\n",
      "Epoch 52/1000\n",
      "8890/8890 [==============================] - 1s 81us/sample - loss: 1.3154 - mae: 0.8751 - mse: 1.3154 - val_loss: 1.3690 - val_mae: 0.8998 - val_mse: 1.3690\n",
      "Epoch 53/1000\n",
      "8890/8890 [==============================] - 0s 43us/sample - loss: 1.3184 - mae: 0.8759 - mse: 1.3184 - val_loss: 1.3942 - val_mae: 0.8715 - val_mse: 1.3942\n",
      "Epoch 54/1000\n",
      "8890/8890 [==============================] - 0s 54us/sample - loss: 1.3164 - mae: 0.8751 - mse: 1.3164 - val_loss: 1.3584 - val_mae: 0.8841 - val_mse: 1.3584\n",
      "Epoch 55/1000\n",
      "8890/8890 [==============================] - 0s 46us/sample - loss: 1.3150 - mae: 0.8754 - mse: 1.3150 - val_loss: 1.3635 - val_mae: 0.8967 - val_mse: 1.3635\n",
      "Epoch 56/1000\n",
      "8890/8890 [==============================] - 0s 50us/sample - loss: 1.3197 - mae: 0.8768 - mse: 1.3197 - val_loss: 1.3724 - val_mae: 0.9074 - val_mse: 1.3724\n",
      "Epoch 57/1000\n",
      "8890/8890 [==============================] - 1s 60us/sample - loss: 1.3154 - mae: 0.8763 - mse: 1.3154 - val_loss: 1.3604 - val_mae: 0.8820 - val_mse: 1.3604\n",
      "Epoch 58/1000\n",
      "8890/8890 [==============================] - 1s 60us/sample - loss: 1.3167 - mae: 0.8766 - mse: 1.3167 - val_loss: 1.3682 - val_mae: 0.9022 - val_mse: 1.3682\n",
      "Epoch 59/1000\n",
      "8890/8890 [==============================] - 0s 44us/sample - loss: 1.3162 - mae: 0.8765 - mse: 1.3162 - val_loss: 1.3629 - val_mae: 0.8962 - val_mse: 1.3629\n",
      "Epoch 60/1000\n",
      "8890/8890 [==============================] - 1s 61us/sample - loss: 1.3148 - mae: 0.8751 - mse: 1.3148 - val_loss: 1.4055 - val_mae: 0.9269 - val_mse: 1.4055\n",
      "Epoch 61/1000\n",
      "8890/8890 [==============================] - 0s 55us/sample - loss: 1.3145 - mae: 0.8757 - mse: 1.3145 - val_loss: 1.3781 - val_mae: 0.8715 - val_mse: 1.3781\n",
      "Epoch 62/1000\n",
      "8890/8890 [==============================] - 0s 50us/sample - loss: 1.3145 - mae: 0.8751 - mse: 1.3145 - val_loss: 1.3600 - val_mae: 0.8884 - val_mse: 1.3600\n",
      "Epoch 63/1000\n",
      "8890/8890 [==============================] - 0s 39us/sample - loss: 1.3149 - mae: 0.8758 - mse: 1.3149 - val_loss: 1.3614 - val_mae: 0.8875 - val_mse: 1.3614\n",
      "Epoch 64/1000\n",
      "8890/8890 [==============================] - 0s 41us/sample - loss: 1.3149 - mae: 0.8750 - mse: 1.3149 - val_loss: 1.3974 - val_mae: 0.9246 - val_mse: 1.3974\n",
      "Epoch 65/1000\n",
      "8890/8890 [==============================] - 0s 39us/sample - loss: 1.3136 - mae: 0.8757 - mse: 1.3136 - val_loss: 1.4079 - val_mae: 0.9335 - val_mse: 1.4079\n",
      "Epoch 66/1000\n",
      "8890/8890 [==============================] - 0s 42us/sample - loss: 1.3158 - mae: 0.8763 - mse: 1.3158 - val_loss: 1.3600 - val_mae: 0.8799 - val_mse: 1.3600\n",
      "Epoch 67/1000\n",
      "8890/8890 [==============================] - 0s 49us/sample - loss: 1.3150 - mae: 0.8767 - mse: 1.3150 - val_loss: 1.3608 - val_mae: 0.8796 - val_mse: 1.3608\n",
      "Epoch 68/1000\n",
      "8890/8890 [==============================] - 0s 49us/sample - loss: 1.3146 - mae: 0.8755 - mse: 1.3146 - val_loss: 1.3670 - val_mae: 0.8721 - val_mse: 1.3670\n",
      "Epoch 69/1000\n",
      "8890/8890 [==============================] - 0s 44us/sample - loss: 1.3158 - mae: 0.8758 - mse: 1.3158 - val_loss: 1.3575 - val_mae: 0.8821 - val_mse: 1.3575\n",
      "Epoch 70/1000\n",
      "8890/8890 [==============================] - 0s 41us/sample - loss: 1.3131 - mae: 0.8753 - mse: 1.3131 - val_loss: 1.3626 - val_mae: 0.8921 - val_mse: 1.3626\n",
      "Epoch 71/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3158 - mae: 0.8765 - mse: 1.3158 - val_loss: 1.3717 - val_mae: 0.8756 - val_mse: 1.3717\n",
      "Epoch 72/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3136 - mae: 0.8761 - mse: 1.3136 - val_loss: 1.3770 - val_mae: 0.9047 - val_mse: 1.3770\n",
      "Epoch 73/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3110 - mae: 0.8750 - mse: 1.3110 - val_loss: 1.3754 - val_mae: 0.9056 - val_mse: 1.3754\n",
      "Epoch 74/1000\n",
      "8890/8890 [==============================] - 0s 31us/sample - loss: 1.3107 - mae: 0.8753 - mse: 1.3107 - val_loss: 1.3818 - val_mae: 0.8704 - val_mse: 1.3818\n",
      "Epoch 75/1000\n",
      "8890/8890 [==============================] - 1s 72us/sample - loss: 1.3141 - mae: 0.8751 - mse: 1.3141 - val_loss: 1.3641 - val_mae: 0.8744 - val_mse: 1.3641\n",
      "Epoch 76/1000\n",
      "8890/8890 [==============================] - 1s 56us/sample - loss: 1.3144 - mae: 0.8757 - mse: 1.3144 - val_loss: 1.3661 - val_mae: 0.8991 - val_mse: 1.3661\n",
      "Epoch 77/1000\n",
      "8890/8890 [==============================] - 0s 55us/sample - loss: 1.3136 - mae: 0.8754 - mse: 1.3136 - val_loss: 1.4314 - val_mae: 0.9456 - val_mse: 1.4314\n",
      "Epoch 78/1000\n",
      "8890/8890 [==============================] - 1s 64us/sample - loss: 1.3151 - mae: 0.8767 - mse: 1.3151 - val_loss: 1.3631 - val_mae: 0.8803 - val_mse: 1.3631\n",
      "Epoch 79/1000\n",
      "8890/8890 [==============================] - 0s 55us/sample - loss: 1.3123 - mae: 0.8741 - mse: 1.3123 - val_loss: 1.3663 - val_mae: 0.8916 - val_mse: 1.3663\n",
      "Epoch 80/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3140 - mae: 0.8755 - mse: 1.3140 - val_loss: 1.3671 - val_mae: 0.8737 - val_mse: 1.3671\n",
      "Epoch 81/1000\n",
      "8890/8890 [==============================] - 0s 51us/sample - loss: 1.3130 - mae: 0.8765 - mse: 1.3130 - val_loss: 1.3629 - val_mae: 0.8774 - val_mse: 1.3629\n",
      "Epoch 82/1000\n",
      "8890/8890 [==============================] - 0s 44us/sample - loss: 1.3152 - mae: 0.8765 - mse: 1.3152 - val_loss: 1.3659 - val_mae: 0.8783 - val_mse: 1.3659\n",
      "Epoch 83/1000\n",
      "8890/8890 [==============================] - 0s 48us/sample - loss: 1.3145 - mae: 0.8771 - mse: 1.3145 - val_loss: 1.3694 - val_mae: 0.8756 - val_mse: 1.3694\n",
      "Epoch 84/1000\n",
      "8890/8890 [==============================] - 0s 46us/sample - loss: 1.3125 - mae: 0.8756 - mse: 1.3125 - val_loss: 1.3672 - val_mae: 0.8731 - val_mse: 1.3672\n",
      "Epoch 85/1000\n",
      "8890/8890 [==============================] - 0s 50us/sample - loss: 1.3119 - mae: 0.8743 - mse: 1.3119 - val_loss: 1.3707 - val_mae: 0.8734 - val_mse: 1.3707\n",
      "Epoch 86/1000\n",
      "8890/8890 [==============================] - 1s 60us/sample - loss: 1.3136 - mae: 0.8755 - mse: 1.3136 - val_loss: 1.3811 - val_mae: 0.9134 - val_mse: 1.3811\n",
      "Epoch 87/1000\n",
      "8890/8890 [==============================] - 1s 63us/sample - loss: 1.3104 - mae: 0.8749 - mse: 1.3104 - val_loss: 1.3948 - val_mae: 0.8677 - val_mse: 1.3948\n",
      "Epoch 88/1000\n",
      "8890/8890 [==============================] - 0s 51us/sample - loss: 1.3145 - mae: 0.8763 - mse: 1.3145 - val_loss: 1.3659 - val_mae: 0.8970 - val_mse: 1.3659\n",
      "Epoch 89/1000\n",
      "8890/8890 [==============================] - 1s 59us/sample - loss: 1.3114 - mae: 0.8760 - mse: 1.3114 - val_loss: 1.3778 - val_mae: 0.9109 - val_mse: 1.3778\n",
      "Epoch 90/1000\n",
      "8890/8890 [==============================] - 0s 49us/sample - loss: 1.3086 - mae: 0.8750 - mse: 1.3086 - val_loss: 1.3590 - val_mae: 0.8854 - val_mse: 1.3590\n",
      "Epoch 91/1000\n",
      "8890/8890 [==============================] - 0s 39us/sample - loss: 1.3103 - mae: 0.8758 - mse: 1.3103 - val_loss: 1.3679 - val_mae: 0.8782 - val_mse: 1.3679\n",
      "Epoch 92/1000\n",
      "8890/8890 [==============================] - 0s 42us/sample - loss: 1.3115 - mae: 0.8751 - mse: 1.3115 - val_loss: 1.3762 - val_mae: 0.8766 - val_mse: 1.3762\n",
      "Epoch 93/1000\n",
      "8890/8890 [==============================] - 0s 45us/sample - loss: 1.3112 - mae: 0.8743 - mse: 1.3112 - val_loss: 1.3636 - val_mae: 0.8758 - val_mse: 1.3636\n",
      "Epoch 94/1000\n",
      "8890/8890 [==============================] - 1s 75us/sample - loss: 1.3120 - mae: 0.8750 - mse: 1.3120 - val_loss: 1.3897 - val_mae: 0.9158 - val_mse: 1.3897\n",
      "Epoch 95/1000\n",
      "8890/8890 [==============================] - 1s 67us/sample - loss: 1.3133 - mae: 0.8773 - mse: 1.3133 - val_loss: 1.3935 - val_mae: 0.8727 - val_mse: 1.3935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/1000\n",
      "8890/8890 [==============================] - 1s 61us/sample - loss: 1.3114 - mae: 0.8743 - mse: 1.3114 - val_loss: 1.3599 - val_mae: 0.8836 - val_mse: 1.3599\n",
      "Epoch 97/1000\n",
      "8890/8890 [==============================] - 0s 49us/sample - loss: 1.3108 - mae: 0.8749 - mse: 1.3108 - val_loss: 1.3760 - val_mae: 0.8709 - val_mse: 1.3760\n",
      "Epoch 98/1000\n",
      "8890/8890 [==============================] - 1s 63us/sample - loss: 1.3083 - mae: 0.8744 - mse: 1.3083 - val_loss: 1.3666 - val_mae: 0.9000 - val_mse: 1.3666\n",
      "Epoch 99/1000\n",
      "8890/8890 [==============================] - 0s 47us/sample - loss: 1.3129 - mae: 0.8759 - mse: 1.3129 - val_loss: 1.3638 - val_mae: 0.8967 - val_mse: 1.3638\n",
      "Epoch 100/1000\n",
      "8890/8890 [==============================] - 0s 47us/sample - loss: 1.3091 - mae: 0.8756 - mse: 1.3091 - val_loss: 1.3628 - val_mae: 0.8842 - val_mse: 1.3628\n",
      "Epoch 101/1000\n",
      "8890/8890 [==============================] - 0s 46us/sample - loss: 1.3124 - mae: 0.8762 - mse: 1.3124 - val_loss: 1.3615 - val_mae: 0.8913 - val_mse: 1.3615\n",
      "Epoch 102/1000\n",
      "8890/8890 [==============================] - 1s 68us/sample - loss: 1.3125 - mae: 0.8761 - mse: 1.3125 - val_loss: 1.3813 - val_mae: 0.8746 - val_mse: 1.3813\n",
      "Epoch 103/1000\n",
      "8890/8890 [==============================] - 0s 44us/sample - loss: 1.3106 - mae: 0.8756 - mse: 1.3106 - val_loss: 1.3853 - val_mae: 0.9134 - val_mse: 1.3853\n",
      "Epoch 104/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3140 - mae: 0.8761 - mse: 1.3140 - val_loss: 1.4096 - val_mae: 0.9353 - val_mse: 1.4096\n",
      "Epoch 105/1000\n",
      "8890/8890 [==============================] - 0s 42us/sample - loss: 1.3106 - mae: 0.8759 - mse: 1.3106 - val_loss: 1.3683 - val_mae: 0.8992 - val_mse: 1.3683\n",
      "Epoch 106/1000\n",
      "8890/8890 [==============================] - 0s 55us/sample - loss: 1.3085 - mae: 0.8739 - mse: 1.3085 - val_loss: 1.3583 - val_mae: 0.8816 - val_mse: 1.3583\n",
      "Epoch 107/1000\n",
      "8890/8890 [==============================] - 0s 46us/sample - loss: 1.3103 - mae: 0.8740 - mse: 1.3103 - val_loss: 1.3646 - val_mae: 0.8994 - val_mse: 1.3646\n",
      "Epoch 108/1000\n",
      "8890/8890 [==============================] - 1s 66us/sample - loss: 1.3090 - mae: 0.8754 - mse: 1.3090 - val_loss: 1.3667 - val_mae: 0.8994 - val_mse: 1.3667\n",
      "Epoch 109/1000\n",
      "8890/8890 [==============================] - 1s 59us/sample - loss: 1.3132 - mae: 0.8758 - mse: 1.3132 - val_loss: 1.3728 - val_mae: 0.9060 - val_mse: 1.3728\n",
      "Epoch 110/1000\n",
      "8890/8890 [==============================] - 0s 33us/sample - loss: 1.3092 - mae: 0.8743 - mse: 1.3092 - val_loss: 1.3664 - val_mae: 0.8781 - val_mse: 1.3664\n",
      "Epoch 111/1000\n",
      "8890/8890 [==============================] - 0s 51us/sample - loss: 1.3107 - mae: 0.8752 - mse: 1.3107 - val_loss: 1.3680 - val_mae: 0.9001 - val_mse: 1.3680\n",
      "Epoch 112/1000\n",
      "8890/8890 [==============================] - 0s 47us/sample - loss: 1.3079 - mae: 0.8743 - mse: 1.3079 - val_loss: 1.3760 - val_mae: 0.8721 - val_mse: 1.3760\n",
      "Epoch 113/1000\n",
      "8890/8890 [==============================] - 0s 53us/sample - loss: 1.3120 - mae: 0.8757 - mse: 1.3120 - val_loss: 1.3689 - val_mae: 0.9028 - val_mse: 1.3689\n",
      "Epoch 114/1000\n",
      "8890/8890 [==============================] - 0s 49us/sample - loss: 1.3099 - mae: 0.8757 - mse: 1.3099 - val_loss: 1.3649 - val_mae: 0.8789 - val_mse: 1.3649\n",
      "Epoch 115/1000\n",
      "8890/8890 [==============================] - 1s 73us/sample - loss: 1.3107 - mae: 0.8748 - mse: 1.3107 - val_loss: 1.3689 - val_mae: 0.8760 - val_mse: 1.3689\n",
      "Epoch 116/1000\n",
      "8890/8890 [==============================] - 1s 64us/sample - loss: 1.3102 - mae: 0.8742 - mse: 1.3102 - val_loss: 1.3661 - val_mae: 0.8978 - val_mse: 1.3661\n",
      "Epoch 117/1000\n",
      "8890/8890 [==============================] - 1s 72us/sample - loss: 1.3125 - mae: 0.8762 - mse: 1.3125 - val_loss: 1.3829 - val_mae: 0.8805 - val_mse: 1.3829\n",
      "Epoch 118/1000\n",
      "8890/8890 [==============================] - 0s 39us/sample - loss: 1.3106 - mae: 0.8744 - mse: 1.3106 - val_loss: 1.4515 - val_mae: 0.9564 - val_mse: 1.4515\n",
      "Epoch 119/1000\n",
      "8890/8890 [==============================] - 0s 41us/sample - loss: 1.3103 - mae: 0.8759 - mse: 1.3103 - val_loss: 1.3658 - val_mae: 0.8888 - val_mse: 1.3658\n",
      "Epoch 120/1000\n",
      "8890/8890 [==============================] - 0s 47us/sample - loss: 1.3115 - mae: 0.8751 - mse: 1.3115 - val_loss: 1.3602 - val_mae: 0.8883 - val_mse: 1.3602\n",
      "Epoch 121/1000\n",
      "8890/8890 [==============================] - 0s 42us/sample - loss: 1.3098 - mae: 0.8759 - mse: 1.3098 - val_loss: 1.3617 - val_mae: 0.8871 - val_mse: 1.3617\n",
      "Epoch 122/1000\n",
      "8890/8890 [==============================] - 0s 50us/sample - loss: 1.3091 - mae: 0.8749 - mse: 1.3091 - val_loss: 1.3631 - val_mae: 0.8942 - val_mse: 1.3631\n",
      "Epoch 123/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3110 - mae: 0.8754 - mse: 1.3110 - val_loss: 1.3705 - val_mae: 0.8771 - val_mse: 1.3705\n",
      "Epoch 124/1000\n",
      "8890/8890 [==============================] - 0s 56us/sample - loss: 1.3089 - mae: 0.8748 - mse: 1.3089 - val_loss: 1.3673 - val_mae: 0.8752 - val_mse: 1.3673\n",
      "Epoch 125/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3093 - mae: 0.8752 - mse: 1.3093 - val_loss: 1.3625 - val_mae: 0.8848 - val_mse: 1.3625\n",
      "Epoch 126/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3107 - mae: 0.8747 - mse: 1.3107 - val_loss: 1.3723 - val_mae: 0.9050 - val_mse: 1.3723\n",
      "Epoch 127/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3080 - mae: 0.8749 - mse: 1.3080 - val_loss: 1.3712 - val_mae: 0.8795 - val_mse: 1.3712\n",
      "Epoch 128/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3110 - mae: 0.8750 - mse: 1.3110 - val_loss: 1.3775 - val_mae: 0.9117 - val_mse: 1.3775\n",
      "Epoch 129/1000\n",
      "8890/8890 [==============================] - 0s 49us/sample - loss: 1.3083 - mae: 0.8750 - mse: 1.3083 - val_loss: 1.3766 - val_mae: 0.8751 - val_mse: 1.3766\n",
      "Epoch 130/1000\n",
      "8890/8890 [==============================] - 0s 48us/sample - loss: 1.3111 - mae: 0.8754 - mse: 1.3111 - val_loss: 1.3633 - val_mae: 0.8972 - val_mse: 1.3633\n",
      "Epoch 131/1000\n",
      "8890/8890 [==============================] - 0s 41us/sample - loss: 1.3108 - mae: 0.8763 - mse: 1.3108 - val_loss: 1.3612 - val_mae: 0.8881 - val_mse: 1.3612\n",
      "Epoch 132/1000\n",
      "8890/8890 [==============================] - 0s 45us/sample - loss: 1.3075 - mae: 0.8760 - mse: 1.3075 - val_loss: 1.3628 - val_mae: 0.8842 - val_mse: 1.3628\n",
      "Epoch 133/1000\n",
      "8890/8890 [==============================] - 0s 53us/sample - loss: 1.3113 - mae: 0.8749 - mse: 1.3113 - val_loss: 1.3638 - val_mae: 0.8772 - val_mse: 1.3638\n",
      "Epoch 134/1000\n",
      "8890/8890 [==============================] - 0s 49us/sample - loss: 1.3112 - mae: 0.8746 - mse: 1.3112 - val_loss: 1.3649 - val_mae: 0.8917 - val_mse: 1.3649\n",
      "Epoch 135/1000\n",
      "8890/8890 [==============================] - 0s 47us/sample - loss: 1.3109 - mae: 0.8762 - mse: 1.3109 - val_loss: 1.3627 - val_mae: 0.8905 - val_mse: 1.3627\n",
      "Epoch 136/1000\n",
      "8890/8890 [==============================] - 1s 62us/sample - loss: 1.3099 - mae: 0.8752 - mse: 1.3099 - val_loss: 1.3720 - val_mae: 0.9067 - val_mse: 1.3720\n",
      "Epoch 137/1000\n",
      "8890/8890 [==============================] - 0s 50us/sample - loss: 1.3095 - mae: 0.8758 - mse: 1.3095 - val_loss: 1.3631 - val_mae: 0.8884 - val_mse: 1.3631\n",
      "Epoch 138/1000\n",
      "8890/8890 [==============================] - 0s 33us/sample - loss: 1.3094 - mae: 0.8753 - mse: 1.3094 - val_loss: 1.3665 - val_mae: 0.8852 - val_mse: 1.3665\n",
      "Epoch 139/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3088 - mae: 0.8748 - mse: 1.3088 - val_loss: 1.3664 - val_mae: 0.8778 - val_mse: 1.3664\n",
      "Epoch 140/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3116 - mae: 0.8753 - mse: 1.3116 - val_loss: 1.3674 - val_mae: 0.8826 - val_mse: 1.3674\n",
      "Epoch 141/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3088 - mae: 0.8759 - mse: 1.3088 - val_loss: 1.3743 - val_mae: 0.8752 - val_mse: 1.3743\n",
      "Epoch 142/1000\n",
      "8890/8890 [==============================] - 0s 39us/sample - loss: 1.3115 - mae: 0.8748 - mse: 1.3115 - val_loss: 1.3606 - val_mae: 0.8896 - val_mse: 1.3606\n",
      "Epoch 143/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8890/8890 [==============================] - 0s 43us/sample - loss: 1.3075 - mae: 0.8746 - mse: 1.3075 - val_loss: 1.3656 - val_mae: 0.8991 - val_mse: 1.3656\n",
      "Epoch 144/1000\n",
      "8890/8890 [==============================] - 0s 41us/sample - loss: 1.3072 - mae: 0.8744 - mse: 1.3072 - val_loss: 1.3717 - val_mae: 0.8988 - val_mse: 1.3717\n",
      "Epoch 145/1000\n",
      "8890/8890 [==============================] - 0s 42us/sample - loss: 1.3094 - mae: 0.8757 - mse: 1.3094 - val_loss: 1.3770 - val_mae: 0.9114 - val_mse: 1.3770\n",
      "Epoch 146/1000\n",
      "8890/8890 [==============================] - 0s 33us/sample - loss: 1.3095 - mae: 0.8765 - mse: 1.3095 - val_loss: 1.3709 - val_mae: 0.9021 - val_mse: 1.3709\n",
      "Epoch 147/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3091 - mae: 0.8753 - mse: 1.3091 - val_loss: 1.3638 - val_mae: 0.8783 - val_mse: 1.3638\n",
      "Epoch 148/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3083 - mae: 0.8755 - mse: 1.3083 - val_loss: 1.3642 - val_mae: 0.8913 - val_mse: 1.3642\n",
      "Epoch 149/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3083 - mae: 0.8741 - mse: 1.3083 - val_loss: 1.3673 - val_mae: 0.8839 - val_mse: 1.3673\n",
      "Epoch 150/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3073 - mae: 0.8744 - mse: 1.3073 - val_loss: 1.3619 - val_mae: 0.8885 - val_mse: 1.3619\n",
      "Epoch 151/1000\n",
      "8890/8890 [==============================] - 0s 53us/sample - loss: 1.3082 - mae: 0.8740 - mse: 1.3082 - val_loss: 1.3936 - val_mae: 0.9226 - val_mse: 1.3936\n",
      "Epoch 152/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3100 - mae: 0.8750 - mse: 1.3100 - val_loss: 1.3865 - val_mae: 0.9152 - val_mse: 1.3865\n",
      "Epoch 153/1000\n",
      "8890/8890 [==============================] - 0s 32us/sample - loss: 1.3086 - mae: 0.8753 - mse: 1.3086 - val_loss: 1.3684 - val_mae: 0.8988 - val_mse: 1.3684\n",
      "Epoch 154/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3103 - mae: 0.8751 - mse: 1.3103 - val_loss: 1.3893 - val_mae: 0.9171 - val_mse: 1.3893\n",
      "Epoch 155/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3101 - mae: 0.8747 - mse: 1.3101 - val_loss: 1.3806 - val_mae: 0.8763 - val_mse: 1.3806\n",
      "Epoch 156/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3084 - mae: 0.8723 - mse: 1.3084 - val_loss: 1.3700 - val_mae: 0.9019 - val_mse: 1.3700\n",
      "Epoch 157/1000\n",
      "8890/8890 [==============================] - 0s 33us/sample - loss: 1.3069 - mae: 0.8746 - mse: 1.3069 - val_loss: 1.3731 - val_mae: 0.9066 - val_mse: 1.3731\n",
      "Epoch 158/1000\n",
      "8890/8890 [==============================] - 0s 32us/sample - loss: 1.3096 - mae: 0.8762 - mse: 1.3096 - val_loss: 1.3637 - val_mae: 0.8785 - val_mse: 1.3637\n",
      "Epoch 159/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3094 - mae: 0.8738 - mse: 1.3094 - val_loss: 1.3785 - val_mae: 0.9068 - val_mse: 1.3785\n",
      "Epoch 160/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3087 - mae: 0.8747 - mse: 1.3087 - val_loss: 1.3629 - val_mae: 0.8856 - val_mse: 1.3629\n",
      "Epoch 161/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3099 - mae: 0.8759 - mse: 1.3099 - val_loss: 1.4035 - val_mae: 0.9285 - val_mse: 1.4035\n",
      "Epoch 162/1000\n",
      "8890/8890 [==============================] - 0s 55us/sample - loss: 1.3091 - mae: 0.8750 - mse: 1.3091 - val_loss: 1.3911 - val_mae: 0.9197 - val_mse: 1.3911\n",
      "Epoch 163/1000\n",
      "8890/8890 [==============================] - 0s 33us/sample - loss: 1.3096 - mae: 0.8753 - mse: 1.3096 - val_loss: 1.3816 - val_mae: 0.9116 - val_mse: 1.3816\n",
      "Epoch 164/1000\n",
      "8890/8890 [==============================] - 1s 60us/sample - loss: 1.3058 - mae: 0.8729 - mse: 1.3058 - val_loss: 1.4433 - val_mae: 0.9505 - val_mse: 1.4433\n",
      "Epoch 165/1000\n",
      "8890/8890 [==============================] - 0s 51us/sample - loss: 1.3103 - mae: 0.8763 - mse: 1.3103 - val_loss: 1.3688 - val_mae: 0.8803 - val_mse: 1.3688\n",
      "Epoch 166/1000\n",
      "8890/8890 [==============================] - 0s 44us/sample - loss: 1.3099 - mae: 0.8744 - mse: 1.3099 - val_loss: 1.3735 - val_mae: 0.8910 - val_mse: 1.3735\n",
      "Epoch 167/1000\n",
      "8890/8890 [==============================] - 0s 41us/sample - loss: 1.3088 - mae: 0.8754 - mse: 1.3088 - val_loss: 1.3823 - val_mae: 0.9137 - val_mse: 1.3823\n",
      "Epoch 168/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3073 - mae: 0.8742 - mse: 1.3073 - val_loss: 1.3851 - val_mae: 0.9148 - val_mse: 1.3851\n",
      "Epoch 169/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3085 - mae: 0.8748 - mse: 1.3085 - val_loss: 1.3674 - val_mae: 0.8782 - val_mse: 1.3674\n",
      "Epoch 170/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3081 - mae: 0.8742 - mse: 1.3081 - val_loss: 1.3642 - val_mae: 0.8858 - val_mse: 1.3642\n",
      "Epoch 171/1000\n",
      "8890/8890 [==============================] - 0s 32us/sample - loss: 1.3102 - mae: 0.8752 - mse: 1.3102 - val_loss: 1.3684 - val_mae: 0.8785 - val_mse: 1.3684\n",
      "Epoch 172/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3093 - mae: 0.8748 - mse: 1.3093 - val_loss: 1.3745 - val_mae: 0.8799 - val_mse: 1.3745\n",
      "Epoch 173/1000\n",
      "8890/8890 [==============================] - 0s 33us/sample - loss: 1.3052 - mae: 0.8735 - mse: 1.3052 - val_loss: 1.3672 - val_mae: 0.8811 - val_mse: 1.3672\n",
      "Epoch 174/1000\n",
      "8890/8890 [==============================] - 0s 32us/sample - loss: 1.3091 - mae: 0.8747 - mse: 1.3091 - val_loss: 1.3651 - val_mae: 0.8888 - val_mse: 1.3651\n",
      "Epoch 175/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3091 - mae: 0.8749 - mse: 1.3091 - val_loss: 1.3659 - val_mae: 0.8849 - val_mse: 1.3659\n",
      "Epoch 176/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3077 - mae: 0.8741 - mse: 1.3077 - val_loss: 1.3862 - val_mae: 0.8766 - val_mse: 1.3862\n",
      "Epoch 177/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3078 - mae: 0.8745 - mse: 1.3078 - val_loss: 1.3661 - val_mae: 0.8855 - val_mse: 1.3661\n",
      "Epoch 178/1000\n",
      "8890/8890 [==============================] - 0s 50us/sample - loss: 1.3088 - mae: 0.8746 - mse: 1.3088 - val_loss: 1.3711 - val_mae: 0.8827 - val_mse: 1.3711\n",
      "Epoch 179/1000\n",
      "8890/8890 [==============================] - 1s 59us/sample - loss: 1.3102 - mae: 0.8745 - mse: 1.3102 - val_loss: 1.3606 - val_mae: 0.8875 - val_mse: 1.3606\n",
      "Epoch 180/1000\n",
      "8890/8890 [==============================] - 0s 44us/sample - loss: 1.3089 - mae: 0.8754 - mse: 1.3089 - val_loss: 1.3650 - val_mae: 0.8872 - val_mse: 1.3650\n",
      "Epoch 181/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3054 - mae: 0.8747 - mse: 1.3054 - val_loss: 1.3670 - val_mae: 0.8856 - val_mse: 1.3670\n",
      "Epoch 182/1000\n",
      "8890/8890 [==============================] - 0s 33us/sample - loss: 1.3059 - mae: 0.8734 - mse: 1.3059 - val_loss: 1.3746 - val_mae: 0.8872 - val_mse: 1.3746\n",
      "Epoch 183/1000\n",
      "8890/8890 [==============================] - 0s 43us/sample - loss: 1.3087 - mae: 0.8743 - mse: 1.3087 - val_loss: 1.3656 - val_mae: 0.8889 - val_mse: 1.3656\n",
      "Epoch 184/1000\n",
      "8890/8890 [==============================] - 0s 39us/sample - loss: 1.3064 - mae: 0.8729 - mse: 1.3064 - val_loss: 1.3744 - val_mae: 0.8856 - val_mse: 1.3744\n",
      "Epoch 185/1000\n",
      "8890/8890 [==============================] - 0s 39us/sample - loss: 1.3112 - mae: 0.8755 - mse: 1.3112 - val_loss: 1.3628 - val_mae: 0.8876 - val_mse: 1.3628\n",
      "Epoch 186/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3079 - mae: 0.8744 - mse: 1.3079 - val_loss: 1.3778 - val_mae: 0.9105 - val_mse: 1.3778\n",
      "Epoch 187/1000\n",
      "8890/8890 [==============================] - 0s 39us/sample - loss: 1.3063 - mae: 0.8744 - mse: 1.3063 - val_loss: 1.3654 - val_mae: 0.8822 - val_mse: 1.3654\n",
      "Epoch 188/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3090 - mae: 0.8748 - mse: 1.3090 - val_loss: 1.3699 - val_mae: 0.8813 - val_mse: 1.3699\n",
      "Epoch 189/1000\n",
      "8890/8890 [==============================] - 0s 39us/sample - loss: 1.3065 - mae: 0.8736 - mse: 1.3065 - val_loss: 1.3759 - val_mae: 0.8781 - val_mse: 1.3759\n",
      "Epoch 190/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3080 - mae: 0.8739 - mse: 1.3080 - val_loss: 1.3644 - val_mae: 0.8983 - val_mse: 1.3644\n",
      "Epoch 191/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3065 - mae: 0.8748 - mse: 1.3065 - val_loss: 1.3611 - val_mae: 0.8889 - val_mse: 1.3611\n",
      "Epoch 192/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3082 - mae: 0.8748 - mse: 1.3082 - val_loss: 1.3646 - val_mae: 0.8881 - val_mse: 1.3646\n",
      "Epoch 193/1000\n",
      "8890/8890 [==============================] - 0s 33us/sample - loss: 1.3083 - mae: 0.8735 - mse: 1.3083 - val_loss: 1.3637 - val_mae: 0.8947 - val_mse: 1.3637\n",
      "Epoch 194/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3085 - mae: 0.8750 - mse: 1.3085 - val_loss: 1.3738 - val_mae: 0.9079 - val_mse: 1.3738\n",
      "Epoch 195/1000\n",
      "8890/8890 [==============================] - 0s 51us/sample - loss: 1.3082 - mae: 0.8757 - mse: 1.3082 - val_loss: 1.3734 - val_mae: 0.8762 - val_mse: 1.3734\n",
      "Epoch 196/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3071 - mae: 0.8729 - mse: 1.3071 - val_loss: 1.3685 - val_mae: 0.8957 - val_mse: 1.3685\n",
      "Epoch 197/1000\n",
      "8890/8890 [==============================] - 0s 33us/sample - loss: 1.3043 - mae: 0.8732 - mse: 1.3043 - val_loss: 1.3657 - val_mae: 0.8817 - val_mse: 1.3657\n",
      "Epoch 198/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3042 - mae: 0.8723 - mse: 1.3042 - val_loss: 1.3858 - val_mae: 0.9163 - val_mse: 1.3858\n",
      "Epoch 199/1000\n",
      "8890/8890 [==============================] - 0s 39us/sample - loss: 1.3079 - mae: 0.8758 - mse: 1.3079 - val_loss: 1.3734 - val_mae: 0.8799 - val_mse: 1.3734\n",
      "Epoch 200/1000\n",
      "8890/8890 [==============================] - 0s 41us/sample - loss: 1.3069 - mae: 0.8744 - mse: 1.3069 - val_loss: 1.3827 - val_mae: 0.8757 - val_mse: 1.3827\n",
      "Epoch 201/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3077 - mae: 0.8736 - mse: 1.3077 - val_loss: 1.3624 - val_mae: 0.8841 - val_mse: 1.3624\n",
      "Epoch 202/1000\n",
      "8890/8890 [==============================] - 0s 50us/sample - loss: 1.3064 - mae: 0.8743 - mse: 1.3064 - val_loss: 1.3694 - val_mae: 0.8966 - val_mse: 1.3694\n",
      "Epoch 203/1000\n",
      "8890/8890 [==============================] - 0s 46us/sample - loss: 1.3061 - mae: 0.8733 - mse: 1.3061 - val_loss: 1.3603 - val_mae: 0.8815 - val_mse: 1.3603\n",
      "Epoch 204/1000\n",
      "8890/8890 [==============================] - 0s 46us/sample - loss: 1.3101 - mae: 0.8746 - mse: 1.3101 - val_loss: 1.3811 - val_mae: 0.9109 - val_mse: 1.3811\n",
      "Epoch 205/1000\n",
      "8890/8890 [==============================] - 0s 39us/sample - loss: 1.3057 - mae: 0.8745 - mse: 1.3057 - val_loss: 1.3745 - val_mae: 0.9017 - val_mse: 1.3745\n",
      "Epoch 206/1000\n",
      "8890/8890 [==============================] - 0s 44us/sample - loss: 1.3062 - mae: 0.8753 - mse: 1.3062 - val_loss: 1.3735 - val_mae: 0.9056 - val_mse: 1.3735\n",
      "Epoch 207/1000\n",
      "8890/8890 [==============================] - 0s 41us/sample - loss: 1.3091 - mae: 0.8753 - mse: 1.3091 - val_loss: 1.3654 - val_mae: 0.8813 - val_mse: 1.3654\n",
      "Epoch 208/1000\n",
      "8890/8890 [==============================] - 0s 42us/sample - loss: 1.3084 - mae: 0.8741 - mse: 1.3084 - val_loss: 1.3618 - val_mae: 0.8942 - val_mse: 1.3618\n",
      "Epoch 209/1000\n",
      "8890/8890 [==============================] - 0s 46us/sample - loss: 1.3062 - mae: 0.8749 - mse: 1.3062 - val_loss: 1.3843 - val_mae: 0.9142 - val_mse: 1.3843\n",
      "Epoch 210/1000\n",
      "8890/8890 [==============================] - 0s 49us/sample - loss: 1.3077 - mae: 0.8759 - mse: 1.3077 - val_loss: 1.3859 - val_mae: 0.8769 - val_mse: 1.3859\n",
      "Epoch 211/1000\n",
      "8890/8890 [==============================] - 0s 47us/sample - loss: 1.3080 - mae: 0.8741 - mse: 1.3080 - val_loss: 1.3739 - val_mae: 0.8792 - val_mse: 1.3739\n",
      "Epoch 212/1000\n",
      "8890/8890 [==============================] - 1s 58us/sample - loss: 1.3083 - mae: 0.8741 - mse: 1.3083 - val_loss: 1.3689 - val_mae: 0.8903 - val_mse: 1.3689\n",
      "Epoch 213/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3097 - mae: 0.8754 - mse: 1.3097 - val_loss: 1.3660 - val_mae: 0.8847 - val_mse: 1.3660\n",
      "Epoch 214/1000\n",
      "8890/8890 [==============================] - 0s 33us/sample - loss: 1.3053 - mae: 0.8737 - mse: 1.3053 - val_loss: 1.3662 - val_mae: 0.8856 - val_mse: 1.3662\n",
      "Epoch 215/1000\n",
      "8890/8890 [==============================] - 0s 43us/sample - loss: 1.3096 - mae: 0.8752 - mse: 1.3096 - val_loss: 1.3638 - val_mae: 0.8846 - val_mse: 1.3638\n",
      "Epoch 216/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3047 - mae: 0.8728 - mse: 1.3047 - val_loss: 1.3857 - val_mae: 0.9176 - val_mse: 1.3857\n",
      "Epoch 217/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3071 - mae: 0.8746 - mse: 1.3071 - val_loss: 1.3967 - val_mae: 0.9232 - val_mse: 1.3967\n",
      "Epoch 218/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3082 - mae: 0.8744 - mse: 1.3082 - val_loss: 1.3951 - val_mae: 0.9207 - val_mse: 1.3951\n",
      "Epoch 219/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3067 - mae: 0.8746 - mse: 1.3067 - val_loss: 1.3669 - val_mae: 0.8789 - val_mse: 1.3669\n",
      "Epoch 220/1000\n",
      "8890/8890 [==============================] - 0s 53us/sample - loss: 1.3078 - mae: 0.8740 - mse: 1.3078 - val_loss: 1.3634 - val_mae: 0.8883 - val_mse: 1.3634\n",
      "Epoch 221/1000\n",
      "8890/8890 [==============================] - 0s 54us/sample - loss: 1.3078 - mae: 0.8750 - mse: 1.3078 - val_loss: 1.3706 - val_mae: 0.9035 - val_mse: 1.3706\n",
      "Epoch 222/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3083 - mae: 0.8744 - mse: 1.3083 - val_loss: 1.3699 - val_mae: 0.9018 - val_mse: 1.3699\n",
      "Epoch 223/1000\n",
      "8890/8890 [==============================] - 0s 31us/sample - loss: 1.3063 - mae: 0.8737 - mse: 1.3063 - val_loss: 1.3642 - val_mae: 0.8837 - val_mse: 1.3642\n",
      "Epoch 224/1000\n",
      "8890/8890 [==============================] - 0s 42us/sample - loss: 1.3074 - mae: 0.8755 - mse: 1.3074 - val_loss: 1.3649 - val_mae: 0.8878 - val_mse: 1.3649\n",
      "Epoch 225/1000\n",
      "8890/8890 [==============================] - 0s 32us/sample - loss: 1.3050 - mae: 0.8741 - mse: 1.3050 - val_loss: 1.3711 - val_mae: 0.8797 - val_mse: 1.3711\n",
      "Epoch 226/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3086 - mae: 0.8745 - mse: 1.3086 - val_loss: 1.3713 - val_mae: 0.8748 - val_mse: 1.3713\n",
      "Epoch 227/1000\n",
      "8890/8890 [==============================] - 0s 33us/sample - loss: 1.3070 - mae: 0.8729 - mse: 1.3070 - val_loss: 1.3671 - val_mae: 0.8977 - val_mse: 1.3671\n",
      "Epoch 228/1000\n",
      "8890/8890 [==============================] - 0s 47us/sample - loss: 1.3063 - mae: 0.8746 - mse: 1.3063 - val_loss: 1.3900 - val_mae: 0.9164 - val_mse: 1.3900\n",
      "Epoch 229/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3086 - mae: 0.8751 - mse: 1.3086 - val_loss: 1.3776 - val_mae: 0.9089 - val_mse: 1.3776\n",
      "Epoch 230/1000\n",
      "8890/8890 [==============================] - 0s 51us/sample - loss: 1.3078 - mae: 0.8746 - mse: 1.3078 - val_loss: 1.3639 - val_mae: 0.8827 - val_mse: 1.3639\n",
      "Epoch 231/1000\n",
      "8890/8890 [==============================] - 0s 46us/sample - loss: 1.3067 - mae: 0.8738 - mse: 1.3067 - val_loss: 1.3681 - val_mae: 0.8783 - val_mse: 1.3681\n",
      "Epoch 232/1000\n",
      "8890/8890 [==============================] - 0s 41us/sample - loss: 1.3070 - mae: 0.8732 - mse: 1.3070 - val_loss: 1.3724 - val_mae: 0.8986 - val_mse: 1.3724\n",
      "Epoch 233/1000\n",
      "8890/8890 [==============================] - 0s 42us/sample - loss: 1.3072 - mae: 0.8751 - mse: 1.3072 - val_loss: 1.3751 - val_mae: 0.8743 - val_mse: 1.3751\n",
      "Epoch 234/1000\n",
      "8890/8890 [==============================] - 0s 50us/sample - loss: 1.3055 - mae: 0.8728 - mse: 1.3055 - val_loss: 1.3659 - val_mae: 0.8909 - val_mse: 1.3659\n",
      "Epoch 235/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3062 - mae: 0.8737 - mse: 1.3062 - val_loss: 1.3829 - val_mae: 0.9129 - val_mse: 1.3829\n",
      "Epoch 236/1000\n",
      "8890/8890 [==============================] - 0s 42us/sample - loss: 1.3070 - mae: 0.8755 - mse: 1.3070 - val_loss: 1.3637 - val_mae: 0.8841 - val_mse: 1.3637\n",
      "Epoch 237/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8890/8890 [==============================] - 0s 47us/sample - loss: 1.3070 - mae: 0.8741 - mse: 1.3070 - val_loss: 1.3660 - val_mae: 0.8864 - val_mse: 1.3660\n",
      "Epoch 238/1000\n",
      "8890/8890 [==============================] - ETA: 0s - loss: 1.2908 - mae: 0.8665 - mse: 1.290 - 0s 37us/sample - loss: 1.3075 - mae: 0.8735 - mse: 1.3075 - val_loss: 1.3658 - val_mae: 0.8976 - val_mse: 1.3658\n",
      "Epoch 239/1000\n",
      "8890/8890 [==============================] - 0s 45us/sample - loss: 1.3053 - mae: 0.8737 - mse: 1.3053 - val_loss: 1.3760 - val_mae: 0.8835 - val_mse: 1.3760\n",
      "Epoch 240/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3089 - mae: 0.8744 - mse: 1.3089 - val_loss: 1.3699 - val_mae: 0.9009 - val_mse: 1.3699\n",
      "Epoch 241/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3059 - mae: 0.8739 - mse: 1.3059 - val_loss: 1.3676 - val_mae: 0.8995 - val_mse: 1.3676\n",
      "Epoch 242/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3078 - mae: 0.8747 - mse: 1.3078 - val_loss: 1.3640 - val_mae: 0.8907 - val_mse: 1.3640\n",
      "Epoch 243/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3073 - mae: 0.8741 - mse: 1.3073 - val_loss: 1.3950 - val_mae: 0.8742 - val_mse: 1.3950\n",
      "Epoch 244/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3077 - mae: 0.8741 - mse: 1.3077 - val_loss: 1.3641 - val_mae: 0.8904 - val_mse: 1.3641\n",
      "Epoch 245/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3072 - mae: 0.8740 - mse: 1.3072 - val_loss: 1.3626 - val_mae: 0.8800 - val_mse: 1.3626\n",
      "Epoch 246/1000\n",
      "8890/8890 [==============================] - 0s 39us/sample - loss: 1.3071 - mae: 0.8732 - mse: 1.3071 - val_loss: 1.3656 - val_mae: 0.8935 - val_mse: 1.3656\n",
      "Epoch 247/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3073 - mae: 0.8746 - mse: 1.3073 - val_loss: 1.3735 - val_mae: 0.9007 - val_mse: 1.3735\n",
      "Epoch 248/1000\n",
      "8890/8890 [==============================] - 0s 42us/sample - loss: 1.3061 - mae: 0.8752 - mse: 1.3061 - val_loss: 1.3784 - val_mae: 0.8817 - val_mse: 1.3784\n",
      "Epoch 249/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3077 - mae: 0.8748 - mse: 1.3077 - val_loss: 1.3716 - val_mae: 0.9026 - val_mse: 1.3716\n",
      "Epoch 250/1000\n",
      "8890/8890 [==============================] - 0s 30us/sample - loss: 1.3065 - mae: 0.8739 - mse: 1.3065 - val_loss: 1.3751 - val_mae: 0.9044 - val_mse: 1.3751\n",
      "Epoch 251/1000\n",
      "8890/8890 [==============================] - 0s 41us/sample - loss: 1.3077 - mae: 0.8751 - mse: 1.3077 - val_loss: 1.3784 - val_mae: 0.9097 - val_mse: 1.3784\n",
      "Epoch 252/1000\n",
      "8890/8890 [==============================] - 0s 47us/sample - loss: 1.3060 - mae: 0.8747 - mse: 1.3060 - val_loss: 1.3712 - val_mae: 0.8769 - val_mse: 1.3712\n",
      "Epoch 253/1000\n",
      "8890/8890 [==============================] - 0s 42us/sample - loss: 1.3078 - mae: 0.8742 - mse: 1.3078 - val_loss: 1.3738 - val_mae: 0.9049 - val_mse: 1.3738\n",
      "Epoch 254/1000\n",
      "8890/8890 [==============================] - 0s 46us/sample - loss: 1.3057 - mae: 0.8731 - mse: 1.3057 - val_loss: 1.3876 - val_mae: 0.9130 - val_mse: 1.3876\n",
      "Epoch 255/1000\n",
      "8890/8890 [==============================] - 0s 43us/sample - loss: 1.3088 - mae: 0.8748 - mse: 1.3088 - val_loss: 1.3638 - val_mae: 0.8837 - val_mse: 1.3638\n",
      "Epoch 256/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3073 - mae: 0.8737 - mse: 1.3073 - val_loss: 1.3642 - val_mae: 0.8907 - val_mse: 1.3642\n",
      "Epoch 257/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3073 - mae: 0.8739 - mse: 1.3073 - val_loss: 1.3694 - val_mae: 0.8839 - val_mse: 1.3694\n",
      "Epoch 258/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3061 - mae: 0.8737 - mse: 1.3061 - val_loss: 1.3722 - val_mae: 0.9020 - val_mse: 1.3722\n",
      "Epoch 259/1000\n",
      "8890/8890 [==============================] - 0s 39us/sample - loss: 1.3073 - mae: 0.8744 - mse: 1.3073 - val_loss: 1.3714 - val_mae: 0.9008 - val_mse: 1.3714\n",
      "Epoch 260/1000\n",
      "8890/8890 [==============================] - 0s 43us/sample - loss: 1.3059 - mae: 0.8743 - mse: 1.3059 - val_loss: 1.3670 - val_mae: 0.8946 - val_mse: 1.3670\n",
      "Epoch 261/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3072 - mae: 0.8735 - mse: 1.3072 - val_loss: 1.3654 - val_mae: 0.8826 - val_mse: 1.3654\n",
      "Epoch 262/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3071 - mae: 0.8742 - mse: 1.3071 - val_loss: 1.3644 - val_mae: 0.8964 - val_mse: 1.3644\n",
      "Epoch 263/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3042 - mae: 0.8738 - mse: 1.3042 - val_loss: 1.3752 - val_mae: 0.8866 - val_mse: 1.3752\n",
      "Epoch 264/1000\n",
      "8890/8890 [==============================] - 0s 44us/sample - loss: 1.3061 - mae: 0.8733 - mse: 1.3061 - val_loss: 1.3787 - val_mae: 0.8769 - val_mse: 1.3787\n",
      "Epoch 265/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3075 - mae: 0.8737 - mse: 1.3075 - val_loss: 1.3711 - val_mae: 0.8920 - val_mse: 1.3711\n",
      "Epoch 266/1000\n",
      "8890/8890 [==============================] - 0s 39us/sample - loss: 1.3063 - mae: 0.8729 - mse: 1.3063 - val_loss: 1.3767 - val_mae: 0.9092 - val_mse: 1.3767\n",
      "Epoch 267/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3058 - mae: 0.8744 - mse: 1.3058 - val_loss: 1.3737 - val_mae: 0.8756 - val_mse: 1.3737\n",
      "Epoch 268/1000\n",
      "8890/8890 [==============================] - 0s 39us/sample - loss: 1.3076 - mae: 0.8739 - mse: 1.3076 - val_loss: 1.3667 - val_mae: 0.8922 - val_mse: 1.3667\n",
      "Epoch 269/1000\n",
      "8890/8890 [==============================] - 1s 69us/sample - loss: 1.3055 - mae: 0.8726 - mse: 1.3055 - val_loss: 1.3725 - val_mae: 0.9043 - val_mse: 1.3725\n",
      "Epoch 270/1000\n",
      "8890/8890 [==============================] - 0s 54us/sample - loss: 1.3049 - mae: 0.8739 - mse: 1.3049 - val_loss: 1.3718 - val_mae: 0.8796 - val_mse: 1.3718\n",
      "Epoch 271/1000\n",
      "8890/8890 [==============================] - 1s 77us/sample - loss: 1.3080 - mae: 0.8734 - mse: 1.3080 - val_loss: 1.3820 - val_mae: 0.9149 - val_mse: 1.3820\n",
      "Epoch 272/1000\n",
      "8890/8890 [==============================] - 0s 43us/sample - loss: 1.3050 - mae: 0.8737 - mse: 1.3050 - val_loss: 1.3660 - val_mae: 0.8833 - val_mse: 1.3660\n",
      "Epoch 273/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3070 - mae: 0.8739 - mse: 1.3070 - val_loss: 1.3685 - val_mae: 0.8984 - val_mse: 1.3685\n",
      "Epoch 274/1000\n",
      "8890/8890 [==============================] - 1s 58us/sample - loss: 1.3045 - mae: 0.8734 - mse: 1.3045 - val_loss: 1.3757 - val_mae: 0.9057 - val_mse: 1.3757\n",
      "Epoch 275/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3062 - mae: 0.8744 - mse: 1.3062 - val_loss: 1.3667 - val_mae: 0.8845 - val_mse: 1.3667\n",
      "Epoch 276/1000\n",
      "8890/8890 [==============================] - 0s 33us/sample - loss: 1.3056 - mae: 0.8730 - mse: 1.3056 - val_loss: 1.3715 - val_mae: 0.8836 - val_mse: 1.3715\n",
      "Epoch 277/1000\n",
      "8890/8890 [==============================] - 0s 42us/sample - loss: 1.3050 - mae: 0.8740 - mse: 1.3050 - val_loss: 1.3630 - val_mae: 0.8865 - val_mse: 1.3630\n",
      "Epoch 278/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3054 - mae: 0.8741 - mse: 1.3054 - val_loss: 1.3689 - val_mae: 0.8987 - val_mse: 1.3689\n",
      "Epoch 279/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3054 - mae: 0.8738 - mse: 1.3054 - val_loss: 1.3709 - val_mae: 0.8783 - val_mse: 1.3709\n",
      "Epoch 280/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3050 - mae: 0.8738 - mse: 1.3050 - val_loss: 1.3923 - val_mae: 0.8740 - val_mse: 1.3923\n",
      "Epoch 281/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3080 - mae: 0.8729 - mse: 1.3080 - val_loss: 1.3658 - val_mae: 0.8935 - val_mse: 1.3658\n",
      "Epoch 282/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3063 - mae: 0.8744 - mse: 1.3063 - val_loss: 1.3647 - val_mae: 0.8876 - val_mse: 1.3647\n",
      "Epoch 283/1000\n",
      "8890/8890 [==============================] - 0s 46us/sample - loss: 1.3056 - mae: 0.8731 - mse: 1.3056 - val_loss: 1.4287 - val_mae: 0.9440 - val_mse: 1.4287\n",
      "Epoch 284/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3067 - mae: 0.8747 - mse: 1.3067 - val_loss: 1.3710 - val_mae: 0.8828 - val_mse: 1.3710\n",
      "Epoch 285/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3057 - mae: 0.8732 - mse: 1.3057 - val_loss: 1.3675 - val_mae: 0.8940 - val_mse: 1.3675\n",
      "Epoch 286/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3049 - mae: 0.8733 - mse: 1.3049 - val_loss: 1.3715 - val_mae: 0.9041 - val_mse: 1.3715\n",
      "Epoch 287/1000\n",
      "8890/8890 [==============================] - 0s 44us/sample - loss: 1.3070 - mae: 0.8753 - mse: 1.3070 - val_loss: 1.3651 - val_mae: 0.8904 - val_mse: 1.3651\n",
      "Epoch 288/1000\n",
      "8890/8890 [==============================] - 0s 47us/sample - loss: 1.3058 - mae: 0.8745 - mse: 1.3058 - val_loss: 1.3741 - val_mae: 0.9069 - val_mse: 1.3741\n",
      "Epoch 289/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3070 - mae: 0.8742 - mse: 1.3070 - val_loss: 1.3796 - val_mae: 0.9112 - val_mse: 1.3796\n",
      "Epoch 290/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3069 - mae: 0.8746 - mse: 1.3069 - val_loss: 1.3784 - val_mae: 0.9069 - val_mse: 1.3784\n",
      "Epoch 291/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3066 - mae: 0.8744 - mse: 1.3066 - val_loss: 1.3788 - val_mae: 0.8753 - val_mse: 1.3788\n",
      "Epoch 292/1000\n",
      "8890/8890 [==============================] - 0s 42us/sample - loss: 1.3060 - mae: 0.8741 - mse: 1.3060 - val_loss: 1.3837 - val_mae: 0.8741 - val_mse: 1.3837\n",
      "Epoch 293/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3057 - mae: 0.8731 - mse: 1.3057 - val_loss: 1.3657 - val_mae: 0.8900 - val_mse: 1.3657\n",
      "Epoch 294/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3052 - mae: 0.8733 - mse: 1.3052 - val_loss: 1.3657 - val_mae: 0.8872 - val_mse: 1.3657\n",
      "Epoch 295/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3057 - mae: 0.8737 - mse: 1.3057 - val_loss: 1.3649 - val_mae: 0.8921 - val_mse: 1.3649\n",
      "Epoch 296/1000\n",
      "8890/8890 [==============================] - 0s 54us/sample - loss: 1.3060 - mae: 0.8738 - mse: 1.3060 - val_loss: 1.3673 - val_mae: 0.8866 - val_mse: 1.3673\n",
      "Epoch 297/1000\n",
      "8890/8890 [==============================] - 0s 49us/sample - loss: 1.3056 - mae: 0.8730 - mse: 1.3056 - val_loss: 1.3679 - val_mae: 0.8936 - val_mse: 1.3679\n",
      "Epoch 298/1000\n",
      "8890/8890 [==============================] - 0s 45us/sample - loss: 1.3065 - mae: 0.8738 - mse: 1.3065 - val_loss: 1.3740 - val_mae: 0.9053 - val_mse: 1.3740\n",
      "Epoch 299/1000\n",
      "8890/8890 [==============================] - 0s 39us/sample - loss: 1.3035 - mae: 0.8732 - mse: 1.3035 - val_loss: 1.3629 - val_mae: 0.8891 - val_mse: 1.3629\n",
      "Epoch 300/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3045 - mae: 0.8742 - mse: 1.3045 - val_loss: 1.3669 - val_mae: 0.8814 - val_mse: 1.3669\n",
      "Epoch 301/1000\n",
      "8890/8890 [==============================] - 0s 33us/sample - loss: 1.3057 - mae: 0.8745 - mse: 1.3057 - val_loss: 1.3712 - val_mae: 0.8866 - val_mse: 1.3712\n",
      "Epoch 302/1000\n",
      "8890/8890 [==============================] - 0s 33us/sample - loss: 1.3062 - mae: 0.8741 - mse: 1.3062 - val_loss: 1.3760 - val_mae: 0.8767 - val_mse: 1.3760\n",
      "Epoch 303/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3057 - mae: 0.8728 - mse: 1.3057 - val_loss: 1.3640 - val_mae: 0.8877 - val_mse: 1.3640\n",
      "Epoch 304/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3057 - mae: 0.8744 - mse: 1.3057 - val_loss: 1.3645 - val_mae: 0.8939 - val_mse: 1.3645\n",
      "Epoch 305/1000\n",
      "8890/8890 [==============================] - 0s 33us/sample - loss: 1.3057 - mae: 0.8748 - mse: 1.3057 - val_loss: 1.3704 - val_mae: 0.8997 - val_mse: 1.3704\n",
      "Epoch 306/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3063 - mae: 0.8746 - mse: 1.3063 - val_loss: 1.3675 - val_mae: 0.8982 - val_mse: 1.3675\n",
      "Epoch 307/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3056 - mae: 0.8752 - mse: 1.3056 - val_loss: 1.3635 - val_mae: 0.8809 - val_mse: 1.3635\n",
      "Epoch 308/1000\n",
      "8890/8890 [==============================] - 0s 33us/sample - loss: 1.3062 - mae: 0.8741 - mse: 1.3062 - val_loss: 1.3658 - val_mae: 0.8910 - val_mse: 1.3658\n",
      "Epoch 309/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3068 - mae: 0.8747 - mse: 1.3068 - val_loss: 1.3644 - val_mae: 0.8860 - val_mse: 1.3644\n",
      "Epoch 310/1000\n",
      "8890/8890 [==============================] - 0s 41us/sample - loss: 1.3058 - mae: 0.8730 - mse: 1.3058 - val_loss: 1.3660 - val_mae: 0.8819 - val_mse: 1.3660\n",
      "Epoch 311/1000\n",
      "8890/8890 [==============================] - 0s 39us/sample - loss: 1.3064 - mae: 0.8741 - mse: 1.3064 - val_loss: 1.3799 - val_mae: 0.8795 - val_mse: 1.3799\n",
      "Epoch 312/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3038 - mae: 0.8726 - mse: 1.3038 - val_loss: 1.3717 - val_mae: 0.8951 - val_mse: 1.3717\n",
      "Epoch 313/1000\n",
      "8890/8890 [==============================] - 0s 49us/sample - loss: 1.3057 - mae: 0.8738 - mse: 1.3057 - val_loss: 1.3641 - val_mae: 0.8917 - val_mse: 1.3641\n",
      "Epoch 314/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3049 - mae: 0.8750 - mse: 1.3049 - val_loss: 1.3647 - val_mae: 0.8802 - val_mse: 1.3647\n",
      "Epoch 315/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3060 - mae: 0.8741 - mse: 1.3060 - val_loss: 1.3785 - val_mae: 0.8810 - val_mse: 1.3785\n",
      "Epoch 316/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3071 - mae: 0.8736 - mse: 1.3071 - val_loss: 1.3750 - val_mae: 0.9063 - val_mse: 1.3750\n",
      "Epoch 317/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3060 - mae: 0.8746 - mse: 1.3060 - val_loss: 1.3672 - val_mae: 0.8981 - val_mse: 1.3672\n",
      "Epoch 318/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3067 - mae: 0.8745 - mse: 1.3067 - val_loss: 1.3810 - val_mae: 0.9115 - val_mse: 1.3810\n",
      "Epoch 319/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3045 - mae: 0.8743 - mse: 1.3045 - val_loss: 1.3675 - val_mae: 0.8988 - val_mse: 1.3675\n",
      "Epoch 320/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3063 - mae: 0.8738 - mse: 1.3063 - val_loss: 1.3650 - val_mae: 0.8815 - val_mse: 1.3650\n",
      "Epoch 321/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3049 - mae: 0.8728 - mse: 1.3049 - val_loss: 1.3665 - val_mae: 0.8887 - val_mse: 1.3665\n",
      "Epoch 322/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3048 - mae: 0.8741 - mse: 1.3048 - val_loss: 1.3692 - val_mae: 0.9000 - val_mse: 1.3692\n",
      "Epoch 323/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3059 - mae: 0.8736 - mse: 1.3059 - val_loss: 1.3957 - val_mae: 0.9223 - val_mse: 1.3957\n",
      "Epoch 324/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3070 - mae: 0.8747 - mse: 1.3070 - val_loss: 1.3811 - val_mae: 0.9116 - val_mse: 1.3811\n",
      "Epoch 325/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3051 - mae: 0.8743 - mse: 1.3051 - val_loss: 1.3814 - val_mae: 0.9132 - val_mse: 1.3814\n",
      "Epoch 326/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3057 - mae: 0.8743 - mse: 1.3057 - val_loss: 1.3617 - val_mae: 0.8847 - val_mse: 1.3617\n",
      "Epoch 327/1000\n",
      "8890/8890 [==============================] - 0s 41us/sample - loss: 1.3043 - mae: 0.8738 - mse: 1.3043 - val_loss: 1.3678 - val_mae: 0.8854 - val_mse: 1.3678\n",
      "Epoch 328/1000\n",
      "8890/8890 [==============================] - 0s 42us/sample - loss: 1.3065 - mae: 0.8745 - mse: 1.3065 - val_loss: 1.3672 - val_mae: 0.8865 - val_mse: 1.3672\n",
      "Epoch 329/1000\n",
      "8890/8890 [==============================] - 0s 41us/sample - loss: 1.3047 - mae: 0.8740 - mse: 1.3047 - val_loss: 1.3836 - val_mae: 0.9141 - val_mse: 1.3836\n",
      "Epoch 330/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3068 - mae: 0.8743 - mse: 1.3068 - val_loss: 1.3712 - val_mae: 0.8995 - val_mse: 1.3712\n",
      "Epoch 331/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8890/8890 [==============================] - 0s 33us/sample - loss: 1.3062 - mae: 0.8745 - mse: 1.3062 - val_loss: 1.3623 - val_mae: 0.8911 - val_mse: 1.3623\n",
      "Epoch 332/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3050 - mae: 0.8748 - mse: 1.3050 - val_loss: 1.3656 - val_mae: 0.8956 - val_mse: 1.3656\n",
      "Epoch 333/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3058 - mae: 0.8726 - mse: 1.3058 - val_loss: 1.3719 - val_mae: 0.9017 - val_mse: 1.3719\n",
      "Epoch 334/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3049 - mae: 0.8739 - mse: 1.3049 - val_loss: 1.3732 - val_mae: 0.9057 - val_mse: 1.3732\n",
      "Epoch 335/1000\n",
      "8890/8890 [==============================] - 0s 31us/sample - loss: 1.3069 - mae: 0.8732 - mse: 1.3069 - val_loss: 1.3631 - val_mae: 0.8876 - val_mse: 1.3631\n",
      "Epoch 336/1000\n",
      "8890/8890 [==============================] - 0s 33us/sample - loss: 1.3044 - mae: 0.8742 - mse: 1.3044 - val_loss: 1.3674 - val_mae: 0.8779 - val_mse: 1.3674\n",
      "Epoch 337/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3073 - mae: 0.8745 - mse: 1.3073 - val_loss: 1.3656 - val_mae: 0.8967 - val_mse: 1.3656\n",
      "Epoch 338/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3063 - mae: 0.8749 - mse: 1.3063 - val_loss: 1.3640 - val_mae: 0.8942 - val_mse: 1.3640\n",
      "Epoch 339/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3043 - mae: 0.8725 - mse: 1.3043 - val_loss: 1.3696 - val_mae: 0.8845 - val_mse: 1.3696\n",
      "Epoch 340/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3040 - mae: 0.8733 - mse: 1.3040 - val_loss: 1.3751 - val_mae: 0.9056 - val_mse: 1.3751\n",
      "Epoch 341/1000\n",
      "8890/8890 [==============================] - 0s 32us/sample - loss: 1.3062 - mae: 0.8745 - mse: 1.3062 - val_loss: 1.3650 - val_mae: 0.8973 - val_mse: 1.3650\n",
      "Epoch 342/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3036 - mae: 0.8729 - mse: 1.3036 - val_loss: 1.3713 - val_mae: 0.9001 - val_mse: 1.3713\n",
      "Epoch 343/1000\n",
      "8890/8890 [==============================] - 0s 39us/sample - loss: 1.3059 - mae: 0.8730 - mse: 1.3059 - val_loss: 1.3663 - val_mae: 0.8975 - val_mse: 1.3663\n",
      "Epoch 344/1000\n",
      "8890/8890 [==============================] - 1s 58us/sample - loss: 1.3043 - mae: 0.8744 - mse: 1.3043 - val_loss: 1.3636 - val_mae: 0.8918 - val_mse: 1.3636\n",
      "Epoch 345/1000\n",
      "8890/8890 [==============================] - 0s 50us/sample - loss: 1.3051 - mae: 0.8734 - mse: 1.3051 - val_loss: 1.3662 - val_mae: 0.8942 - val_mse: 1.3662\n",
      "Epoch 346/1000\n",
      "8890/8890 [==============================] - 0s 45us/sample - loss: 1.3063 - mae: 0.8730 - mse: 1.3063 - val_loss: 1.3671 - val_mae: 0.8901 - val_mse: 1.3671\n",
      "Epoch 347/1000\n",
      "8890/8890 [==============================] - 0s 33us/sample - loss: 1.3051 - mae: 0.8735 - mse: 1.3051 - val_loss: 1.3872 - val_mae: 0.9154 - val_mse: 1.3872\n",
      "Epoch 348/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3042 - mae: 0.8741 - mse: 1.3042 - val_loss: 1.3668 - val_mae: 0.8884 - val_mse: 1.3668\n",
      "Epoch 349/1000\n",
      "8890/8890 [==============================] - 0s 33us/sample - loss: 1.3057 - mae: 0.8742 - mse: 1.3057 - val_loss: 1.3663 - val_mae: 0.8946 - val_mse: 1.3663\n",
      "Epoch 350/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3057 - mae: 0.8737 - mse: 1.3057 - val_loss: 1.3645 - val_mae: 0.8899 - val_mse: 1.3645\n",
      "Epoch 351/1000\n",
      "8890/8890 [==============================] - 0s 45us/sample - loss: 1.3037 - mae: 0.8733 - mse: 1.3037 - val_loss: 1.3646 - val_mae: 0.8805 - val_mse: 1.3646\n",
      "Epoch 352/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3060 - mae: 0.8736 - mse: 1.3060 - val_loss: 1.3602 - val_mae: 0.8892 - val_mse: 1.3602\n",
      "Epoch 353/1000\n",
      "8890/8890 [==============================] - 0s 41us/sample - loss: 1.3060 - mae: 0.8746 - mse: 1.3060 - val_loss: 1.3643 - val_mae: 0.8934 - val_mse: 1.3643\n",
      "Epoch 354/1000\n",
      "8890/8890 [==============================] - 0s 43us/sample - loss: 1.3065 - mae: 0.8743 - mse: 1.3065 - val_loss: 1.3731 - val_mae: 0.9064 - val_mse: 1.3731\n",
      "Epoch 355/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3057 - mae: 0.8757 - mse: 1.3057 - val_loss: 1.3654 - val_mae: 0.8946 - val_mse: 1.3654\n",
      "Epoch 356/1000\n",
      "8890/8890 [==============================] - 0s 42us/sample - loss: 1.3040 - mae: 0.8741 - mse: 1.3040 - val_loss: 1.3743 - val_mae: 0.9016 - val_mse: 1.3743\n",
      "Epoch 357/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3072 - mae: 0.8733 - mse: 1.3072 - val_loss: 1.3673 - val_mae: 0.8902 - val_mse: 1.3673\n",
      "Epoch 358/1000\n",
      "8890/8890 [==============================] - 0s 33us/sample - loss: 1.3060 - mae: 0.8742 - mse: 1.3060 - val_loss: 1.3630 - val_mae: 0.8892 - val_mse: 1.3630\n",
      "Epoch 359/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3047 - mae: 0.8729 - mse: 1.3047 - val_loss: 1.3937 - val_mae: 0.9213 - val_mse: 1.3937\n",
      "Epoch 360/1000\n",
      "8890/8890 [==============================] - 0s 33us/sample - loss: 1.3060 - mae: 0.8746 - mse: 1.3060 - val_loss: 1.3638 - val_mae: 0.8784 - val_mse: 1.3638\n",
      "Epoch 361/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3064 - mae: 0.8737 - mse: 1.3064 - val_loss: 1.3663 - val_mae: 0.8872 - val_mse: 1.3663\n",
      "Epoch 362/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3051 - mae: 0.8727 - mse: 1.3051 - val_loss: 1.3666 - val_mae: 0.8963 - val_mse: 1.3666\n",
      "Epoch 363/1000\n",
      "8890/8890 [==============================] - 0s 39us/sample - loss: 1.3068 - mae: 0.8753 - mse: 1.3068 - val_loss: 1.3761 - val_mae: 0.8763 - val_mse: 1.3761\n",
      "Epoch 364/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3075 - mae: 0.8739 - mse: 1.3075 - val_loss: 1.3675 - val_mae: 0.8893 - val_mse: 1.3675\n",
      "Epoch 365/1000\n",
      "8890/8890 [==============================] - 0s 43us/sample - loss: 1.3044 - mae: 0.8737 - mse: 1.3044 - val_loss: 1.3663 - val_mae: 0.8874 - val_mse: 1.3663\n",
      "Epoch 366/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3058 - mae: 0.8736 - mse: 1.3058 - val_loss: 1.3677 - val_mae: 0.8961 - val_mse: 1.3677\n",
      "Epoch 367/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3069 - mae: 0.8748 - mse: 1.3069 - val_loss: 1.3654 - val_mae: 0.8950 - val_mse: 1.3654\n",
      "Epoch 368/1000\n",
      "8890/8890 [==============================] - 0s 33us/sample - loss: 1.3058 - mae: 0.8733 - mse: 1.3058 - val_loss: 1.3658 - val_mae: 0.8853 - val_mse: 1.3658\n",
      "Epoch 369/1000\n",
      "8890/8890 [==============================] - 0s 52us/sample - loss: 1.3042 - mae: 0.8730 - mse: 1.3042 - val_loss: 1.3652 - val_mae: 0.8955 - val_mse: 1.3652\n",
      "Epoch 370/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3051 - mae: 0.8728 - mse: 1.3051 - val_loss: 1.3669 - val_mae: 0.8991 - val_mse: 1.3669\n",
      "Epoch 371/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3044 - mae: 0.8732 - mse: 1.3044 - val_loss: 1.3918 - val_mae: 0.8748 - val_mse: 1.3918\n",
      "Epoch 372/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3084 - mae: 0.8743 - mse: 1.3084 - val_loss: 1.3728 - val_mae: 0.8771 - val_mse: 1.3728\n",
      "Epoch 373/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3057 - mae: 0.8731 - mse: 1.3057 - val_loss: 1.3697 - val_mae: 0.8997 - val_mse: 1.3697\n",
      "Epoch 374/1000\n",
      "8890/8890 [==============================] - 0s 39us/sample - loss: 1.3034 - mae: 0.8735 - mse: 1.3034 - val_loss: 1.3657 - val_mae: 0.8853 - val_mse: 1.3657\n",
      "Epoch 375/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3066 - mae: 0.8745 - mse: 1.3066 - val_loss: 1.3694 - val_mae: 0.8832 - val_mse: 1.3694\n",
      "Epoch 376/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3045 - mae: 0.8740 - mse: 1.3045 - val_loss: 1.3668 - val_mae: 0.8930 - val_mse: 1.3668\n",
      "Epoch 377/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3057 - mae: 0.8738 - mse: 1.3057 - val_loss: 1.3633 - val_mae: 0.8930 - val_mse: 1.3633\n",
      "Epoch 378/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3036 - mae: 0.8732 - mse: 1.3036 - val_loss: 1.3949 - val_mae: 0.9167 - val_mse: 1.3949\n",
      "Epoch 379/1000\n",
      "8890/8890 [==============================] - 0s 31us/sample - loss: 1.3045 - mae: 0.8733 - mse: 1.3045 - val_loss: 1.3654 - val_mae: 0.8871 - val_mse: 1.3654\n",
      "Epoch 380/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3044 - mae: 0.8727 - mse: 1.3044 - val_loss: 1.3722 - val_mae: 0.8964 - val_mse: 1.3722\n",
      "Epoch 381/1000\n",
      "8890/8890 [==============================] - 0s 32us/sample - loss: 1.3056 - mae: 0.8736 - mse: 1.3056 - val_loss: 1.3691 - val_mae: 0.8981 - val_mse: 1.3691\n",
      "Epoch 382/1000\n",
      "8890/8890 [==============================] - 0s 42us/sample - loss: 1.3042 - mae: 0.8735 - mse: 1.3042 - val_loss: 1.3695 - val_mae: 0.8991 - val_mse: 1.3695\n",
      "Epoch 383/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3051 - mae: 0.8740 - mse: 1.3051 - val_loss: 1.3639 - val_mae: 0.8950 - val_mse: 1.3639\n",
      "Epoch 384/1000\n",
      "8890/8890 [==============================] - 0s 47us/sample - loss: 1.3056 - mae: 0.8750 - mse: 1.3056 - val_loss: 1.3650 - val_mae: 0.8901 - val_mse: 1.3650\n",
      "Epoch 385/1000\n",
      "8890/8890 [==============================] - 0s 43us/sample - loss: 1.3051 - mae: 0.8737 - mse: 1.3051 - val_loss: 1.3702 - val_mae: 0.8908 - val_mse: 1.3702\n",
      "Epoch 386/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3059 - mae: 0.8735 - mse: 1.3059 - val_loss: 1.3679 - val_mae: 0.8816 - val_mse: 1.3679\n",
      "Epoch 387/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3058 - mae: 0.8738 - mse: 1.3058 - val_loss: 1.3712 - val_mae: 0.8973 - val_mse: 1.3712\n",
      "Epoch 388/1000\n",
      "8890/8890 [==============================] - 0s 39us/sample - loss: 1.3055 - mae: 0.8733 - mse: 1.3055 - val_loss: 1.3665 - val_mae: 0.8971 - val_mse: 1.3665\n",
      "Epoch 389/1000\n",
      "8890/8890 [==============================] - 0s 43us/sample - loss: 1.3052 - mae: 0.8731 - mse: 1.3052 - val_loss: 1.3752 - val_mae: 0.9068 - val_mse: 1.3752\n",
      "Epoch 390/1000\n",
      "8890/8890 [==============================] - 0s 50us/sample - loss: 1.3060 - mae: 0.8750 - mse: 1.3060 - val_loss: 1.3650 - val_mae: 0.8929 - val_mse: 1.3650\n",
      "Epoch 391/1000\n",
      "8890/8890 [==============================] - 0s 46us/sample - loss: 1.3026 - mae: 0.8738 - mse: 1.3026 - val_loss: 1.3647 - val_mae: 0.8880 - val_mse: 1.3647\n",
      "Epoch 392/1000\n",
      "8890/8890 [==============================] - 0s 44us/sample - loss: 1.3053 - mae: 0.8744 - mse: 1.3053 - val_loss: 1.3647 - val_mae: 0.8894 - val_mse: 1.3647\n",
      "Epoch 393/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3065 - mae: 0.8736 - mse: 1.3065 - val_loss: 1.3820 - val_mae: 0.9130 - val_mse: 1.3820\n",
      "Epoch 394/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3036 - mae: 0.8742 - mse: 1.3036 - val_loss: 1.3624 - val_mae: 0.8876 - val_mse: 1.3624\n",
      "Epoch 395/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3057 - mae: 0.8733 - mse: 1.3057 - val_loss: 1.3665 - val_mae: 0.8964 - val_mse: 1.3665\n",
      "Epoch 396/1000\n",
      "8890/8890 [==============================] - 0s 32us/sample - loss: 1.3034 - mae: 0.8730 - mse: 1.3034 - val_loss: 1.3773 - val_mae: 0.9034 - val_mse: 1.3773\n",
      "Epoch 397/1000\n",
      "8890/8890 [==============================] - 0s 33us/sample - loss: 1.3058 - mae: 0.8735 - mse: 1.3058 - val_loss: 1.3647 - val_mae: 0.8825 - val_mse: 1.3647\n",
      "Epoch 398/1000\n",
      "8890/8890 [==============================] - 0s 32us/sample - loss: 1.3047 - mae: 0.8725 - mse: 1.3047 - val_loss: 1.3648 - val_mae: 0.8900 - val_mse: 1.3648\n",
      "Epoch 399/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3059 - mae: 0.8734 - mse: 1.3059 - val_loss: 1.3644 - val_mae: 0.8913 - val_mse: 1.3644\n",
      "Epoch 400/1000\n",
      "8890/8890 [==============================] - 0s 39us/sample - loss: 1.3059 - mae: 0.8742 - mse: 1.3059 - val_loss: 1.3635 - val_mae: 0.8895 - val_mse: 1.3635\n",
      "Epoch 401/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3045 - mae: 0.8735 - mse: 1.3045 - val_loss: 1.3653 - val_mae: 0.8891 - val_mse: 1.3653\n",
      "Epoch 402/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3050 - mae: 0.8729 - mse: 1.3050 - val_loss: 1.3748 - val_mae: 0.9067 - val_mse: 1.3748\n",
      "Epoch 403/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3040 - mae: 0.8744 - mse: 1.3040 - val_loss: 1.3641 - val_mae: 0.8816 - val_mse: 1.3641\n",
      "Epoch 404/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3068 - mae: 0.8743 - mse: 1.3068 - val_loss: 1.3731 - val_mae: 0.9041 - val_mse: 1.3731\n",
      "Epoch 405/1000\n",
      "8890/8890 [==============================] - 0s 31us/sample - loss: 1.3050 - mae: 0.8739 - mse: 1.3050 - val_loss: 1.3672 - val_mae: 0.8869 - val_mse: 1.3672\n",
      "Epoch 406/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3031 - mae: 0.8737 - mse: 1.3031 - val_loss: 1.3674 - val_mae: 0.8955 - val_mse: 1.3674\n",
      "Epoch 407/1000\n",
      "8890/8890 [==============================] - 0s 44us/sample - loss: 1.3041 - mae: 0.8735 - mse: 1.3041 - val_loss: 1.3623 - val_mae: 0.8855 - val_mse: 1.3623\n",
      "Epoch 408/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3052 - mae: 0.8733 - mse: 1.3052 - val_loss: 1.3644 - val_mae: 0.8981 - val_mse: 1.3644\n",
      "Epoch 409/1000\n",
      "8890/8890 [==============================] - 0s 43us/sample - loss: 1.3038 - mae: 0.8727 - mse: 1.3038 - val_loss: 1.3767 - val_mae: 0.9025 - val_mse: 1.3767\n",
      "Epoch 410/1000\n",
      "8890/8890 [==============================] - 0s 48us/sample - loss: 1.3058 - mae: 0.8733 - mse: 1.3058 - val_loss: 1.3650 - val_mae: 0.8816 - val_mse: 1.3650\n",
      "Epoch 411/1000\n",
      "8890/8890 [==============================] - 0s 51us/sample - loss: 1.3046 - mae: 0.8733 - mse: 1.3046 - val_loss: 1.3815 - val_mae: 0.9138 - val_mse: 1.3815\n",
      "Epoch 412/1000\n",
      "8890/8890 [==============================] - 0s 44us/sample - loss: 1.3044 - mae: 0.8743 - mse: 1.3044 - val_loss: 1.3662 - val_mae: 0.8970 - val_mse: 1.3662\n",
      "Epoch 413/1000\n",
      "8890/8890 [==============================] - 0s 45us/sample - loss: 1.3058 - mae: 0.8742 - mse: 1.3058 - val_loss: 1.3707 - val_mae: 0.8810 - val_mse: 1.3707\n",
      "Epoch 414/1000\n",
      "8890/8890 [==============================] - 0s 33us/sample - loss: 1.3051 - mae: 0.8723 - mse: 1.3051 - val_loss: 1.3620 - val_mae: 0.8887 - val_mse: 1.3620\n",
      "Epoch 415/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3040 - mae: 0.8722 - mse: 1.3040 - val_loss: 1.3678 - val_mae: 0.9001 - val_mse: 1.3678\n",
      "Epoch 416/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3048 - mae: 0.8745 - mse: 1.3048 - val_loss: 1.3694 - val_mae: 0.9032 - val_mse: 1.3694\n",
      "Epoch 417/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3035 - mae: 0.8730 - mse: 1.3035 - val_loss: 1.3656 - val_mae: 0.8937 - val_mse: 1.3656\n",
      "Epoch 418/1000\n",
      "8890/8890 [==============================] - 0s 48us/sample - loss: 1.3049 - mae: 0.8732 - mse: 1.3049 - val_loss: 1.3672 - val_mae: 0.8950 - val_mse: 1.3672\n",
      "Epoch 419/1000\n",
      "8890/8890 [==============================] - 0s 43us/sample - loss: 1.3050 - mae: 0.8732 - mse: 1.3050 - val_loss: 1.3859 - val_mae: 0.9169 - val_mse: 1.3859\n",
      "Epoch 420/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3051 - mae: 0.8745 - mse: 1.3051 - val_loss: 1.3734 - val_mae: 0.9032 - val_mse: 1.3734\n",
      "Epoch 421/1000\n",
      "8890/8890 [==============================] - 0s 42us/sample - loss: 1.3065 - mae: 0.8749 - mse: 1.3065 - val_loss: 1.3642 - val_mae: 0.8874 - val_mse: 1.3642\n",
      "Epoch 422/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3056 - mae: 0.8741 - mse: 1.3056 - val_loss: 1.3671 - val_mae: 0.8812 - val_mse: 1.3671\n",
      "Epoch 423/1000\n",
      "8890/8890 [==============================] - 0s 41us/sample - loss: 1.3038 - mae: 0.8741 - mse: 1.3038 - val_loss: 1.3619 - val_mae: 0.8814 - val_mse: 1.3619\n",
      "Epoch 424/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3043 - mae: 0.8733 - mse: 1.3043 - val_loss: 1.3623 - val_mae: 0.8894 - val_mse: 1.3623\n",
      "Epoch 425/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3041 - mae: 0.8715 - mse: 1.3041 - val_loss: 1.3825 - val_mae: 0.9131 - val_mse: 1.3825\n",
      "Epoch 426/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3045 - mae: 0.8749 - mse: 1.3045 - val_loss: 1.3637 - val_mae: 0.8890 - val_mse: 1.3637\n",
      "Epoch 427/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3044 - mae: 0.8729 - mse: 1.3044 - val_loss: 1.3689 - val_mae: 0.8973 - val_mse: 1.3689\n",
      "Epoch 428/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3058 - mae: 0.8738 - mse: 1.3058 - val_loss: 1.3647 - val_mae: 0.8904 - val_mse: 1.3647\n",
      "Epoch 429/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3052 - mae: 0.8733 - mse: 1.3052 - val_loss: 1.3722 - val_mae: 0.9030 - val_mse: 1.3722\n",
      "Epoch 430/1000\n",
      "8890/8890 [==============================] - 0s 45us/sample - loss: 1.3049 - mae: 0.8729 - mse: 1.3049 - val_loss: 1.3628 - val_mae: 0.8940 - val_mse: 1.3628\n",
      "Epoch 431/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3046 - mae: 0.8721 - mse: 1.3046 - val_loss: 1.3920 - val_mae: 0.9218 - val_mse: 1.3920\n",
      "Epoch 432/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3060 - mae: 0.8746 - mse: 1.3060 - val_loss: 1.3679 - val_mae: 0.8774 - val_mse: 1.3679\n",
      "Epoch 433/1000\n",
      "8890/8890 [==============================] - 0s 39us/sample - loss: 1.3040 - mae: 0.8724 - mse: 1.3040 - val_loss: 1.3617 - val_mae: 0.8935 - val_mse: 1.3617\n",
      "Epoch 434/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3068 - mae: 0.8735 - mse: 1.3068 - val_loss: 1.3656 - val_mae: 0.8805 - val_mse: 1.3656\n",
      "Epoch 435/1000\n",
      "8890/8890 [==============================] - ETA: 0s - loss: 1.3152 - mae: 0.8746 - mse: 1.315 - 0s 41us/sample - loss: 1.3049 - mae: 0.8738 - mse: 1.3049 - val_loss: 1.3821 - val_mae: 0.9147 - val_mse: 1.3821\n",
      "Epoch 436/1000\n",
      "8890/8890 [==============================] - 0s 55us/sample - loss: 1.3058 - mae: 0.8744 - mse: 1.3058 - val_loss: 1.3641 - val_mae: 0.8940 - val_mse: 1.3641\n",
      "Epoch 437/1000\n",
      "8890/8890 [==============================] - 0s 46us/sample - loss: 1.3049 - mae: 0.8736 - mse: 1.3049 - val_loss: 1.3693 - val_mae: 0.8824 - val_mse: 1.3693\n",
      "Epoch 438/1000\n",
      "8890/8890 [==============================] - 0s 47us/sample - loss: 1.3047 - mae: 0.8726 - mse: 1.3047 - val_loss: 1.3714 - val_mae: 0.9047 - val_mse: 1.3714\n",
      "Epoch 439/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3052 - mae: 0.8742 - mse: 1.3052 - val_loss: 1.3739 - val_mae: 0.9030 - val_mse: 1.3739\n",
      "Epoch 440/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3043 - mae: 0.8722 - mse: 1.3043 - val_loss: 1.3639 - val_mae: 0.8834 - val_mse: 1.3639\n",
      "Epoch 441/1000\n",
      "8890/8890 [==============================] - 0s 31us/sample - loss: 1.3045 - mae: 0.8735 - mse: 1.3045 - val_loss: 1.3768 - val_mae: 0.9024 - val_mse: 1.3768\n",
      "Epoch 442/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3054 - mae: 0.8735 - mse: 1.3054 - val_loss: 1.3672 - val_mae: 0.8899 - val_mse: 1.3672\n",
      "Epoch 443/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3050 - mae: 0.8730 - mse: 1.3050 - val_loss: 1.3662 - val_mae: 0.8873 - val_mse: 1.3662\n",
      "Epoch 444/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3045 - mae: 0.8729 - mse: 1.3045 - val_loss: 1.3660 - val_mae: 0.8948 - val_mse: 1.3660\n",
      "Epoch 445/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3047 - mae: 0.8738 - mse: 1.3047 - val_loss: 1.3668 - val_mae: 0.8927 - val_mse: 1.3668\n",
      "Epoch 446/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3050 - mae: 0.8740 - mse: 1.3050 - val_loss: 1.3694 - val_mae: 0.8878 - val_mse: 1.3694\n",
      "Epoch 447/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3054 - mae: 0.8736 - mse: 1.3054 - val_loss: 1.3691 - val_mae: 0.8811 - val_mse: 1.3691\n",
      "Epoch 448/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3058 - mae: 0.8734 - mse: 1.3058 - val_loss: 1.3787 - val_mae: 0.9087 - val_mse: 1.3787\n",
      "Epoch 449/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3054 - mae: 0.8733 - mse: 1.3054 - val_loss: 1.3621 - val_mae: 0.8859 - val_mse: 1.3621\n",
      "Epoch 450/1000\n",
      "8890/8890 [==============================] - 0s 50us/sample - loss: 1.3027 - mae: 0.8729 - mse: 1.3027 - val_loss: 1.3686 - val_mae: 0.8868 - val_mse: 1.3686\n",
      "Epoch 451/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3045 - mae: 0.8734 - mse: 1.3045 - val_loss: 1.3661 - val_mae: 0.8906 - val_mse: 1.3661\n",
      "Epoch 452/1000\n",
      "8890/8890 [==============================] - 0s 41us/sample - loss: 1.3028 - mae: 0.8719 - mse: 1.3028 - val_loss: 1.3727 - val_mae: 0.9033 - val_mse: 1.3727\n",
      "Epoch 453/1000\n",
      "8890/8890 [==============================] - 0s 39us/sample - loss: 1.3026 - mae: 0.8740 - mse: 1.3026 - val_loss: 1.3687 - val_mae: 0.8824 - val_mse: 1.3687\n",
      "Epoch 454/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3062 - mae: 0.8736 - mse: 1.3062 - val_loss: 1.3627 - val_mae: 0.8901 - val_mse: 1.3627\n",
      "Epoch 455/1000\n",
      "8890/8890 [==============================] - 0s 43us/sample - loss: 1.3037 - mae: 0.8736 - mse: 1.3037 - val_loss: 1.3718 - val_mae: 0.8807 - val_mse: 1.3718\n",
      "Epoch 456/1000\n",
      "8890/8890 [==============================] - 0s 43us/sample - loss: 1.3062 - mae: 0.8724 - mse: 1.3062 - val_loss: 1.3734 - val_mae: 0.9040 - val_mse: 1.3734\n",
      "Epoch 457/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3069 - mae: 0.8750 - mse: 1.3069 - val_loss: 1.3684 - val_mae: 0.8783 - val_mse: 1.3684\n",
      "Epoch 458/1000\n",
      "8890/8890 [==============================] - 0s 45us/sample - loss: 1.3051 - mae: 0.8724 - mse: 1.3051 - val_loss: 1.3618 - val_mae: 0.8914 - val_mse: 1.3618\n",
      "Epoch 459/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3059 - mae: 0.8737 - mse: 1.3059 - val_loss: 1.3653 - val_mae: 0.8940 - val_mse: 1.3653\n",
      "Epoch 460/1000\n",
      "8890/8890 [==============================] - 0s 32us/sample - loss: 1.3026 - mae: 0.8725 - mse: 1.3026 - val_loss: 1.3632 - val_mae: 0.8921 - val_mse: 1.3632\n",
      "Epoch 461/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3048 - mae: 0.8738 - mse: 1.3048 - val_loss: 1.3653 - val_mae: 0.8954 - val_mse: 1.3653\n",
      "Epoch 462/1000\n",
      "8890/8890 [==============================] - 0s 39us/sample - loss: 1.3052 - mae: 0.8734 - mse: 1.3052 - val_loss: 1.3668 - val_mae: 0.8832 - val_mse: 1.3668\n",
      "Epoch 463/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3044 - mae: 0.8725 - mse: 1.3044 - val_loss: 1.3682 - val_mae: 0.8855 - val_mse: 1.3682\n",
      "Epoch 464/1000\n",
      "8890/8890 [==============================] - 0s 42us/sample - loss: 1.3045 - mae: 0.8721 - mse: 1.3045 - val_loss: 1.3658 - val_mae: 0.8883 - val_mse: 1.3658\n",
      "Epoch 465/1000\n",
      "8890/8890 [==============================] - 0s 42us/sample - loss: 1.3066 - mae: 0.8738 - mse: 1.3066 - val_loss: 1.3694 - val_mae: 0.8922 - val_mse: 1.3694\n",
      "Epoch 466/1000\n",
      "8890/8890 [==============================] - 0s 39us/sample - loss: 1.3048 - mae: 0.8737 - mse: 1.3048 - val_loss: 1.3666 - val_mae: 0.8806 - val_mse: 1.3666\n",
      "Epoch 467/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3029 - mae: 0.8716 - mse: 1.3029 - val_loss: 1.3865 - val_mae: 0.9178 - val_mse: 1.3865\n",
      "Epoch 468/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3062 - mae: 0.8744 - mse: 1.3062 - val_loss: 1.3730 - val_mae: 0.9034 - val_mse: 1.3730\n",
      "Epoch 469/1000\n",
      "8890/8890 [==============================] - 0s 39us/sample - loss: 1.3056 - mae: 0.8746 - mse: 1.3056 - val_loss: 1.3704 - val_mae: 0.8785 - val_mse: 1.3704\n",
      "Epoch 470/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3068 - mae: 0.8744 - mse: 1.3068 - val_loss: 1.3648 - val_mae: 0.8816 - val_mse: 1.3648\n",
      "Epoch 471/1000\n",
      "8890/8890 [==============================] - 0s 42us/sample - loss: 1.3031 - mae: 0.8727 - mse: 1.3031 - val_loss: 1.3636 - val_mae: 0.8868 - val_mse: 1.3636\n",
      "Epoch 472/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3040 - mae: 0.8734 - mse: 1.3040 - val_loss: 1.3726 - val_mae: 0.8808 - val_mse: 1.3726\n",
      "Epoch 473/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3050 - mae: 0.8732 - mse: 1.3050 - val_loss: 1.3661 - val_mae: 0.8938 - val_mse: 1.3661\n",
      "Epoch 474/1000\n",
      "8890/8890 [==============================] - 0s 32us/sample - loss: 1.3047 - mae: 0.8735 - mse: 1.3047 - val_loss: 1.3758 - val_mae: 0.9042 - val_mse: 1.3758\n",
      "Epoch 475/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3046 - mae: 0.8746 - mse: 1.3046 - val_loss: 1.3655 - val_mae: 0.8926 - val_mse: 1.3655\n",
      "Epoch 476/1000\n",
      "8890/8890 [==============================] - 0s 41us/sample - loss: 1.3028 - mae: 0.8719 - mse: 1.3028 - val_loss: 1.3726 - val_mae: 0.8977 - val_mse: 1.3726\n",
      "Epoch 477/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3065 - mae: 0.8743 - mse: 1.3065 - val_loss: 1.3690 - val_mae: 0.9001 - val_mse: 1.3690\n",
      "Epoch 478/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3030 - mae: 0.8727 - mse: 1.3030 - val_loss: 1.3658 - val_mae: 0.8854 - val_mse: 1.3658\n",
      "Epoch 479/1000\n",
      "8890/8890 [==============================] - 0s 32us/sample - loss: 1.3024 - mae: 0.8729 - mse: 1.3024 - val_loss: 1.3778 - val_mae: 0.8778 - val_mse: 1.3778\n",
      "Epoch 480/1000\n",
      "8890/8890 [==============================] - 0s 31us/sample - loss: 1.3062 - mae: 0.8744 - mse: 1.3062 - val_loss: 1.3676 - val_mae: 0.8811 - val_mse: 1.3676\n",
      "Epoch 481/1000\n",
      "8890/8890 [==============================] - 0s 31us/sample - loss: 1.3032 - mae: 0.8732 - mse: 1.3032 - val_loss: 1.3653 - val_mae: 0.8955 - val_mse: 1.3653\n",
      "Epoch 482/1000\n",
      "8890/8890 [==============================] - 0s 44us/sample - loss: 1.3050 - mae: 0.8728 - mse: 1.3050 - val_loss: 1.3773 - val_mae: 0.9096 - val_mse: 1.3773\n",
      "Epoch 483/1000\n",
      "8890/8890 [==============================] - 0s 44us/sample - loss: 1.3045 - mae: 0.8737 - mse: 1.3045 - val_loss: 1.3620 - val_mae: 0.8841 - val_mse: 1.3620\n",
      "Epoch 484/1000\n",
      "8890/8890 [==============================] - 0s 45us/sample - loss: 1.3041 - mae: 0.8725 - mse: 1.3041 - val_loss: 1.3654 - val_mae: 0.8949 - val_mse: 1.3654\n",
      "Epoch 485/1000\n",
      "8890/8890 [==============================] - 0s 42us/sample - loss: 1.3061 - mae: 0.8742 - mse: 1.3061 - val_loss: 1.3632 - val_mae: 0.8944 - val_mse: 1.3632\n",
      "Epoch 486/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3050 - mae: 0.8742 - mse: 1.3050 - val_loss: 1.3669 - val_mae: 0.8833 - val_mse: 1.3669\n",
      "Epoch 487/1000\n",
      "8890/8890 [==============================] - 0s 45us/sample - loss: 1.3041 - mae: 0.8732 - mse: 1.3041 - val_loss: 1.3747 - val_mae: 0.8768 - val_mse: 1.3747\n",
      "Epoch 488/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3052 - mae: 0.8740 - mse: 1.3052 - val_loss: 1.3681 - val_mae: 0.8857 - val_mse: 1.3681\n",
      "Epoch 489/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3046 - mae: 0.8733 - mse: 1.3046 - val_loss: 1.3691 - val_mae: 0.9008 - val_mse: 1.3691\n",
      "Epoch 490/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3049 - mae: 0.8746 - mse: 1.3049 - val_loss: 1.3634 - val_mae: 0.8914 - val_mse: 1.3634\n",
      "Epoch 491/1000\n",
      "8890/8890 [==============================] - 0s 33us/sample - loss: 1.3033 - mae: 0.8734 - mse: 1.3033 - val_loss: 1.3634 - val_mae: 0.8899 - val_mse: 1.3634\n",
      "Epoch 492/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3053 - mae: 0.8731 - mse: 1.3053 - val_loss: 1.3674 - val_mae: 0.8882 - val_mse: 1.3674\n",
      "Epoch 493/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3032 - mae: 0.8725 - mse: 1.3032 - val_loss: 1.3656 - val_mae: 0.8926 - val_mse: 1.3656\n",
      "Epoch 494/1000\n",
      "8890/8890 [==============================] - 0s 33us/sample - loss: 1.3052 - mae: 0.8739 - mse: 1.3052 - val_loss: 1.3673 - val_mae: 0.8820 - val_mse: 1.3673\n",
      "Epoch 495/1000\n",
      "8890/8890 [==============================] - 0s 33us/sample - loss: 1.3054 - mae: 0.8728 - mse: 1.3054 - val_loss: 1.3626 - val_mae: 0.8911 - val_mse: 1.3626\n",
      "Epoch 496/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3036 - mae: 0.8719 - mse: 1.3036 - val_loss: 1.3697 - val_mae: 0.9002 - val_mse: 1.3697\n",
      "Epoch 497/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3046 - mae: 0.8743 - mse: 1.3046 - val_loss: 1.3705 - val_mae: 0.8983 - val_mse: 1.3705\n",
      "Epoch 498/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3033 - mae: 0.8729 - mse: 1.3033 - val_loss: 1.3636 - val_mae: 0.8916 - val_mse: 1.3636\n",
      "Epoch 499/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3043 - mae: 0.8732 - mse: 1.3043 - val_loss: 1.3674 - val_mae: 0.8978 - val_mse: 1.3674\n",
      "Epoch 500/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3040 - mae: 0.8734 - mse: 1.3040 - val_loss: 1.3715 - val_mae: 0.9009 - val_mse: 1.3715\n",
      "Epoch 501/1000\n",
      "8890/8890 [==============================] - 0s 32us/sample - loss: 1.3046 - mae: 0.8740 - mse: 1.3046 - val_loss: 1.3707 - val_mae: 0.9024 - val_mse: 1.3707\n",
      "Epoch 502/1000\n",
      "8890/8890 [==============================] - 0s 33us/sample - loss: 1.3040 - mae: 0.8719 - mse: 1.3040 - val_loss: 1.3707 - val_mae: 0.9022 - val_mse: 1.3707\n",
      "Epoch 503/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3044 - mae: 0.8740 - mse: 1.3044 - val_loss: 1.3647 - val_mae: 0.8871 - val_mse: 1.3647\n",
      "Epoch 504/1000\n",
      "8890/8890 [==============================] - 0s 33us/sample - loss: 1.3037 - mae: 0.8728 - mse: 1.3037 - val_loss: 1.3685 - val_mae: 0.8899 - val_mse: 1.3685\n",
      "Epoch 505/1000\n",
      "8890/8890 [==============================] - 0s 33us/sample - loss: 1.3030 - mae: 0.8723 - mse: 1.3030 - val_loss: 1.3648 - val_mae: 0.8899 - val_mse: 1.3648\n",
      "Epoch 506/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3047 - mae: 0.8735 - mse: 1.3047 - val_loss: 1.3674 - val_mae: 0.8802 - val_mse: 1.3674\n",
      "Epoch 507/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3039 - mae: 0.8733 - mse: 1.3039 - val_loss: 1.3710 - val_mae: 0.8810 - val_mse: 1.3710\n",
      "Epoch 508/1000\n",
      "8890/8890 [==============================] - 0s 41us/sample - loss: 1.3034 - mae: 0.8731 - mse: 1.3034 - val_loss: 1.3632 - val_mae: 0.8920 - val_mse: 1.3632\n",
      "Epoch 509/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3048 - mae: 0.8753 - mse: 1.3048 - val_loss: 1.3678 - val_mae: 0.8901 - val_mse: 1.3678\n",
      "Epoch 510/1000\n",
      "8890/8890 [==============================] - 0s 45us/sample - loss: 1.3053 - mae: 0.8738 - mse: 1.3053 - val_loss: 1.3652 - val_mae: 0.8850 - val_mse: 1.3652\n",
      "Epoch 511/1000\n",
      "8890/8890 [==============================] - 0s 48us/sample - loss: 1.3044 - mae: 0.8722 - mse: 1.3044 - val_loss: 1.3721 - val_mae: 0.8834 - val_mse: 1.3721\n",
      "Epoch 512/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3027 - mae: 0.8729 - mse: 1.3027 - val_loss: 1.3772 - val_mae: 0.9089 - val_mse: 1.3772\n",
      "Epoch 513/1000\n",
      "8890/8890 [==============================] - 0s 46us/sample - loss: 1.3039 - mae: 0.8734 - mse: 1.3039 - val_loss: 1.3741 - val_mae: 0.9031 - val_mse: 1.3741\n",
      "Epoch 514/1000\n",
      "8890/8890 [==============================] - 0s 39us/sample - loss: 1.3053 - mae: 0.8732 - mse: 1.3053 - val_loss: 1.3722 - val_mae: 0.9042 - val_mse: 1.3722\n",
      "Epoch 515/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3040 - mae: 0.8735 - mse: 1.3040 - val_loss: 1.3675 - val_mae: 0.8827 - val_mse: 1.3675\n",
      "Epoch 516/1000\n",
      "8890/8890 [==============================] - 0s 39us/sample - loss: 1.3047 - mae: 0.8725 - mse: 1.3047 - val_loss: 1.3660 - val_mae: 0.8885 - val_mse: 1.3660\n",
      "Epoch 517/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3048 - mae: 0.8732 - mse: 1.3048 - val_loss: 1.3634 - val_mae: 0.8826 - val_mse: 1.3634\n",
      "Epoch 518/1000\n",
      "8890/8890 [==============================] - 0s 33us/sample - loss: 1.3040 - mae: 0.8715 - mse: 1.3040 - val_loss: 1.3792 - val_mae: 0.9099 - val_mse: 1.3792\n",
      "Epoch 519/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3046 - mae: 0.8735 - mse: 1.3046 - val_loss: 1.3684 - val_mae: 0.8992 - val_mse: 1.3684\n",
      "Epoch 520/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3052 - mae: 0.8737 - mse: 1.3052 - val_loss: 1.3668 - val_mae: 0.8854 - val_mse: 1.3668\n",
      "Epoch 521/1000\n",
      "8890/8890 [==============================] - 0s 33us/sample - loss: 1.3043 - mae: 0.8730 - mse: 1.3043 - val_loss: 1.3641 - val_mae: 0.8883 - val_mse: 1.3641\n",
      "Epoch 522/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3029 - mae: 0.8713 - mse: 1.3029 - val_loss: 1.3800 - val_mae: 0.9091 - val_mse: 1.3800\n",
      "Epoch 523/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3043 - mae: 0.8733 - mse: 1.3043 - val_loss: 1.3711 - val_mae: 0.8847 - val_mse: 1.3711\n",
      "Epoch 524/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3048 - mae: 0.8729 - mse: 1.3048 - val_loss: 1.3672 - val_mae: 0.8911 - val_mse: 1.3672\n",
      "Epoch 525/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3035 - mae: 0.8726 - mse: 1.3035 - val_loss: 1.3663 - val_mae: 0.8884 - val_mse: 1.3663\n",
      "Epoch 526/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3041 - mae: 0.8729 - mse: 1.3041 - val_loss: 1.3697 - val_mae: 0.8794 - val_mse: 1.3697\n",
      "Epoch 527/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3037 - mae: 0.8722 - mse: 1.3037 - val_loss: 1.3683 - val_mae: 0.8921 - val_mse: 1.3683\n",
      "Epoch 528/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3044 - mae: 0.8744 - mse: 1.3044 - val_loss: 1.3668 - val_mae: 0.8821 - val_mse: 1.3668\n",
      "Epoch 529/1000\n",
      "8890/8890 [==============================] - 0s 39us/sample - loss: 1.3027 - mae: 0.8717 - mse: 1.3027 - val_loss: 1.3645 - val_mae: 0.8885 - val_mse: 1.3645\n",
      "Epoch 530/1000\n",
      "8890/8890 [==============================] - 0s 39us/sample - loss: 1.3054 - mae: 0.8738 - mse: 1.3054 - val_loss: 1.3674 - val_mae: 0.8905 - val_mse: 1.3674\n",
      "Epoch 531/1000\n",
      "8890/8890 [==============================] - 0s 41us/sample - loss: 1.3053 - mae: 0.8728 - mse: 1.3053 - val_loss: 1.3873 - val_mae: 0.9181 - val_mse: 1.3873\n",
      "Epoch 532/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3030 - mae: 0.8742 - mse: 1.3030 - val_loss: 1.3678 - val_mae: 0.8922 - val_mse: 1.3678\n",
      "Epoch 533/1000\n",
      "8890/8890 [==============================] - 0s 47us/sample - loss: 1.3030 - mae: 0.8730 - mse: 1.3030 - val_loss: 1.3641 - val_mae: 0.8942 - val_mse: 1.3641\n",
      "Epoch 534/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3030 - mae: 0.8725 - mse: 1.3030 - val_loss: 1.3688 - val_mae: 0.8773 - val_mse: 1.3688\n",
      "Epoch 535/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3050 - mae: 0.8726 - mse: 1.3050 - val_loss: 1.3679 - val_mae: 0.8960 - val_mse: 1.3679\n",
      "Epoch 536/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3031 - mae: 0.8726 - mse: 1.3031 - val_loss: 1.3818 - val_mae: 0.9086 - val_mse: 1.3818\n",
      "Epoch 537/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3053 - mae: 0.8734 - mse: 1.3053 - val_loss: 1.3629 - val_mae: 0.8892 - val_mse: 1.3629\n",
      "Epoch 538/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3039 - mae: 0.8731 - mse: 1.3039 - val_loss: 1.3799 - val_mae: 0.9100 - val_mse: 1.3799\n",
      "Epoch 539/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3033 - mae: 0.8735 - mse: 1.3033 - val_loss: 1.3728 - val_mae: 0.8960 - val_mse: 1.3728\n",
      "Epoch 540/1000\n",
      "8890/8890 [==============================] - 1s 69us/sample - loss: 1.3053 - mae: 0.8731 - mse: 1.3053 - val_loss: 1.3696 - val_mae: 0.8815 - val_mse: 1.3696\n",
      "Epoch 541/1000\n",
      "8890/8890 [==============================] - 1s 67us/sample - loss: 1.3040 - mae: 0.8720 - mse: 1.3040 - val_loss: 1.3618 - val_mae: 0.8863 - val_mse: 1.3618\n",
      "Epoch 542/1000\n",
      "8890/8890 [==============================] - 0s 44us/sample - loss: 1.3042 - mae: 0.8729 - mse: 1.3042 - val_loss: 1.3690 - val_mae: 0.8971 - val_mse: 1.3690\n",
      "Epoch 543/1000\n",
      "8890/8890 [==============================] - 1s 57us/sample - loss: 1.3053 - mae: 0.8736 - mse: 1.3053 - val_loss: 1.3746 - val_mae: 0.8751 - val_mse: 1.3746\n",
      "Epoch 544/1000\n",
      "8890/8890 [==============================] - 0s 39us/sample - loss: 1.3041 - mae: 0.8730 - mse: 1.3041 - val_loss: 1.3679 - val_mae: 0.8824 - val_mse: 1.3679\n",
      "Epoch 545/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3052 - mae: 0.8735 - mse: 1.3052 - val_loss: 1.3661 - val_mae: 0.8864 - val_mse: 1.3661\n",
      "Epoch 546/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3044 - mae: 0.8733 - mse: 1.3044 - val_loss: 1.3634 - val_mae: 0.8856 - val_mse: 1.3634\n",
      "Epoch 547/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3031 - mae: 0.8728 - mse: 1.3031 - val_loss: 1.3638 - val_mae: 0.8853 - val_mse: 1.3638\n",
      "Epoch 548/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3047 - mae: 0.8724 - mse: 1.3047 - val_loss: 1.3628 - val_mae: 0.8936 - val_mse: 1.3628\n",
      "Epoch 549/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3040 - mae: 0.8733 - mse: 1.3040 - val_loss: 1.3659 - val_mae: 0.8805 - val_mse: 1.3659\n",
      "Epoch 550/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3044 - mae: 0.8729 - mse: 1.3044 - val_loss: 1.3649 - val_mae: 0.8935 - val_mse: 1.3649\n",
      "Epoch 551/1000\n",
      "8890/8890 [==============================] - 0s 39us/sample - loss: 1.3030 - mae: 0.8735 - mse: 1.3030 - val_loss: 1.3767 - val_mae: 0.8814 - val_mse: 1.3767\n",
      "Epoch 552/1000\n",
      "8890/8890 [==============================] - 0s 39us/sample - loss: 1.3048 - mae: 0.8724 - mse: 1.3048 - val_loss: 1.3689 - val_mae: 0.8870 - val_mse: 1.3689\n",
      "Epoch 553/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3029 - mae: 0.8727 - mse: 1.3029 - val_loss: 1.3680 - val_mae: 0.8862 - val_mse: 1.3680\n",
      "Epoch 554/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3031 - mae: 0.8718 - mse: 1.3031 - val_loss: 1.3666 - val_mae: 0.8966 - val_mse: 1.3666\n",
      "Epoch 555/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3040 - mae: 0.8730 - mse: 1.3040 - val_loss: 1.3646 - val_mae: 0.8919 - val_mse: 1.3646\n",
      "Epoch 556/1000\n",
      "8890/8890 [==============================] - 0s 41us/sample - loss: 1.3042 - mae: 0.8724 - mse: 1.3042 - val_loss: 1.3657 - val_mae: 0.8813 - val_mse: 1.3657\n",
      "Epoch 557/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3046 - mae: 0.8730 - mse: 1.3046 - val_loss: 1.3640 - val_mae: 0.8897 - val_mse: 1.3640\n",
      "Epoch 558/1000\n",
      "8890/8890 [==============================] - 0s 33us/sample - loss: 1.3038 - mae: 0.8733 - mse: 1.3038 - val_loss: 1.3625 - val_mae: 0.8864 - val_mse: 1.3625\n",
      "Epoch 559/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3032 - mae: 0.8715 - mse: 1.3032 - val_loss: 1.3708 - val_mae: 0.8780 - val_mse: 1.3708\n",
      "Epoch 560/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3026 - mae: 0.8726 - mse: 1.3026 - val_loss: 1.3741 - val_mae: 0.8775 - val_mse: 1.3741\n",
      "Epoch 561/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3051 - mae: 0.8729 - mse: 1.3051 - val_loss: 1.3633 - val_mae: 0.8894 - val_mse: 1.3633\n",
      "Epoch 562/1000\n",
      "8890/8890 [==============================] - 0s 45us/sample - loss: 1.3048 - mae: 0.8734 - mse: 1.3048 - val_loss: 1.3680 - val_mae: 0.8951 - val_mse: 1.3680\n",
      "Epoch 563/1000\n",
      "8890/8890 [==============================] - 0s 53us/sample - loss: 1.3046 - mae: 0.8730 - mse: 1.3046 - val_loss: 1.3669 - val_mae: 0.8809 - val_mse: 1.3669\n",
      "Epoch 564/1000\n",
      "8890/8890 [==============================] - 0s 32us/sample - loss: 1.3048 - mae: 0.8729 - mse: 1.3048 - val_loss: 1.3667 - val_mae: 0.8880 - val_mse: 1.3667\n",
      "Epoch 565/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3043 - mae: 0.8723 - mse: 1.3043 - val_loss: 1.3681 - val_mae: 0.8969 - val_mse: 1.3681\n",
      "Epoch 566/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8890/8890 [==============================] - 0s 49us/sample - loss: 1.3025 - mae: 0.8727 - mse: 1.3025 - val_loss: 1.3675 - val_mae: 0.8836 - val_mse: 1.3675\n",
      "Epoch 567/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3037 - mae: 0.8723 - mse: 1.3037 - val_loss: 1.3634 - val_mae: 0.8922 - val_mse: 1.3634\n",
      "Epoch 568/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3023 - mae: 0.8723 - mse: 1.3023 - val_loss: 1.3655 - val_mae: 0.8885 - val_mse: 1.3655\n",
      "Epoch 569/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3020 - mae: 0.8723 - mse: 1.3020 - val_loss: 1.3747 - val_mae: 0.8827 - val_mse: 1.3747\n",
      "Epoch 570/1000\n",
      "8890/8890 [==============================] - 0s 43us/sample - loss: 1.3043 - mae: 0.8730 - mse: 1.3043 - val_loss: 1.3658 - val_mae: 0.8965 - val_mse: 1.3658\n",
      "Epoch 571/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3045 - mae: 0.8730 - mse: 1.3045 - val_loss: 1.3678 - val_mae: 0.8899 - val_mse: 1.3678\n",
      "Epoch 572/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3053 - mae: 0.8736 - mse: 1.3053 - val_loss: 1.3818 - val_mae: 0.9102 - val_mse: 1.3818\n",
      "Epoch 573/1000\n",
      "8890/8890 [==============================] - 0s 43us/sample - loss: 1.3053 - mae: 0.8742 - mse: 1.3053 - val_loss: 1.3666 - val_mae: 0.8892 - val_mse: 1.3666\n",
      "Epoch 574/1000\n",
      "8890/8890 [==============================] - 0s 49us/sample - loss: 1.3060 - mae: 0.8732 - mse: 1.3060 - val_loss: 1.3672 - val_mae: 0.8839 - val_mse: 1.3672\n",
      "Epoch 575/1000\n",
      "8890/8890 [==============================] - 0s 44us/sample - loss: 1.3040 - mae: 0.8716 - mse: 1.3040 - val_loss: 1.3861 - val_mae: 0.9167 - val_mse: 1.3861\n",
      "Epoch 576/1000\n",
      "8890/8890 [==============================] - 0s 52us/sample - loss: 1.3044 - mae: 0.8743 - mse: 1.3044 - val_loss: 1.3681 - val_mae: 0.8917 - val_mse: 1.3681\n",
      "Epoch 577/1000\n",
      "8890/8890 [==============================] - 1s 57us/sample - loss: 1.3057 - mae: 0.8731 - mse: 1.3057 - val_loss: 1.3654 - val_mae: 0.8939 - val_mse: 1.3654\n",
      "Epoch 578/1000\n",
      "8890/8890 [==============================] - 1s 65us/sample - loss: 1.3039 - mae: 0.8729 - mse: 1.3039 - val_loss: 1.3653 - val_mae: 0.8853 - val_mse: 1.3653\n",
      "Epoch 579/1000\n",
      "8890/8890 [==============================] - 0s 44us/sample - loss: 1.3049 - mae: 0.8721 - mse: 1.3049 - val_loss: 1.3652 - val_mae: 0.8833 - val_mse: 1.3652\n",
      "Epoch 580/1000\n",
      "8890/8890 [==============================] - 0s 47us/sample - loss: 1.3032 - mae: 0.8719 - mse: 1.3032 - val_loss: 1.3690 - val_mae: 0.9009 - val_mse: 1.3690\n",
      "Epoch 581/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3054 - mae: 0.8743 - mse: 1.3054 - val_loss: 1.3661 - val_mae: 0.8814 - val_mse: 1.3661\n",
      "Epoch 582/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3045 - mae: 0.8726 - mse: 1.3045 - val_loss: 1.3651 - val_mae: 0.8818 - val_mse: 1.3651\n",
      "Epoch 583/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3051 - mae: 0.8727 - mse: 1.3051 - val_loss: 1.3668 - val_mae: 0.8910 - val_mse: 1.3668\n",
      "Epoch 584/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3042 - mae: 0.8740 - mse: 1.3042 - val_loss: 1.3662 - val_mae: 0.8836 - val_mse: 1.3662\n",
      "Epoch 585/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3040 - mae: 0.8721 - mse: 1.3040 - val_loss: 1.3708 - val_mae: 0.8893 - val_mse: 1.3708\n",
      "Epoch 586/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3036 - mae: 0.8720 - mse: 1.3036 - val_loss: 1.3707 - val_mae: 0.8761 - val_mse: 1.3707\n",
      "Epoch 587/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3047 - mae: 0.8726 - mse: 1.3047 - val_loss: 1.3630 - val_mae: 0.8862 - val_mse: 1.3630\n",
      "Epoch 588/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3051 - mae: 0.8739 - mse: 1.3051 - val_loss: 1.3683 - val_mae: 0.8787 - val_mse: 1.3683\n",
      "Epoch 589/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3032 - mae: 0.8725 - mse: 1.3032 - val_loss: 1.3699 - val_mae: 0.8805 - val_mse: 1.3699\n",
      "Epoch 590/1000\n",
      "8890/8890 [==============================] - 0s 33us/sample - loss: 1.3028 - mae: 0.8713 - mse: 1.3028 - val_loss: 1.3918 - val_mae: 0.9178 - val_mse: 1.3918\n",
      "Epoch 591/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3063 - mae: 0.8743 - mse: 1.3063 - val_loss: 1.3651 - val_mae: 0.8935 - val_mse: 1.3651\n",
      "Epoch 592/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3035 - mae: 0.8734 - mse: 1.3035 - val_loss: 1.3713 - val_mae: 0.8993 - val_mse: 1.3713\n",
      "Epoch 593/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3033 - mae: 0.8739 - mse: 1.3033 - val_loss: 1.3695 - val_mae: 0.8900 - val_mse: 1.3695\n",
      "Epoch 594/1000\n",
      "8890/8890 [==============================] - 0s 33us/sample - loss: 1.3053 - mae: 0.8728 - mse: 1.3053 - val_loss: 1.3655 - val_mae: 0.8823 - val_mse: 1.3655\n",
      "Epoch 595/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3041 - mae: 0.8735 - mse: 1.3041 - val_loss: 1.3749 - val_mae: 0.8979 - val_mse: 1.3749\n",
      "Epoch 596/1000\n",
      "8890/8890 [==============================] - 1s 60us/sample - loss: 1.3048 - mae: 0.8729 - mse: 1.3048 - val_loss: 1.3675 - val_mae: 0.8955 - val_mse: 1.3675\n",
      "Epoch 597/1000\n",
      "8890/8890 [==============================] - 0s 49us/sample - loss: 1.3051 - mae: 0.8727 - mse: 1.3051 - val_loss: 1.3675 - val_mae: 0.8946 - val_mse: 1.3675\n",
      "Epoch 598/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3039 - mae: 0.8730 - mse: 1.3039 - val_loss: 1.3672 - val_mae: 0.8796 - val_mse: 1.3672\n",
      "Epoch 599/1000\n",
      "8890/8890 [==============================] - 1s 83us/sample - loss: 1.3045 - mae: 0.8720 - mse: 1.3045 - val_loss: 1.3711 - val_mae: 0.9025 - val_mse: 1.3711\n",
      "Epoch 600/1000\n",
      "8890/8890 [==============================] - 0s 32us/sample - loss: 1.3038 - mae: 0.8734 - mse: 1.3038 - val_loss: 1.3657 - val_mae: 0.8856 - val_mse: 1.3657\n",
      "Epoch 601/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3049 - mae: 0.8728 - mse: 1.3049 - val_loss: 1.3720 - val_mae: 0.9018 - val_mse: 1.3720\n",
      "Epoch 602/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3031 - mae: 0.8730 - mse: 1.3031 - val_loss: 1.3694 - val_mae: 0.9016 - val_mse: 1.3694\n",
      "Epoch 603/1000\n",
      "8890/8890 [==============================] - 0s 39us/sample - loss: 1.3048 - mae: 0.8731 - mse: 1.3048 - val_loss: 1.3648 - val_mae: 0.8914 - val_mse: 1.3648\n",
      "Epoch 604/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3033 - mae: 0.8722 - mse: 1.3033 - val_loss: 1.3645 - val_mae: 0.8910 - val_mse: 1.3645\n",
      "Epoch 605/1000\n",
      "8890/8890 [==============================] - 0s 56us/sample - loss: 1.3038 - mae: 0.8738 - mse: 1.3038 - val_loss: 1.3644 - val_mae: 0.8823 - val_mse: 1.3644\n",
      "Epoch 606/1000\n",
      "8890/8890 [==============================] - 0s 39us/sample - loss: 1.3052 - mae: 0.8733 - mse: 1.3052 - val_loss: 1.3663 - val_mae: 0.8791 - val_mse: 1.3663\n",
      "Epoch 607/1000\n",
      "8890/8890 [==============================] - 0s 41us/sample - loss: 1.3042 - mae: 0.8725 - mse: 1.3042 - val_loss: 1.3634 - val_mae: 0.8896 - val_mse: 1.3634\n",
      "Epoch 608/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3050 - mae: 0.8735 - mse: 1.3050 - val_loss: 1.3619 - val_mae: 0.8858 - val_mse: 1.3619\n",
      "Epoch 609/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3022 - mae: 0.8720 - mse: 1.3022 - val_loss: 1.4076 - val_mae: 0.9317 - val_mse: 1.4076\n",
      "Epoch 610/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3043 - mae: 0.8749 - mse: 1.3043 - val_loss: 1.3675 - val_mae: 0.8869 - val_mse: 1.3675\n",
      "Epoch 611/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3047 - mae: 0.8726 - mse: 1.3047 - val_loss: 1.3741 - val_mae: 0.9059 - val_mse: 1.3741\n",
      "Epoch 612/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3032 - mae: 0.8734 - mse: 1.3032 - val_loss: 1.3669 - val_mae: 0.8825 - val_mse: 1.3669\n",
      "Epoch 613/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3034 - mae: 0.8721 - mse: 1.3034 - val_loss: 1.3636 - val_mae: 0.8898 - val_mse: 1.3636\n",
      "Epoch 614/1000\n",
      "8890/8890 [==============================] - 0s 41us/sample - loss: 1.3036 - mae: 0.8728 - mse: 1.3036 - val_loss: 1.3671 - val_mae: 0.8962 - val_mse: 1.3671\n",
      "Epoch 615/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3024 - mae: 0.8721 - mse: 1.3024 - val_loss: 1.3796 - val_mae: 0.9058 - val_mse: 1.3796\n",
      "Epoch 616/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3052 - mae: 0.8732 - mse: 1.3052 - val_loss: 1.3639 - val_mae: 0.8918 - val_mse: 1.3639\n",
      "Epoch 617/1000\n",
      "8890/8890 [==============================] - 0s 53us/sample - loss: 1.3023 - mae: 0.8726 - mse: 1.3023 - val_loss: 1.3690 - val_mae: 0.8828 - val_mse: 1.3690\n",
      "Epoch 618/1000\n",
      "8890/8890 [==============================] - 0s 48us/sample - loss: 1.3042 - mae: 0.8724 - mse: 1.3042 - val_loss: 1.3671 - val_mae: 0.8972 - val_mse: 1.3671\n",
      "Epoch 619/1000\n",
      "8890/8890 [==============================] - 1s 71us/sample - loss: 1.3031 - mae: 0.8720 - mse: 1.3031 - val_loss: 1.3670 - val_mae: 0.8838 - val_mse: 1.3670\n",
      "Epoch 620/1000\n",
      "8890/8890 [==============================] - 0s 44us/sample - loss: 1.3041 - mae: 0.8727 - mse: 1.3041 - val_loss: 1.3678 - val_mae: 0.8863 - val_mse: 1.3678\n",
      "Epoch 621/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3035 - mae: 0.8724 - mse: 1.3035 - val_loss: 1.3673 - val_mae: 0.8854 - val_mse: 1.3673\n",
      "Epoch 622/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3037 - mae: 0.8721 - mse: 1.3037 - val_loss: 1.3694 - val_mae: 0.8974 - val_mse: 1.3694\n",
      "Epoch 623/1000\n",
      "8890/8890 [==============================] - 1s 67us/sample - loss: 1.3035 - mae: 0.8725 - mse: 1.3035 - val_loss: 1.3651 - val_mae: 0.8844 - val_mse: 1.3651\n",
      "Epoch 624/1000\n",
      "8890/8890 [==============================] - 1s 75us/sample - loss: 1.3033 - mae: 0.8732 - mse: 1.3033 - val_loss: 1.3743 - val_mae: 0.8809 - val_mse: 1.3743\n",
      "Epoch 625/1000\n",
      "8890/8890 [==============================] - 1s 61us/sample - loss: 1.3026 - mae: 0.8725 - mse: 1.3026 - val_loss: 1.3648 - val_mae: 0.8909 - val_mse: 1.3648\n",
      "Epoch 626/1000\n",
      "8890/8890 [==============================] - 0s 50us/sample - loss: 1.3022 - mae: 0.8721 - mse: 1.3022 - val_loss: 1.3730 - val_mae: 0.8813 - val_mse: 1.3730\n",
      "Epoch 627/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3031 - mae: 0.8716 - mse: 1.3031 - val_loss: 1.3660 - val_mae: 0.8962 - val_mse: 1.3660\n",
      "Epoch 628/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3051 - mae: 0.8738 - mse: 1.3051 - val_loss: 1.3676 - val_mae: 0.8960 - val_mse: 1.3676\n",
      "Epoch 629/1000\n",
      "8890/8890 [==============================] - 0s 31us/sample - loss: 1.3022 - mae: 0.8722 - mse: 1.3022 - val_loss: 1.3663 - val_mae: 0.8947 - val_mse: 1.3663\n",
      "Epoch 630/1000\n",
      "8890/8890 [==============================] - 0s 33us/sample - loss: 1.3025 - mae: 0.8722 - mse: 1.3025 - val_loss: 1.3721 - val_mae: 0.8835 - val_mse: 1.3721\n",
      "Epoch 631/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3021 - mae: 0.8713 - mse: 1.3021 - val_loss: 1.3729 - val_mae: 0.9018 - val_mse: 1.3729\n",
      "Epoch 632/1000\n",
      "8890/8890 [==============================] - 0s 33us/sample - loss: 1.3031 - mae: 0.8730 - mse: 1.3031 - val_loss: 1.3754 - val_mae: 0.9026 - val_mse: 1.3754\n",
      "Epoch 633/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3030 - mae: 0.8726 - mse: 1.3030 - val_loss: 1.3758 - val_mae: 0.9074 - val_mse: 1.3758\n",
      "Epoch 634/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3048 - mae: 0.8744 - mse: 1.3048 - val_loss: 1.3729 - val_mae: 0.9013 - val_mse: 1.3729\n",
      "Epoch 635/1000\n",
      "8890/8890 [==============================] - 0s 31us/sample - loss: 1.3029 - mae: 0.8725 - mse: 1.3029 - val_loss: 1.3799 - val_mae: 0.9094 - val_mse: 1.3799\n",
      "Epoch 636/1000\n",
      "8890/8890 [==============================] - 0s 41us/sample - loss: 1.3026 - mae: 0.8731 - mse: 1.3026 - val_loss: 1.3682 - val_mae: 0.8889 - val_mse: 1.3682\n",
      "Epoch 637/1000\n",
      "8890/8890 [==============================] - 0s 41us/sample - loss: 1.3038 - mae: 0.8733 - mse: 1.3038 - val_loss: 1.3658 - val_mae: 0.8906 - val_mse: 1.3658\n",
      "Epoch 638/1000\n",
      "8890/8890 [==============================] - 0s 33us/sample - loss: 1.3036 - mae: 0.8735 - mse: 1.3036 - val_loss: 1.3674 - val_mae: 0.8940 - val_mse: 1.3674\n",
      "Epoch 639/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3034 - mae: 0.8727 - mse: 1.3034 - val_loss: 1.3607 - val_mae: 0.8857 - val_mse: 1.3607\n",
      "Epoch 640/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3044 - mae: 0.8724 - mse: 1.3044 - val_loss: 1.3675 - val_mae: 0.8848 - val_mse: 1.3675\n",
      "Epoch 641/1000\n",
      "8890/8890 [==============================] - 0s 51us/sample - loss: 1.3031 - mae: 0.8720 - mse: 1.3031 - val_loss: 1.3664 - val_mae: 0.8907 - val_mse: 1.3664\n",
      "Epoch 642/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3025 - mae: 0.8725 - mse: 1.3025 - val_loss: 1.3889 - val_mae: 0.8902 - val_mse: 1.3889\n",
      "Epoch 643/1000\n",
      "8890/8890 [==============================] - 0s 41us/sample - loss: 1.3056 - mae: 0.8746 - mse: 1.3056 - val_loss: 1.3694 - val_mae: 0.8783 - val_mse: 1.3694\n",
      "Epoch 644/1000\n",
      "8890/8890 [==============================] - 0s 42us/sample - loss: 1.3048 - mae: 0.8727 - mse: 1.3048 - val_loss: 1.3675 - val_mae: 0.8949 - val_mse: 1.3675\n",
      "Epoch 645/1000\n",
      "8890/8890 [==============================] - 0s 39us/sample - loss: 1.3031 - mae: 0.8728 - mse: 1.3031 - val_loss: 1.3791 - val_mae: 0.9082 - val_mse: 1.3791\n",
      "Epoch 646/1000\n",
      "8890/8890 [==============================] - 0s 55us/sample - loss: 1.3036 - mae: 0.8731 - mse: 1.3036 - val_loss: 1.3807 - val_mae: 0.8773 - val_mse: 1.3807\n",
      "Epoch 647/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3046 - mae: 0.8718 - mse: 1.3046 - val_loss: 1.3675 - val_mae: 0.8946 - val_mse: 1.3675\n",
      "Epoch 648/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3031 - mae: 0.8716 - mse: 1.3031 - val_loss: 1.3708 - val_mae: 0.9025 - val_mse: 1.3708\n",
      "Epoch 649/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3028 - mae: 0.8716 - mse: 1.3028 - val_loss: 1.3745 - val_mae: 0.9011 - val_mse: 1.3745\n",
      "Epoch 650/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3037 - mae: 0.8728 - mse: 1.3037 - val_loss: 1.3691 - val_mae: 0.8846 - val_mse: 1.3691\n",
      "Epoch 651/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3043 - mae: 0.8733 - mse: 1.3043 - val_loss: 1.3647 - val_mae: 0.8859 - val_mse: 1.3647\n",
      "Epoch 652/1000\n",
      "8890/8890 [==============================] - 0s 50us/sample - loss: 1.3048 - mae: 0.8736 - mse: 1.3048 - val_loss: 1.3668 - val_mae: 0.8853 - val_mse: 1.3668\n",
      "Epoch 653/1000\n",
      "8890/8890 [==============================] - 0s 54us/sample - loss: 1.3031 - mae: 0.8728 - mse: 1.3031 - val_loss: 1.3626 - val_mae: 0.8815 - val_mse: 1.3626\n",
      "Epoch 654/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3018 - mae: 0.8723 - mse: 1.3018 - val_loss: 1.3669 - val_mae: 0.8912 - val_mse: 1.3669\n",
      "Epoch 655/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3046 - mae: 0.8730 - mse: 1.3046 - val_loss: 1.3687 - val_mae: 0.8872 - val_mse: 1.3687\n",
      "Epoch 656/1000\n",
      "8890/8890 [==============================] - 0s 39us/sample - loss: 1.3037 - mae: 0.8727 - mse: 1.3037 - val_loss: 1.3693 - val_mae: 0.8817 - val_mse: 1.3693\n",
      "Epoch 657/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3035 - mae: 0.8718 - mse: 1.3035 - val_loss: 1.3673 - val_mae: 0.8935 - val_mse: 1.3673\n",
      "Epoch 658/1000\n",
      "8890/8890 [==============================] - 0s 46us/sample - loss: 1.3035 - mae: 0.8731 - mse: 1.3035 - val_loss: 1.3686 - val_mae: 0.8936 - val_mse: 1.3686\n",
      "Epoch 659/1000\n",
      "8890/8890 [==============================] - 1s 57us/sample - loss: 1.3030 - mae: 0.8725 - mse: 1.3030 - val_loss: 1.3693 - val_mae: 0.8857 - val_mse: 1.3693\n",
      "Epoch 660/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8890/8890 [==============================] - 0s 50us/sample - loss: 1.3036 - mae: 0.8726 - mse: 1.3036 - val_loss: 1.3683 - val_mae: 0.8960 - val_mse: 1.3683\n",
      "Epoch 661/1000\n",
      "8890/8890 [==============================] - 0s 44us/sample - loss: 1.3029 - mae: 0.8740 - mse: 1.3029 - val_loss: 1.3622 - val_mae: 0.8902 - val_mse: 1.3622\n",
      "Epoch 662/1000\n",
      "8890/8890 [==============================] - 0s 46us/sample - loss: 1.3025 - mae: 0.8723 - mse: 1.3025 - val_loss: 1.3671 - val_mae: 0.8994 - val_mse: 1.3671\n",
      "Epoch 663/1000\n",
      "8890/8890 [==============================] - 0s 32us/sample - loss: 1.3048 - mae: 0.8743 - mse: 1.3048 - val_loss: 1.3659 - val_mae: 0.8838 - val_mse: 1.3659\n",
      "Epoch 664/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3055 - mae: 0.8741 - mse: 1.3055 - val_loss: 1.3670 - val_mae: 0.8809 - val_mse: 1.3670\n",
      "Epoch 665/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3027 - mae: 0.8728 - mse: 1.3027 - val_loss: 1.3662 - val_mae: 0.8928 - val_mse: 1.3662\n",
      "Epoch 666/1000\n",
      "8890/8890 [==============================] - 0s 33us/sample - loss: 1.3015 - mae: 0.8724 - mse: 1.3015 - val_loss: 1.3718 - val_mae: 0.8805 - val_mse: 1.3718\n",
      "Epoch 667/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3043 - mae: 0.8724 - mse: 1.3043 - val_loss: 1.3671 - val_mae: 0.8943 - val_mse: 1.3671\n",
      "Epoch 668/1000\n",
      "8890/8890 [==============================] - 0s 32us/sample - loss: 1.3022 - mae: 0.8723 - mse: 1.3022 - val_loss: 1.3764 - val_mae: 0.8946 - val_mse: 1.3764\n",
      "Epoch 669/1000\n",
      "8890/8890 [==============================] - 0s 31us/sample - loss: 1.3020 - mae: 0.8724 - mse: 1.3020 - val_loss: 1.3605 - val_mae: 0.8855 - val_mse: 1.3605\n",
      "Epoch 670/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3034 - mae: 0.8726 - mse: 1.3034 - val_loss: 1.3760 - val_mae: 0.8792 - val_mse: 1.3760\n",
      "Epoch 671/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3037 - mae: 0.8721 - mse: 1.3037 - val_loss: 1.3723 - val_mae: 0.8797 - val_mse: 1.3723\n",
      "Epoch 672/1000\n",
      "8890/8890 [==============================] - 0s 39us/sample - loss: 1.3040 - mae: 0.8723 - mse: 1.3040 - val_loss: 1.3642 - val_mae: 0.8893 - val_mse: 1.3642\n",
      "Epoch 673/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3019 - mae: 0.8728 - mse: 1.3019 - val_loss: 1.3712 - val_mae: 0.8824 - val_mse: 1.3712\n",
      "Epoch 674/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3021 - mae: 0.8724 - mse: 1.3021 - val_loss: 1.3736 - val_mae: 0.8780 - val_mse: 1.3736\n",
      "Epoch 675/1000\n",
      "8890/8890 [==============================] - 0s 33us/sample - loss: 1.3030 - mae: 0.8709 - mse: 1.3030 - val_loss: 1.3718 - val_mae: 0.9029 - val_mse: 1.3718\n",
      "Epoch 676/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3045 - mae: 0.8738 - mse: 1.3045 - val_loss: 1.3699 - val_mae: 0.8897 - val_mse: 1.3699\n",
      "Epoch 677/1000\n",
      "8890/8890 [==============================] - 0s 33us/sample - loss: 1.3032 - mae: 0.8723 - mse: 1.3032 - val_loss: 1.3630 - val_mae: 0.8879 - val_mse: 1.3630\n",
      "Epoch 678/1000\n",
      "8890/8890 [==============================] - 0s 39us/sample - loss: 1.3036 - mae: 0.8720 - mse: 1.3036 - val_loss: 1.3957 - val_mae: 0.9232 - val_mse: 1.3957\n",
      "Epoch 679/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3031 - mae: 0.8736 - mse: 1.3031 - val_loss: 1.3652 - val_mae: 0.8833 - val_mse: 1.3652\n",
      "Epoch 680/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3052 - mae: 0.8728 - mse: 1.3052 - val_loss: 1.3720 - val_mae: 0.8760 - val_mse: 1.3720\n",
      "Epoch 681/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3030 - mae: 0.8713 - mse: 1.3030 - val_loss: 1.3880 - val_mae: 0.9185 - val_mse: 1.3880\n",
      "Epoch 682/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3039 - mae: 0.8737 - mse: 1.3039 - val_loss: 1.3705 - val_mae: 0.8827 - val_mse: 1.3705\n",
      "Epoch 683/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3051 - mae: 0.8733 - mse: 1.3051 - val_loss: 1.3693 - val_mae: 0.8925 - val_mse: 1.3693\n",
      "Epoch 684/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3048 - mae: 0.8725 - mse: 1.3048 - val_loss: 1.3684 - val_mae: 0.8913 - val_mse: 1.3684\n",
      "Epoch 685/1000\n",
      "8890/8890 [==============================] - 0s 45us/sample - loss: 1.3027 - mae: 0.8726 - mse: 1.3027 - val_loss: 1.3732 - val_mae: 0.8847 - val_mse: 1.3732\n",
      "Epoch 686/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3044 - mae: 0.8735 - mse: 1.3044 - val_loss: 1.3686 - val_mae: 0.8808 - val_mse: 1.3686\n",
      "Epoch 687/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3038 - mae: 0.8723 - mse: 1.3038 - val_loss: 1.3633 - val_mae: 0.8867 - val_mse: 1.3633\n",
      "Epoch 688/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3025 - mae: 0.8725 - mse: 1.3025 - val_loss: 1.3712 - val_mae: 0.8897 - val_mse: 1.3712\n",
      "Epoch 689/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3034 - mae: 0.8723 - mse: 1.3034 - val_loss: 1.3677 - val_mae: 0.8943 - val_mse: 1.3677\n",
      "Epoch 690/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3037 - mae: 0.8726 - mse: 1.3037 - val_loss: 1.3684 - val_mae: 0.8933 - val_mse: 1.3684\n",
      "Epoch 691/1000\n",
      "8890/8890 [==============================] - 0s 42us/sample - loss: 1.3029 - mae: 0.8729 - mse: 1.3029 - val_loss: 1.3653 - val_mae: 0.8809 - val_mse: 1.3653\n",
      "Epoch 692/1000\n",
      "8890/8890 [==============================] - 0s 42us/sample - loss: 1.3041 - mae: 0.8717 - mse: 1.3041 - val_loss: 1.3695 - val_mae: 0.8820 - val_mse: 1.3695\n",
      "Epoch 693/1000\n",
      "8890/8890 [==============================] - 0s 42us/sample - loss: 1.3029 - mae: 0.8720 - mse: 1.3029 - val_loss: 1.3694 - val_mae: 0.8800 - val_mse: 1.3694\n",
      "Epoch 694/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3046 - mae: 0.8719 - mse: 1.3046 - val_loss: 1.3639 - val_mae: 0.8891 - val_mse: 1.3639\n",
      "Epoch 695/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3024 - mae: 0.8725 - mse: 1.3024 - val_loss: 1.3954 - val_mae: 0.9221 - val_mse: 1.3954\n",
      "Epoch 696/1000\n",
      "8890/8890 [==============================] - 0s 33us/sample - loss: 1.3044 - mae: 0.8734 - mse: 1.3044 - val_loss: 1.3670 - val_mae: 0.8935 - val_mse: 1.3670\n",
      "Epoch 697/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3034 - mae: 0.8713 - mse: 1.3034 - val_loss: 1.3835 - val_mae: 0.9127 - val_mse: 1.3835\n",
      "Epoch 698/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3035 - mae: 0.8736 - mse: 1.3035 - val_loss: 1.3884 - val_mae: 0.9155 - val_mse: 1.3884\n",
      "Epoch 699/1000\n",
      "8890/8890 [==============================] - 0s 39us/sample - loss: 1.3037 - mae: 0.8730 - mse: 1.3037 - val_loss: 1.3670 - val_mae: 0.8808 - val_mse: 1.3670\n",
      "Epoch 700/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3046 - mae: 0.8723 - mse: 1.3046 - val_loss: 1.3637 - val_mae: 0.8887 - val_mse: 1.3637\n",
      "Epoch 701/1000\n",
      "8890/8890 [==============================] - 0s 54us/sample - loss: 1.3037 - mae: 0.8726 - mse: 1.3037 - val_loss: 1.3675 - val_mae: 0.8880 - val_mse: 1.3675\n",
      "Epoch 702/1000\n",
      "8890/8890 [==============================] - 0s 56us/sample - loss: 1.3038 - mae: 0.8731 - mse: 1.3038 - val_loss: 1.3689 - val_mae: 0.8843 - val_mse: 1.3689\n",
      "Epoch 703/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3024 - mae: 0.8719 - mse: 1.3024 - val_loss: 1.3651 - val_mae: 0.8892 - val_mse: 1.3651\n",
      "Epoch 704/1000\n",
      "8890/8890 [==============================] - 0s 33us/sample - loss: 1.3041 - mae: 0.8737 - mse: 1.3041 - val_loss: 1.3693 - val_mae: 0.8987 - val_mse: 1.3693\n",
      "Epoch 705/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3031 - mae: 0.8730 - mse: 1.3031 - val_loss: 1.3682 - val_mae: 0.8827 - val_mse: 1.3682\n",
      "Epoch 706/1000\n",
      "8890/8890 [==============================] - 0s 42us/sample - loss: 1.3037 - mae: 0.8720 - mse: 1.3037 - val_loss: 1.3658 - val_mae: 0.8966 - val_mse: 1.3658\n",
      "Epoch 707/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8890/8890 [==============================] - 0s 44us/sample - loss: 1.3025 - mae: 0.8728 - mse: 1.3025 - val_loss: 1.3671 - val_mae: 0.8813 - val_mse: 1.3671\n",
      "Epoch 708/1000\n",
      "8890/8890 [==============================] - 0s 47us/sample - loss: 1.3062 - mae: 0.8734 - mse: 1.3062 - val_loss: 1.3772 - val_mae: 0.8795 - val_mse: 1.3772\n",
      "Epoch 709/1000\n",
      "8890/8890 [==============================] - 0s 52us/sample - loss: 1.3037 - mae: 0.8710 - mse: 1.3037 - val_loss: 1.3753 - val_mae: 0.9057 - val_mse: 1.3753\n",
      "Epoch 710/1000\n",
      "8890/8890 [==============================] - 0s 41us/sample - loss: 1.3035 - mae: 0.8729 - mse: 1.3035 - val_loss: 1.3685 - val_mae: 0.8818 - val_mse: 1.3685\n",
      "Epoch 711/1000\n",
      "8890/8890 [==============================] - 0s 43us/sample - loss: 1.3025 - mae: 0.8720 - mse: 1.3025 - val_loss: 1.3663 - val_mae: 0.8963 - val_mse: 1.3663\n",
      "Epoch 712/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3036 - mae: 0.8731 - mse: 1.3036 - val_loss: 1.3675 - val_mae: 0.8789 - val_mse: 1.3675\n",
      "Epoch 713/1000\n",
      "8890/8890 [==============================] - 0s 39us/sample - loss: 1.2982 - mae: 0.8702 - mse: 1.2982 - val_loss: 1.3873 - val_mae: 0.9158 - val_mse: 1.3873\n",
      "Epoch 714/1000\n",
      "8890/8890 [==============================] - 0s 39us/sample - loss: 1.3066 - mae: 0.8741 - mse: 1.3066 - val_loss: 1.3657 - val_mae: 0.8942 - val_mse: 1.3657\n",
      "Epoch 715/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3032 - mae: 0.8736 - mse: 1.3032 - val_loss: 1.3702 - val_mae: 0.8920 - val_mse: 1.3702\n",
      "Epoch 716/1000\n",
      "8890/8890 [==============================] - 0s 42us/sample - loss: 1.3041 - mae: 0.8732 - mse: 1.3041 - val_loss: 1.3661 - val_mae: 0.8941 - val_mse: 1.3661\n",
      "Epoch 717/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3040 - mae: 0.8713 - mse: 1.3040 - val_loss: 1.3739 - val_mae: 0.9002 - val_mse: 1.3739\n",
      "Epoch 718/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3057 - mae: 0.8735 - mse: 1.3057 - val_loss: 1.3705 - val_mae: 0.9010 - val_mse: 1.3705\n",
      "Epoch 719/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3037 - mae: 0.8727 - mse: 1.3037 - val_loss: 1.3690 - val_mae: 0.8978 - val_mse: 1.3690\n",
      "Epoch 720/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3036 - mae: 0.8722 - mse: 1.3036 - val_loss: 1.3691 - val_mae: 0.8953 - val_mse: 1.3691\n",
      "Epoch 721/1000\n",
      "8890/8890 [==============================] - 0s 33us/sample - loss: 1.3051 - mae: 0.8732 - mse: 1.3051 - val_loss: 1.3656 - val_mae: 0.8874 - val_mse: 1.3656\n",
      "Epoch 722/1000\n",
      "8890/8890 [==============================] - 0s 32us/sample - loss: 1.3018 - mae: 0.8723 - mse: 1.3018 - val_loss: 1.3703 - val_mae: 0.8964 - val_mse: 1.3703\n",
      "Epoch 723/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3027 - mae: 0.8718 - mse: 1.3027 - val_loss: 1.3719 - val_mae: 0.9018 - val_mse: 1.3719\n",
      "Epoch 724/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3040 - mae: 0.8737 - mse: 1.3040 - val_loss: 1.3669 - val_mae: 0.8795 - val_mse: 1.3669\n",
      "Epoch 725/1000\n",
      "8890/8890 [==============================] - 0s 45us/sample - loss: 1.3023 - mae: 0.8710 - mse: 1.3023 - val_loss: 1.3690 - val_mae: 0.8897 - val_mse: 1.3690\n",
      "Epoch 726/1000\n",
      "8890/8890 [==============================] - 0s 39us/sample - loss: 1.3035 - mae: 0.8729 - mse: 1.3035 - val_loss: 1.3798 - val_mae: 0.9093 - val_mse: 1.3798\n",
      "Epoch 727/1000\n",
      "8890/8890 [==============================] - 1s 57us/sample - loss: 1.3032 - mae: 0.8737 - mse: 1.3032 - val_loss: 1.3641 - val_mae: 0.8925 - val_mse: 1.3641\n",
      "Epoch 728/1000\n",
      "8890/8890 [==============================] - 0s 32us/sample - loss: 1.3049 - mae: 0.8734 - mse: 1.3049 - val_loss: 1.3622 - val_mae: 0.8887 - val_mse: 1.3622\n",
      "Epoch 729/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3030 - mae: 0.8726 - mse: 1.3030 - val_loss: 1.3684 - val_mae: 0.8864 - val_mse: 1.3684\n",
      "Epoch 730/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3031 - mae: 0.8723 - mse: 1.3031 - val_loss: 1.3669 - val_mae: 0.8954 - val_mse: 1.3669\n",
      "Epoch 731/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3032 - mae: 0.8729 - mse: 1.3032 - val_loss: 1.3643 - val_mae: 0.8868 - val_mse: 1.3643\n",
      "Epoch 732/1000\n",
      "8890/8890 [==============================] - 0s 33us/sample - loss: 1.3037 - mae: 0.8730 - mse: 1.3037 - val_loss: 1.3620 - val_mae: 0.8895 - val_mse: 1.3620\n",
      "Epoch 733/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3046 - mae: 0.8730 - mse: 1.3046 - val_loss: 1.3704 - val_mae: 0.9002 - val_mse: 1.3704\n",
      "Epoch 734/1000\n",
      "8890/8890 [==============================] - 0s 39us/sample - loss: 1.3022 - mae: 0.8715 - mse: 1.3022 - val_loss: 1.3646 - val_mae: 0.8943 - val_mse: 1.3646\n",
      "Epoch 735/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3032 - mae: 0.8725 - mse: 1.3032 - val_loss: 1.3669 - val_mae: 0.8811 - val_mse: 1.3669\n",
      "Epoch 736/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3026 - mae: 0.8719 - mse: 1.3026 - val_loss: 1.3737 - val_mae: 0.8842 - val_mse: 1.3737\n",
      "Epoch 737/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3035 - mae: 0.8719 - mse: 1.3035 - val_loss: 1.3660 - val_mae: 0.8964 - val_mse: 1.3660\n",
      "Epoch 738/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3047 - mae: 0.8730 - mse: 1.3047 - val_loss: 1.3787 - val_mae: 0.9103 - val_mse: 1.3787\n",
      "Epoch 739/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3021 - mae: 0.8731 - mse: 1.3021 - val_loss: 1.3655 - val_mae: 0.8932 - val_mse: 1.3655\n",
      "Epoch 740/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3047 - mae: 0.8733 - mse: 1.3047 - val_loss: 1.3781 - val_mae: 0.9096 - val_mse: 1.3781\n",
      "Epoch 741/1000\n",
      "8890/8890 [==============================] - 0s 42us/sample - loss: 1.3054 - mae: 0.8736 - mse: 1.3054 - val_loss: 1.3673 - val_mae: 0.8856 - val_mse: 1.3673\n",
      "Epoch 742/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3034 - mae: 0.8726 - mse: 1.3034 - val_loss: 1.3686 - val_mae: 0.9021 - val_mse: 1.3686\n",
      "Epoch 743/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3049 - mae: 0.8737 - mse: 1.3049 - val_loss: 1.3624 - val_mae: 0.8815 - val_mse: 1.3624\n",
      "Epoch 744/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3012 - mae: 0.8711 - mse: 1.3012 - val_loss: 1.3695 - val_mae: 0.8861 - val_mse: 1.3695\n",
      "Epoch 745/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3033 - mae: 0.8725 - mse: 1.3033 - val_loss: 1.3690 - val_mae: 0.8962 - val_mse: 1.3690\n",
      "Epoch 746/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3059 - mae: 0.8736 - mse: 1.3059 - val_loss: 1.3658 - val_mae: 0.8956 - val_mse: 1.3658\n",
      "Epoch 747/1000\n",
      "8890/8890 [==============================] - 0s 41us/sample - loss: 1.3036 - mae: 0.8732 - mse: 1.3036 - val_loss: 1.3787 - val_mae: 0.9055 - val_mse: 1.3787\n",
      "Epoch 748/1000\n",
      "8890/8890 [==============================] - 0s 39us/sample - loss: 1.3046 - mae: 0.8737 - mse: 1.3046 - val_loss: 1.3676 - val_mae: 0.8966 - val_mse: 1.3676\n",
      "Epoch 749/1000\n",
      "8890/8890 [==============================] - 0s 42us/sample - loss: 1.3049 - mae: 0.8729 - mse: 1.3049 - val_loss: 1.3675 - val_mae: 0.8930 - val_mse: 1.3675\n",
      "Epoch 750/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3034 - mae: 0.8724 - mse: 1.3034 - val_loss: 1.3667 - val_mae: 0.8884 - val_mse: 1.3667\n",
      "Epoch 751/1000\n",
      "8890/8890 [==============================] - 1s 58us/sample - loss: 1.3028 - mae: 0.8727 - mse: 1.3028 - val_loss: 1.3656 - val_mae: 0.8880 - val_mse: 1.3656\n",
      "Epoch 752/1000\n",
      "8890/8890 [==============================] - 0s 48us/sample - loss: 1.3039 - mae: 0.8735 - mse: 1.3039 - val_loss: 1.3640 - val_mae: 0.8822 - val_mse: 1.3640\n",
      "Epoch 753/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3037 - mae: 0.8727 - mse: 1.3037 - val_loss: 1.3708 - val_mae: 0.8789 - val_mse: 1.3708\n",
      "Epoch 754/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8890/8890 [==============================] - 0s 33us/sample - loss: 1.3034 - mae: 0.8731 - mse: 1.3034 - val_loss: 1.3641 - val_mae: 0.8894 - val_mse: 1.3641\n",
      "Epoch 755/1000\n",
      "8890/8890 [==============================] - 0s 33us/sample - loss: 1.3023 - mae: 0.8725 - mse: 1.3023 - val_loss: 1.3815 - val_mae: 0.8792 - val_mse: 1.3815\n",
      "Epoch 756/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3030 - mae: 0.8728 - mse: 1.3030 - val_loss: 1.3674 - val_mae: 0.8884 - val_mse: 1.3674\n",
      "Epoch 757/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3029 - mae: 0.8730 - mse: 1.3029 - val_loss: 1.3654 - val_mae: 0.8966 - val_mse: 1.3654\n",
      "Epoch 758/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3023 - mae: 0.8746 - mse: 1.3023 - val_loss: 1.3659 - val_mae: 0.8826 - val_mse: 1.3659\n",
      "Epoch 759/1000\n",
      "8890/8890 [==============================] - 0s 41us/sample - loss: 1.3039 - mae: 0.8730 - mse: 1.3039 - val_loss: 1.3866 - val_mae: 0.9151 - val_mse: 1.3866\n",
      "Epoch 760/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3031 - mae: 0.8740 - mse: 1.3031 - val_loss: 1.3646 - val_mae: 0.8873 - val_mse: 1.3646\n",
      "Epoch 761/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3024 - mae: 0.8727 - mse: 1.3024 - val_loss: 1.3702 - val_mae: 0.8809 - val_mse: 1.3702\n",
      "Epoch 762/1000\n",
      "8890/8890 [==============================] - 0s 39us/sample - loss: 1.3033 - mae: 0.8730 - mse: 1.3033 - val_loss: 1.3653 - val_mae: 0.8877 - val_mse: 1.3653\n",
      "Epoch 763/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3023 - mae: 0.8725 - mse: 1.3023 - val_loss: 1.3668 - val_mae: 0.8850 - val_mse: 1.3668\n",
      "Epoch 764/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3044 - mae: 0.8732 - mse: 1.3044 - val_loss: 1.3658 - val_mae: 0.8846 - val_mse: 1.3658\n",
      "Epoch 765/1000\n",
      "8890/8890 [==============================] - 0s 41us/sample - loss: 1.3031 - mae: 0.8714 - mse: 1.3031 - val_loss: 1.4067 - val_mae: 0.9294 - val_mse: 1.4067\n",
      "Epoch 766/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3062 - mae: 0.8747 - mse: 1.3062 - val_loss: 1.3712 - val_mae: 0.8989 - val_mse: 1.3712\n",
      "Epoch 767/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3033 - mae: 0.8727 - mse: 1.3033 - val_loss: 1.3747 - val_mae: 0.8781 - val_mse: 1.3747\n",
      "Epoch 768/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3037 - mae: 0.8722 - mse: 1.3037 - val_loss: 1.3624 - val_mae: 0.8833 - val_mse: 1.3624\n",
      "Epoch 769/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3028 - mae: 0.8728 - mse: 1.3028 - val_loss: 1.3719 - val_mae: 0.8973 - val_mse: 1.3719\n",
      "Epoch 770/1000\n",
      "8890/8890 [==============================] - 0s 41us/sample - loss: 1.3036 - mae: 0.8725 - mse: 1.3036 - val_loss: 1.3625 - val_mae: 0.8912 - val_mse: 1.3625\n",
      "Epoch 771/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3019 - mae: 0.8733 - mse: 1.3019 - val_loss: 1.3785 - val_mae: 0.8779 - val_mse: 1.3785\n",
      "Epoch 772/1000\n",
      "8890/8890 [==============================] - 0s 31us/sample - loss: 1.3053 - mae: 0.8724 - mse: 1.3053 - val_loss: 1.3743 - val_mae: 0.8822 - val_mse: 1.3743\n",
      "Epoch 773/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3023 - mae: 0.8721 - mse: 1.3023 - val_loss: 1.3755 - val_mae: 0.8799 - val_mse: 1.3755\n",
      "Epoch 774/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3028 - mae: 0.8719 - mse: 1.3028 - val_loss: 1.3685 - val_mae: 0.8952 - val_mse: 1.3685\n",
      "Epoch 775/1000\n",
      "8890/8890 [==============================] - 1s 77us/sample - loss: 1.3042 - mae: 0.8732 - mse: 1.3042 - val_loss: 1.3762 - val_mae: 0.8809 - val_mse: 1.3762\n",
      "Epoch 776/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3035 - mae: 0.8720 - mse: 1.3035 - val_loss: 1.3749 - val_mae: 0.9038 - val_mse: 1.3749\n",
      "Epoch 777/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3024 - mae: 0.8717 - mse: 1.3024 - val_loss: 1.3793 - val_mae: 0.9116 - val_mse: 1.3793\n",
      "Epoch 778/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3035 - mae: 0.8749 - mse: 1.3035 - val_loss: 1.3728 - val_mae: 0.8940 - val_mse: 1.3728\n",
      "Epoch 779/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3033 - mae: 0.8720 - mse: 1.3033 - val_loss: 1.3669 - val_mae: 0.8983 - val_mse: 1.3669\n",
      "Epoch 780/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3022 - mae: 0.8731 - mse: 1.3022 - val_loss: 1.3708 - val_mae: 0.8781 - val_mse: 1.3708\n",
      "Epoch 781/1000\n",
      "8890/8890 [==============================] - 0s 41us/sample - loss: 1.3039 - mae: 0.8728 - mse: 1.3039 - val_loss: 1.3653 - val_mae: 0.8807 - val_mse: 1.3653\n",
      "Epoch 782/1000\n",
      "8890/8890 [==============================] - 0s 43us/sample - loss: 1.3040 - mae: 0.8726 - mse: 1.3040 - val_loss: 1.3618 - val_mae: 0.8849 - val_mse: 1.3618\n",
      "Epoch 783/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3039 - mae: 0.8726 - mse: 1.3039 - val_loss: 1.3649 - val_mae: 0.8938 - val_mse: 1.3649\n",
      "Epoch 784/1000\n",
      "8890/8890 [==============================] - 0s 43us/sample - loss: 1.3037 - mae: 0.8734 - mse: 1.3037 - val_loss: 1.3659 - val_mae: 0.8818 - val_mse: 1.3659\n",
      "Epoch 785/1000\n",
      "8890/8890 [==============================] - 0s 39us/sample - loss: 1.3033 - mae: 0.8716 - mse: 1.3033 - val_loss: 1.3789 - val_mae: 0.9100 - val_mse: 1.3789\n",
      "Epoch 786/1000\n",
      "8890/8890 [==============================] - 0s 39us/sample - loss: 1.3035 - mae: 0.8733 - mse: 1.3035 - val_loss: 1.3638 - val_mae: 0.8859 - val_mse: 1.3638\n",
      "Epoch 787/1000\n",
      "8890/8890 [==============================] - 0s 43us/sample - loss: 1.3031 - mae: 0.8723 - mse: 1.3031 - val_loss: 1.3684 - val_mae: 0.8982 - val_mse: 1.3684\n",
      "Epoch 788/1000\n",
      "8890/8890 [==============================] - 0s 41us/sample - loss: 1.3033 - mae: 0.8730 - mse: 1.3033 - val_loss: 1.3680 - val_mae: 0.8906 - val_mse: 1.3680\n",
      "Epoch 789/1000\n",
      "8890/8890 [==============================] - 0s 39us/sample - loss: 1.3028 - mae: 0.8727 - mse: 1.3028 - val_loss: 1.3715 - val_mae: 0.8870 - val_mse: 1.3715\n",
      "Epoch 790/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3021 - mae: 0.8720 - mse: 1.3021 - val_loss: 1.3671 - val_mae: 0.8886 - val_mse: 1.3671\n",
      "Epoch 791/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3020 - mae: 0.8705 - mse: 1.3020 - val_loss: 1.3672 - val_mae: 0.8973 - val_mse: 1.3672\n",
      "Epoch 792/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3034 - mae: 0.8729 - mse: 1.3034 - val_loss: 1.3648 - val_mae: 0.8829 - val_mse: 1.3648\n",
      "Epoch 793/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3048 - mae: 0.8727 - mse: 1.3048 - val_loss: 1.3712 - val_mae: 0.8828 - val_mse: 1.3712\n",
      "Epoch 794/1000\n",
      "8890/8890 [==============================] - 0s 41us/sample - loss: 1.3038 - mae: 0.8724 - mse: 1.3038 - val_loss: 1.3671 - val_mae: 0.8906 - val_mse: 1.3671\n",
      "Epoch 795/1000\n",
      "8890/8890 [==============================] - 0s 42us/sample - loss: 1.3035 - mae: 0.8721 - mse: 1.3035 - val_loss: 1.3695 - val_mae: 0.8881 - val_mse: 1.3695\n",
      "Epoch 796/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3010 - mae: 0.8710 - mse: 1.3010 - val_loss: 1.3613 - val_mae: 0.8891 - val_mse: 1.3613\n",
      "Epoch 797/1000\n",
      "8890/8890 [==============================] - 0s 55us/sample - loss: 1.3044 - mae: 0.8733 - mse: 1.3044 - val_loss: 1.3700 - val_mae: 0.8945 - val_mse: 1.3700\n",
      "Epoch 798/1000\n",
      "8890/8890 [==============================] - 0s 56us/sample - loss: 1.3026 - mae: 0.8724 - mse: 1.3026 - val_loss: 1.3678 - val_mae: 0.8925 - val_mse: 1.3678\n",
      "Epoch 799/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3022 - mae: 0.8714 - mse: 1.3022 - val_loss: 1.3764 - val_mae: 0.9076 - val_mse: 1.3764\n",
      "Epoch 800/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3035 - mae: 0.8733 - mse: 1.3035 - val_loss: 1.3791 - val_mae: 0.8869 - val_mse: 1.3791\n",
      "Epoch 801/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3035 - mae: 0.8732 - mse: 1.3035 - val_loss: 1.3726 - val_mae: 0.8949 - val_mse: 1.3726\n",
      "Epoch 802/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3030 - mae: 0.8720 - mse: 1.3030 - val_loss: 1.3761 - val_mae: 0.9045 - val_mse: 1.3761\n",
      "Epoch 803/1000\n",
      "8890/8890 [==============================] - 0s 33us/sample - loss: 1.3016 - mae: 0.8722 - mse: 1.3016 - val_loss: 1.3763 - val_mae: 0.9058 - val_mse: 1.3763\n",
      "Epoch 804/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3033 - mae: 0.8729 - mse: 1.3033 - val_loss: 1.3707 - val_mae: 0.9014 - val_mse: 1.3707\n",
      "Epoch 805/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3018 - mae: 0.8722 - mse: 1.3018 - val_loss: 1.3663 - val_mae: 0.8900 - val_mse: 1.3663\n",
      "Epoch 806/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3027 - mae: 0.8729 - mse: 1.3027 - val_loss: 1.3681 - val_mae: 0.8907 - val_mse: 1.3681\n",
      "Epoch 807/1000\n",
      "8890/8890 [==============================] - 0s 39us/sample - loss: 1.3030 - mae: 0.8734 - mse: 1.3030 - val_loss: 1.3709 - val_mae: 0.8877 - val_mse: 1.3709\n",
      "Epoch 808/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3020 - mae: 0.8724 - mse: 1.3020 - val_loss: 1.3684 - val_mae: 0.8809 - val_mse: 1.3684\n",
      "Epoch 809/1000\n",
      "8890/8890 [==============================] - 0s 31us/sample - loss: 1.3023 - mae: 0.8723 - mse: 1.3023 - val_loss: 1.3694 - val_mae: 0.8808 - val_mse: 1.3694\n",
      "Epoch 810/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3026 - mae: 0.8710 - mse: 1.3026 - val_loss: 1.3765 - val_mae: 0.9034 - val_mse: 1.3765\n",
      "Epoch 811/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3043 - mae: 0.8722 - mse: 1.3043 - val_loss: 1.3681 - val_mae: 0.8966 - val_mse: 1.3681\n",
      "Epoch 812/1000\n",
      "8890/8890 [==============================] - 0s 30us/sample - loss: 1.3024 - mae: 0.8725 - mse: 1.3024 - val_loss: 1.3742 - val_mae: 0.8815 - val_mse: 1.3742\n",
      "Epoch 813/1000\n",
      "8890/8890 [==============================] - 0s 32us/sample - loss: 1.3030 - mae: 0.8722 - mse: 1.3030 - val_loss: 1.3659 - val_mae: 0.8844 - val_mse: 1.3659\n",
      "Epoch 814/1000\n",
      "8890/8890 [==============================] - 0s 33us/sample - loss: 1.3034 - mae: 0.8722 - mse: 1.3034 - val_loss: 1.3710 - val_mae: 0.8967 - val_mse: 1.3710\n",
      "Epoch 815/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3034 - mae: 0.8720 - mse: 1.3034 - val_loss: 1.3716 - val_mae: 0.9011 - val_mse: 1.3716\n",
      "Epoch 816/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3031 - mae: 0.8734 - mse: 1.3031 - val_loss: 1.3693 - val_mae: 0.8921 - val_mse: 1.3693\n",
      "Epoch 817/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3028 - mae: 0.8727 - mse: 1.3028 - val_loss: 1.3716 - val_mae: 0.9022 - val_mse: 1.3716\n",
      "Epoch 818/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3030 - mae: 0.8729 - mse: 1.3030 - val_loss: 1.3696 - val_mae: 0.8837 - val_mse: 1.3696\n",
      "Epoch 819/1000\n",
      "8890/8890 [==============================] - 0s 39us/sample - loss: 1.3018 - mae: 0.8718 - mse: 1.3018 - val_loss: 1.3693 - val_mae: 0.8983 - val_mse: 1.3693\n",
      "Epoch 820/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3033 - mae: 0.8736 - mse: 1.3033 - val_loss: 1.3693 - val_mae: 0.8819 - val_mse: 1.3693\n",
      "Epoch 821/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3027 - mae: 0.8723 - mse: 1.3027 - val_loss: 1.3678 - val_mae: 0.8933 - val_mse: 1.3678\n",
      "Epoch 822/1000\n",
      "8890/8890 [==============================] - 0s 41us/sample - loss: 1.3030 - mae: 0.8730 - mse: 1.3030 - val_loss: 1.3736 - val_mae: 0.8821 - val_mse: 1.3736\n",
      "Epoch 823/1000\n",
      "8890/8890 [==============================] - 0s 46us/sample - loss: 1.3034 - mae: 0.8722 - mse: 1.3034 - val_loss: 1.3633 - val_mae: 0.8838 - val_mse: 1.3633\n",
      "Epoch 824/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3045 - mae: 0.8737 - mse: 1.3045 - val_loss: 1.3700 - val_mae: 0.8817 - val_mse: 1.3700\n",
      "Epoch 825/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3026 - mae: 0.8725 - mse: 1.3026 - val_loss: 1.3670 - val_mae: 0.8972 - val_mse: 1.3670\n",
      "Epoch 826/1000\n",
      "8890/8890 [==============================] - 0s 41us/sample - loss: 1.3042 - mae: 0.8731 - mse: 1.3042 - val_loss: 1.3648 - val_mae: 0.8868 - val_mse: 1.3648\n",
      "Epoch 827/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3020 - mae: 0.8723 - mse: 1.3020 - val_loss: 1.3671 - val_mae: 0.8897 - val_mse: 1.3671\n",
      "Epoch 828/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3025 - mae: 0.8734 - mse: 1.3025 - val_loss: 1.3708 - val_mae: 0.8812 - val_mse: 1.3708\n",
      "Epoch 829/1000\n",
      "8890/8890 [==============================] - 0s 33us/sample - loss: 1.3013 - mae: 0.8704 - mse: 1.3013 - val_loss: 1.3652 - val_mae: 0.8917 - val_mse: 1.3652\n",
      "Epoch 830/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3037 - mae: 0.8726 - mse: 1.3037 - val_loss: 1.3798 - val_mae: 0.9113 - val_mse: 1.3798\n",
      "Epoch 831/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3030 - mae: 0.8729 - mse: 1.3030 - val_loss: 1.3667 - val_mae: 0.8967 - val_mse: 1.3667\n",
      "Epoch 832/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3021 - mae: 0.8725 - mse: 1.3021 - val_loss: 1.3696 - val_mae: 0.8815 - val_mse: 1.3696\n",
      "Epoch 833/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3028 - mae: 0.8727 - mse: 1.3028 - val_loss: 1.3652 - val_mae: 0.8902 - val_mse: 1.3652\n",
      "Epoch 834/1000\n",
      "8890/8890 [==============================] - 0s 32us/sample - loss: 1.3026 - mae: 0.8726 - mse: 1.3026 - val_loss: 1.3703 - val_mae: 0.8968 - val_mse: 1.3703\n",
      "Epoch 835/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3042 - mae: 0.8729 - mse: 1.3042 - val_loss: 1.3691 - val_mae: 0.8994 - val_mse: 1.3691\n",
      "Epoch 836/1000\n",
      "8890/8890 [==============================] - 0s 33us/sample - loss: 1.3042 - mae: 0.8730 - mse: 1.3042 - val_loss: 1.3761 - val_mae: 0.9086 - val_mse: 1.3761\n",
      "Epoch 837/1000\n",
      "8890/8890 [==============================] - 0s 33us/sample - loss: 1.3033 - mae: 0.8727 - mse: 1.3033 - val_loss: 1.3945 - val_mae: 0.9211 - val_mse: 1.3945\n",
      "Epoch 838/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3027 - mae: 0.8726 - mse: 1.3027 - val_loss: 1.3666 - val_mae: 0.8907 - val_mse: 1.3666\n",
      "Epoch 839/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3032 - mae: 0.8725 - mse: 1.3032 - val_loss: 1.3677 - val_mae: 0.8929 - val_mse: 1.3677\n",
      "Epoch 840/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3041 - mae: 0.8725 - mse: 1.3041 - val_loss: 1.3693 - val_mae: 0.8830 - val_mse: 1.3693\n",
      "Epoch 841/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3011 - mae: 0.8719 - mse: 1.3011 - val_loss: 1.3774 - val_mae: 0.9058 - val_mse: 1.3774\n",
      "Epoch 842/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3033 - mae: 0.8727 - mse: 1.3033 - val_loss: 1.3649 - val_mae: 0.8932 - val_mse: 1.3649\n",
      "Epoch 843/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3031 - mae: 0.8723 - mse: 1.3031 - val_loss: 1.3786 - val_mae: 0.9069 - val_mse: 1.3786\n",
      "Epoch 844/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3050 - mae: 0.8741 - mse: 1.3050 - val_loss: 1.3661 - val_mae: 0.8872 - val_mse: 1.3661\n",
      "Epoch 845/1000\n",
      "8890/8890 [==============================] - 0s 55us/sample - loss: 1.3035 - mae: 0.8725 - mse: 1.3035 - val_loss: 1.3703 - val_mae: 0.8985 - val_mse: 1.3703\n",
      "Epoch 846/1000\n",
      "8890/8890 [==============================] - 0s 46us/sample - loss: 1.3020 - mae: 0.8730 - mse: 1.3020 - val_loss: 1.3689 - val_mae: 0.8931 - val_mse: 1.3689\n",
      "Epoch 847/1000\n",
      "8890/8890 [==============================] - 0s 46us/sample - loss: 1.3028 - mae: 0.8722 - mse: 1.3028 - val_loss: 1.3641 - val_mae: 0.8886 - val_mse: 1.3641\n",
      "Epoch 848/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8890/8890 [==============================] - 0s 43us/sample - loss: 1.3036 - mae: 0.8724 - mse: 1.3036 - val_loss: 1.3715 - val_mae: 0.9009 - val_mse: 1.3715\n",
      "Epoch 849/1000\n",
      "8890/8890 [==============================] - 0s 29us/sample - loss: 1.3036 - mae: 0.8721 - mse: 1.3036 - val_loss: 1.3711 - val_mae: 0.9029 - val_mse: 1.3711\n",
      "Epoch 850/1000\n",
      "8890/8890 [==============================] - 0s 33us/sample - loss: 1.3027 - mae: 0.8729 - mse: 1.3027 - val_loss: 1.3670 - val_mae: 0.8850 - val_mse: 1.3670\n",
      "Epoch 851/1000\n",
      "8890/8890 [==============================] - 0s 45us/sample - loss: 1.3049 - mae: 0.8728 - mse: 1.3049 - val_loss: 1.3702 - val_mae: 0.8992 - val_mse: 1.3702\n",
      "Epoch 852/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3040 - mae: 0.8720 - mse: 1.3040 - val_loss: 1.3697 - val_mae: 0.8830 - val_mse: 1.3697\n",
      "Epoch 853/1000\n",
      "8890/8890 [==============================] - 0s 39us/sample - loss: 1.3043 - mae: 0.8722 - mse: 1.3043 - val_loss: 1.3685 - val_mae: 0.8851 - val_mse: 1.3685\n",
      "Epoch 854/1000\n",
      "8890/8890 [==============================] - 0s 39us/sample - loss: 1.3025 - mae: 0.8732 - mse: 1.3025 - val_loss: 1.3688 - val_mae: 0.8926 - val_mse: 1.3688\n",
      "Epoch 855/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3047 - mae: 0.8730 - mse: 1.3047 - val_loss: 1.3712 - val_mae: 0.9019 - val_mse: 1.3712\n",
      "Epoch 856/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3010 - mae: 0.8712 - mse: 1.3010 - val_loss: 1.4008 - val_mae: 0.9245 - val_mse: 1.4008\n",
      "Epoch 857/1000\n",
      "8890/8890 [==============================] - 0s 51us/sample - loss: 1.3030 - mae: 0.8732 - mse: 1.3030 - val_loss: 1.3704 - val_mae: 0.8978 - val_mse: 1.3704\n",
      "Epoch 858/1000\n",
      "8890/8890 [==============================] - 0s 33us/sample - loss: 1.3038 - mae: 0.8732 - mse: 1.3038 - val_loss: 1.3815 - val_mae: 0.9107 - val_mse: 1.3815\n",
      "Epoch 859/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3038 - mae: 0.8731 - mse: 1.3038 - val_loss: 1.3688 - val_mae: 0.8970 - val_mse: 1.3688\n",
      "Epoch 860/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3045 - mae: 0.8725 - mse: 1.3045 - val_loss: 1.3688 - val_mae: 0.8954 - val_mse: 1.3688\n",
      "Epoch 861/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3037 - mae: 0.8730 - mse: 1.3037 - val_loss: 1.3687 - val_mae: 0.8811 - val_mse: 1.3687\n",
      "Epoch 862/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3030 - mae: 0.8727 - mse: 1.3030 - val_loss: 1.3714 - val_mae: 0.8960 - val_mse: 1.3714\n",
      "Epoch 863/1000\n",
      "8890/8890 [==============================] - 0s 31us/sample - loss: 1.3021 - mae: 0.8722 - mse: 1.3021 - val_loss: 1.3655 - val_mae: 0.8909 - val_mse: 1.3655\n",
      "Epoch 864/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3043 - mae: 0.8735 - mse: 1.3043 - val_loss: 1.3669 - val_mae: 0.8868 - val_mse: 1.3669\n",
      "Epoch 865/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3029 - mae: 0.8730 - mse: 1.3029 - val_loss: 1.3676 - val_mae: 0.8901 - val_mse: 1.3676\n",
      "Epoch 866/1000\n",
      "8890/8890 [==============================] - 0s 43us/sample - loss: 1.3033 - mae: 0.8730 - mse: 1.3033 - val_loss: 1.3752 - val_mae: 0.9050 - val_mse: 1.3752\n",
      "Epoch 867/1000\n",
      "8890/8890 [==============================] - 0s 41us/sample - loss: 1.3031 - mae: 0.8733 - mse: 1.3031 - val_loss: 1.3699 - val_mae: 0.8879 - val_mse: 1.3699\n",
      "Epoch 868/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3034 - mae: 0.8734 - mse: 1.3034 - val_loss: 1.3697 - val_mae: 0.8835 - val_mse: 1.3697\n",
      "Epoch 869/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3034 - mae: 0.8723 - mse: 1.3034 - val_loss: 1.3741 - val_mae: 0.9032 - val_mse: 1.3741\n",
      "Epoch 870/1000\n",
      "8890/8890 [==============================] - 0s 31us/sample - loss: 1.3027 - mae: 0.8733 - mse: 1.3027 - val_loss: 1.3746 - val_mae: 0.8818 - val_mse: 1.3746\n",
      "Epoch 871/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3030 - mae: 0.8713 - mse: 1.3030 - val_loss: 1.3756 - val_mae: 0.9051 - val_mse: 1.3756\n",
      "Epoch 872/1000\n",
      "8890/8890 [==============================] - 0s 32us/sample - loss: 1.3030 - mae: 0.8735 - mse: 1.3030 - val_loss: 1.3705 - val_mae: 0.8867 - val_mse: 1.3705\n",
      "Epoch 873/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3029 - mae: 0.8712 - mse: 1.3029 - val_loss: 1.3705 - val_mae: 0.8915 - val_mse: 1.3705\n",
      "Epoch 874/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3042 - mae: 0.8728 - mse: 1.3042 - val_loss: 1.3687 - val_mae: 0.8851 - val_mse: 1.3687\n",
      "Epoch 875/1000\n",
      "8890/8890 [==============================] - 0s 39us/sample - loss: 1.3033 - mae: 0.8722 - mse: 1.3033 - val_loss: 1.3692 - val_mae: 0.8924 - val_mse: 1.3692\n",
      "Epoch 876/1000\n",
      "8890/8890 [==============================] - 0s 42us/sample - loss: 1.3046 - mae: 0.8728 - mse: 1.3046 - val_loss: 1.3658 - val_mae: 0.8902 - val_mse: 1.3658\n",
      "Epoch 877/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3037 - mae: 0.8728 - mse: 1.3037 - val_loss: 1.3722 - val_mae: 0.8962 - val_mse: 1.3722\n",
      "Epoch 878/1000\n",
      "8890/8890 [==============================] - ETA: 0s - loss: 1.3081 - mae: 0.8738 - mse: 1.308 - 0s 35us/sample - loss: 1.3019 - mae: 0.8721 - mse: 1.3019 - val_loss: 1.3803 - val_mae: 0.9077 - val_mse: 1.3803\n",
      "Epoch 879/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3040 - mae: 0.8730 - mse: 1.3040 - val_loss: 1.3667 - val_mae: 0.8891 - val_mse: 1.3667\n",
      "Epoch 880/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3040 - mae: 0.8721 - mse: 1.3040 - val_loss: 1.3647 - val_mae: 0.8896 - val_mse: 1.3647\n",
      "Epoch 881/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3043 - mae: 0.8722 - mse: 1.3043 - val_loss: 1.3722 - val_mae: 0.9026 - val_mse: 1.3722\n",
      "Epoch 882/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3039 - mae: 0.8723 - mse: 1.3039 - val_loss: 1.3653 - val_mae: 0.8932 - val_mse: 1.3653\n",
      "Epoch 883/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3042 - mae: 0.8722 - mse: 1.3042 - val_loss: 1.3672 - val_mae: 0.8892 - val_mse: 1.3672\n",
      "Epoch 884/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3025 - mae: 0.8718 - mse: 1.3025 - val_loss: 1.3666 - val_mae: 0.8897 - val_mse: 1.3666\n",
      "Epoch 885/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3036 - mae: 0.8728 - mse: 1.3036 - val_loss: 1.3661 - val_mae: 0.8963 - val_mse: 1.3661\n",
      "Epoch 886/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3034 - mae: 0.8719 - mse: 1.3034 - val_loss: 1.3728 - val_mae: 0.9033 - val_mse: 1.3728\n",
      "Epoch 887/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3022 - mae: 0.8717 - mse: 1.3022 - val_loss: 1.3890 - val_mae: 0.9174 - val_mse: 1.3890\n",
      "Epoch 888/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3042 - mae: 0.8739 - mse: 1.3042 - val_loss: 1.3669 - val_mae: 0.8865 - val_mse: 1.3669\n",
      "Epoch 889/1000\n",
      "8890/8890 [==============================] - 0s 41us/sample - loss: 1.3027 - mae: 0.8721 - mse: 1.3027 - val_loss: 1.3661 - val_mae: 0.8947 - val_mse: 1.3661\n",
      "Epoch 890/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3027 - mae: 0.8727 - mse: 1.3027 - val_loss: 1.3694 - val_mae: 0.8958 - val_mse: 1.3694\n",
      "Epoch 891/1000\n",
      "8890/8890 [==============================] - 0s 33us/sample - loss: 1.3026 - mae: 0.8726 - mse: 1.3026 - val_loss: 1.3674 - val_mae: 0.8966 - val_mse: 1.3674\n",
      "Epoch 892/1000\n",
      "8890/8890 [==============================] - 0s 47us/sample - loss: 1.3028 - mae: 0.8728 - mse: 1.3028 - val_loss: 1.3701 - val_mae: 0.8983 - val_mse: 1.3701\n",
      "Epoch 893/1000\n",
      "8890/8890 [==============================] - 0s 49us/sample - loss: 1.3013 - mae: 0.8723 - mse: 1.3013 - val_loss: 1.3820 - val_mae: 0.8812 - val_mse: 1.3820\n",
      "Epoch 894/1000\n",
      "8890/8890 [==============================] - 0s 50us/sample - loss: 1.3021 - mae: 0.8715 - mse: 1.3021 - val_loss: 1.3659 - val_mae: 0.8869 - val_mse: 1.3659\n",
      "Epoch 895/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8890/8890 [==============================] - 0s 49us/sample - loss: 1.3040 - mae: 0.8731 - mse: 1.3040 - val_loss: 1.3667 - val_mae: 0.8918 - val_mse: 1.3667\n",
      "Epoch 896/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3022 - mae: 0.8724 - mse: 1.3022 - val_loss: 1.3689 - val_mae: 0.8987 - val_mse: 1.3689\n",
      "Epoch 897/1000\n",
      "8890/8890 [==============================] - 0s 51us/sample - loss: 1.3018 - mae: 0.8722 - mse: 1.3018 - val_loss: 1.3700 - val_mae: 0.8854 - val_mse: 1.3700\n",
      "Epoch 898/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3040 - mae: 0.8721 - mse: 1.3040 - val_loss: 1.3651 - val_mae: 0.8881 - val_mse: 1.3651\n",
      "Epoch 899/1000\n",
      "8890/8890 [==============================] - 0s 33us/sample - loss: 1.3041 - mae: 0.8729 - mse: 1.3041 - val_loss: 1.3753 - val_mae: 0.9062 - val_mse: 1.3753\n",
      "Epoch 900/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3035 - mae: 0.8732 - mse: 1.3035 - val_loss: 1.3655 - val_mae: 0.8861 - val_mse: 1.3655\n",
      "Epoch 901/1000\n",
      "8890/8890 [==============================] - 0s 32us/sample - loss: 1.3019 - mae: 0.8721 - mse: 1.3019 - val_loss: 1.3699 - val_mae: 0.8841 - val_mse: 1.3699\n",
      "Epoch 902/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3041 - mae: 0.8719 - mse: 1.3041 - val_loss: 1.3729 - val_mae: 0.9041 - val_mse: 1.3729\n",
      "Epoch 903/1000\n",
      "8890/8890 [==============================] - 0s 33us/sample - loss: 1.3025 - mae: 0.8723 - mse: 1.3025 - val_loss: 1.3693 - val_mae: 0.8951 - val_mse: 1.3693\n",
      "Epoch 904/1000\n",
      "8890/8890 [==============================] - 0s 33us/sample - loss: 1.3043 - mae: 0.8728 - mse: 1.3043 - val_loss: 1.3683 - val_mae: 0.8958 - val_mse: 1.3683\n",
      "Epoch 905/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3017 - mae: 0.8721 - mse: 1.3017 - val_loss: 1.3655 - val_mae: 0.8903 - val_mse: 1.3655\n",
      "Epoch 906/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3022 - mae: 0.8729 - mse: 1.3022 - val_loss: 1.3683 - val_mae: 0.8841 - val_mse: 1.3683\n",
      "Epoch 907/1000\n",
      "8890/8890 [==============================] - 0s 33us/sample - loss: 1.3051 - mae: 0.8736 - mse: 1.3051 - val_loss: 1.3646 - val_mae: 0.8883 - val_mse: 1.3646\n",
      "Epoch 908/1000\n",
      "8890/8890 [==============================] - 0s 33us/sample - loss: 1.3039 - mae: 0.8724 - mse: 1.3039 - val_loss: 1.3717 - val_mae: 0.9007 - val_mse: 1.3717\n",
      "Epoch 909/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3023 - mae: 0.8730 - mse: 1.3023 - val_loss: 1.3696 - val_mae: 0.8842 - val_mse: 1.3696\n",
      "Epoch 910/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3040 - mae: 0.8726 - mse: 1.3040 - val_loss: 1.3674 - val_mae: 0.8935 - val_mse: 1.3674\n",
      "Epoch 911/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3035 - mae: 0.8724 - mse: 1.3035 - val_loss: 1.3678 - val_mae: 0.8882 - val_mse: 1.3678\n",
      "Epoch 912/1000\n",
      "8890/8890 [==============================] - 0s 39us/sample - loss: 1.3048 - mae: 0.8737 - mse: 1.3048 - val_loss: 1.3677 - val_mae: 0.8891 - val_mse: 1.3677\n",
      "Epoch 913/1000\n",
      "8890/8890 [==============================] - 0s 50us/sample - loss: 1.3015 - mae: 0.8723 - mse: 1.3015 - val_loss: 1.3696 - val_mae: 0.8821 - val_mse: 1.3696\n",
      "Epoch 914/1000\n",
      "8890/8890 [==============================] - 0s 39us/sample - loss: 1.3046 - mae: 0.8741 - mse: 1.3046 - val_loss: 1.3720 - val_mae: 0.8797 - val_mse: 1.3720\n",
      "Epoch 915/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3027 - mae: 0.8721 - mse: 1.3027 - val_loss: 1.3719 - val_mae: 0.9020 - val_mse: 1.3719\n",
      "Epoch 916/1000\n",
      "8890/8890 [==============================] - 0s 46us/sample - loss: 1.3038 - mae: 0.8736 - mse: 1.3038 - val_loss: 1.3643 - val_mae: 0.8862 - val_mse: 1.3643\n",
      "Epoch 917/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3025 - mae: 0.8731 - mse: 1.3025 - val_loss: 1.3650 - val_mae: 0.8824 - val_mse: 1.3650\n",
      "Epoch 918/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3033 - mae: 0.8719 - mse: 1.3033 - val_loss: 1.3695 - val_mae: 0.9002 - val_mse: 1.3695\n",
      "Epoch 919/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3028 - mae: 0.8722 - mse: 1.3028 - val_loss: 1.3807 - val_mae: 0.9108 - val_mse: 1.3807\n",
      "Epoch 920/1000\n",
      "8890/8890 [==============================] - 0s 32us/sample - loss: 1.3027 - mae: 0.8739 - mse: 1.3027 - val_loss: 1.3696 - val_mae: 0.8933 - val_mse: 1.3696\n",
      "Epoch 921/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3035 - mae: 0.8722 - mse: 1.3035 - val_loss: 1.3729 - val_mae: 0.9035 - val_mse: 1.3729\n",
      "Epoch 922/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3027 - mae: 0.8732 - mse: 1.3027 - val_loss: 1.3707 - val_mae: 0.8784 - val_mse: 1.3707\n",
      "Epoch 923/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3023 - mae: 0.8716 - mse: 1.3023 - val_loss: 1.3697 - val_mae: 0.8957 - val_mse: 1.3697\n",
      "Epoch 924/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3014 - mae: 0.8714 - mse: 1.3014 - val_loss: 1.3671 - val_mae: 0.8815 - val_mse: 1.3671\n",
      "Epoch 925/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3033 - mae: 0.8716 - mse: 1.3033 - val_loss: 1.3756 - val_mae: 0.9069 - val_mse: 1.3756\n",
      "Epoch 926/1000\n",
      "8890/8890 [==============================] - 0s 43us/sample - loss: 1.3040 - mae: 0.8727 - mse: 1.3040 - val_loss: 1.3729 - val_mae: 0.9031 - val_mse: 1.3729\n",
      "Epoch 927/1000\n",
      "8890/8890 [==============================] - 0s 41us/sample - loss: 1.3023 - mae: 0.8731 - mse: 1.3023 - val_loss: 1.3682 - val_mae: 0.8835 - val_mse: 1.3682\n",
      "Epoch 928/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3043 - mae: 0.8713 - mse: 1.3043 - val_loss: 1.3685 - val_mae: 0.8981 - val_mse: 1.3685\n",
      "Epoch 929/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3024 - mae: 0.8727 - mse: 1.3024 - val_loss: 1.3661 - val_mae: 0.8940 - val_mse: 1.3661\n",
      "Epoch 930/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3036 - mae: 0.8727 - mse: 1.3036 - val_loss: 1.3735 - val_mae: 0.9017 - val_mse: 1.3735\n",
      "Epoch 931/1000\n",
      "8890/8890 [==============================] - 0s 42us/sample - loss: 1.3025 - mae: 0.8723 - mse: 1.3025 - val_loss: 1.3713 - val_mae: 0.9020 - val_mse: 1.3713\n",
      "Epoch 932/1000\n",
      "8890/8890 [==============================] - 0s 39us/sample - loss: 1.3034 - mae: 0.8735 - mse: 1.3034 - val_loss: 1.3785 - val_mae: 0.9077 - val_mse: 1.3785\n",
      "Epoch 933/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3030 - mae: 0.8723 - mse: 1.3030 - val_loss: 1.3773 - val_mae: 0.9075 - val_mse: 1.3773\n",
      "Epoch 934/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3039 - mae: 0.8727 - mse: 1.3039 - val_loss: 1.3677 - val_mae: 0.8951 - val_mse: 1.3677\n",
      "Epoch 935/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3020 - mae: 0.8719 - mse: 1.3020 - val_loss: 1.3687 - val_mae: 0.8981 - val_mse: 1.3687\n",
      "Epoch 936/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3011 - mae: 0.8715 - mse: 1.3011 - val_loss: 1.3731 - val_mae: 0.8976 - val_mse: 1.3731\n",
      "Epoch 937/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3038 - mae: 0.8730 - mse: 1.3038 - val_loss: 1.3749 - val_mae: 0.8813 - val_mse: 1.3749\n",
      "Epoch 938/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3028 - mae: 0.8720 - mse: 1.3028 - val_loss: 1.3663 - val_mae: 0.8832 - val_mse: 1.3663\n",
      "Epoch 939/1000\n",
      "8890/8890 [==============================] - 0s 41us/sample - loss: 1.3032 - mae: 0.8729 - mse: 1.3032 - val_loss: 1.3673 - val_mae: 0.8856 - val_mse: 1.3673\n",
      "Epoch 940/1000\n",
      "8890/8890 [==============================] - 0s 42us/sample - loss: 1.3028 - mae: 0.8720 - mse: 1.3028 - val_loss: 1.3708 - val_mae: 0.8833 - val_mse: 1.3708\n",
      "Epoch 941/1000\n",
      "8890/8890 [==============================] - 0s 39us/sample - loss: 1.3031 - mae: 0.8721 - mse: 1.3031 - val_loss: 1.3657 - val_mae: 0.8829 - val_mse: 1.3657\n",
      "Epoch 942/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8890/8890 [==============================] - 0s 48us/sample - loss: 1.3024 - mae: 0.8731 - mse: 1.3024 - val_loss: 1.3746 - val_mae: 0.8797 - val_mse: 1.3746\n",
      "Epoch 943/1000\n",
      "8890/8890 [==============================] - 0s 48us/sample - loss: 1.2998 - mae: 0.8713 - mse: 1.2998 - val_loss: 1.3657 - val_mae: 0.8880 - val_mse: 1.3657\n",
      "Epoch 944/1000\n",
      "8890/8890 [==============================] - 0s 45us/sample - loss: 1.3038 - mae: 0.8736 - mse: 1.3038 - val_loss: 1.3640 - val_mae: 0.8871 - val_mse: 1.3640\n",
      "Epoch 945/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3034 - mae: 0.8723 - mse: 1.3034 - val_loss: 1.3659 - val_mae: 0.8908 - val_mse: 1.3659\n",
      "Epoch 946/1000\n",
      "8890/8890 [==============================] - 0s 43us/sample - loss: 1.3030 - mae: 0.8730 - mse: 1.3030 - val_loss: 1.3645 - val_mae: 0.8865 - val_mse: 1.3645\n",
      "Epoch 947/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3029 - mae: 0.8731 - mse: 1.3029 - val_loss: 1.3761 - val_mae: 0.9025 - val_mse: 1.3761\n",
      "Epoch 948/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3027 - mae: 0.8722 - mse: 1.3027 - val_loss: 1.3662 - val_mae: 0.8913 - val_mse: 1.3662\n",
      "Epoch 949/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3025 - mae: 0.8723 - mse: 1.3025 - val_loss: 1.3874 - val_mae: 0.9154 - val_mse: 1.3874\n",
      "Epoch 950/1000\n",
      "8890/8890 [==============================] - 0s 33us/sample - loss: 1.3024 - mae: 0.8726 - mse: 1.3024 - val_loss: 1.3675 - val_mae: 0.8965 - val_mse: 1.3675\n",
      "Epoch 951/1000\n",
      "8890/8890 [==============================] - 0s 41us/sample - loss: 1.3023 - mae: 0.8735 - mse: 1.3023 - val_loss: 1.3699 - val_mae: 0.8826 - val_mse: 1.3699\n",
      "Epoch 952/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3014 - mae: 0.8715 - mse: 1.3014 - val_loss: 1.3649 - val_mae: 0.8855 - val_mse: 1.3649\n",
      "Epoch 953/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3013 - mae: 0.8712 - mse: 1.3013 - val_loss: 1.3786 - val_mae: 0.9112 - val_mse: 1.3786\n",
      "Epoch 954/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3030 - mae: 0.8734 - mse: 1.3030 - val_loss: 1.3686 - val_mae: 0.8916 - val_mse: 1.3686\n",
      "Epoch 955/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3038 - mae: 0.8733 - mse: 1.3038 - val_loss: 1.3720 - val_mae: 0.8988 - val_mse: 1.3720\n",
      "Epoch 956/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3032 - mae: 0.8725 - mse: 1.3032 - val_loss: 1.3651 - val_mae: 0.8885 - val_mse: 1.3651\n",
      "Epoch 957/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3014 - mae: 0.8722 - mse: 1.3014 - val_loss: 1.3666 - val_mae: 0.8950 - val_mse: 1.3666\n",
      "Epoch 958/1000\n",
      "8890/8890 [==============================] - 0s 43us/sample - loss: 1.3015 - mae: 0.8719 - mse: 1.3015 - val_loss: 1.3705 - val_mae: 0.8915 - val_mse: 1.3705\n",
      "Epoch 959/1000\n",
      "8890/8890 [==============================] - 1s 73us/sample - loss: 1.3033 - mae: 0.8722 - mse: 1.3033 - val_loss: 1.3700 - val_mae: 0.8968 - val_mse: 1.3700\n",
      "Epoch 960/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3032 - mae: 0.8725 - mse: 1.3032 - val_loss: 1.3687 - val_mae: 0.8918 - val_mse: 1.3687\n",
      "Epoch 961/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3024 - mae: 0.8719 - mse: 1.3024 - val_loss: 1.3664 - val_mae: 0.8868 - val_mse: 1.3664\n",
      "Epoch 962/1000\n",
      "8890/8890 [==============================] - 0s 41us/sample - loss: 1.3042 - mae: 0.8728 - mse: 1.3042 - val_loss: 1.3666 - val_mae: 0.8809 - val_mse: 1.3666\n",
      "Epoch 963/1000\n",
      "8890/8890 [==============================] - 0s 42us/sample - loss: 1.3006 - mae: 0.8708 - mse: 1.3006 - val_loss: 1.3740 - val_mae: 0.8954 - val_mse: 1.3740\n",
      "Epoch 964/1000\n",
      "8890/8890 [==============================] - 0s 46us/sample - loss: 1.3025 - mae: 0.8732 - mse: 1.3025 - val_loss: 1.3707 - val_mae: 0.8813 - val_mse: 1.3707\n",
      "Epoch 965/1000\n",
      "8890/8890 [==============================] - 0s 51us/sample - loss: 1.3021 - mae: 0.8725 - mse: 1.3021 - val_loss: 1.3723 - val_mae: 0.8872 - val_mse: 1.3723\n",
      "Epoch 966/1000\n",
      "8890/8890 [==============================] - 0s 39us/sample - loss: 1.3013 - mae: 0.8720 - mse: 1.3013 - val_loss: 1.3715 - val_mae: 0.8818 - val_mse: 1.3715\n",
      "Epoch 967/1000\n",
      "8890/8890 [==============================] - 0s 39us/sample - loss: 1.3022 - mae: 0.8705 - mse: 1.3022 - val_loss: 1.3802 - val_mae: 0.9111 - val_mse: 1.3802\n",
      "Epoch 968/1000\n",
      "8890/8890 [==============================] - 0s 45us/sample - loss: 1.3040 - mae: 0.8736 - mse: 1.3040 - val_loss: 1.3658 - val_mae: 0.8896 - val_mse: 1.3658\n",
      "Epoch 969/1000\n",
      "8890/8890 [==============================] - 0s 43us/sample - loss: 1.3029 - mae: 0.8719 - mse: 1.3029 - val_loss: 1.3656 - val_mae: 0.8893 - val_mse: 1.3656\n",
      "Epoch 970/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3026 - mae: 0.8726 - mse: 1.3026 - val_loss: 1.3660 - val_mae: 0.8981 - val_mse: 1.3660\n",
      "Epoch 971/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3030 - mae: 0.8722 - mse: 1.3030 - val_loss: 1.3764 - val_mae: 0.9071 - val_mse: 1.3764\n",
      "Epoch 972/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3030 - mae: 0.8723 - mse: 1.3030 - val_loss: 1.3696 - val_mae: 0.8953 - val_mse: 1.3696\n",
      "Epoch 973/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3054 - mae: 0.8723 - mse: 1.3054 - val_loss: 1.3652 - val_mae: 0.8865 - val_mse: 1.3652\n",
      "Epoch 974/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3012 - mae: 0.8715 - mse: 1.3012 - val_loss: 1.3652 - val_mae: 0.8924 - val_mse: 1.3652\n",
      "Epoch 975/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3028 - mae: 0.8722 - mse: 1.3028 - val_loss: 1.3705 - val_mae: 0.8837 - val_mse: 1.3705\n",
      "Epoch 976/1000\n",
      "8890/8890 [==============================] - 0s 32us/sample - loss: 1.3017 - mae: 0.8714 - mse: 1.3017 - val_loss: 1.3677 - val_mae: 0.8942 - val_mse: 1.3677\n",
      "Epoch 977/1000\n",
      "8890/8890 [==============================] - 0s 33us/sample - loss: 1.3034 - mae: 0.8733 - mse: 1.3034 - val_loss: 1.3664 - val_mae: 0.8863 - val_mse: 1.3664\n",
      "Epoch 978/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3028 - mae: 0.8720 - mse: 1.3028 - val_loss: 1.3680 - val_mae: 0.8965 - val_mse: 1.3680\n",
      "Epoch 979/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3031 - mae: 0.8727 - mse: 1.3031 - val_loss: 1.3732 - val_mae: 0.8828 - val_mse: 1.3732\n",
      "Epoch 980/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3028 - mae: 0.8725 - mse: 1.3028 - val_loss: 1.3721 - val_mae: 0.8907 - val_mse: 1.3721\n",
      "Epoch 981/1000\n",
      "8890/8890 [==============================] - 0s 40us/sample - loss: 1.3030 - mae: 0.8718 - mse: 1.3030 - val_loss: 1.3753 - val_mae: 0.9035 - val_mse: 1.3753\n",
      "Epoch 982/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3015 - mae: 0.8726 - mse: 1.3015 - val_loss: 1.3755 - val_mae: 0.8795 - val_mse: 1.3755\n",
      "Epoch 983/1000\n",
      "8890/8890 [==============================] - 0s 29us/sample - loss: 1.3029 - mae: 0.8723 - mse: 1.3029 - val_loss: 1.3711 - val_mae: 0.9010 - val_mse: 1.3711\n",
      "Epoch 984/1000\n",
      "8890/8890 [==============================] - 0s 33us/sample - loss: 1.3024 - mae: 0.8731 - mse: 1.3024 - val_loss: 1.3689 - val_mae: 0.8909 - val_mse: 1.3689\n",
      "Epoch 985/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3014 - mae: 0.8715 - mse: 1.3014 - val_loss: 1.3649 - val_mae: 0.8927 - val_mse: 1.3649\n",
      "Epoch 986/1000\n",
      "8890/8890 [==============================] - 0s 34us/sample - loss: 1.3035 - mae: 0.8731 - mse: 1.3035 - val_loss: 1.3663 - val_mae: 0.8957 - val_mse: 1.3663\n",
      "Epoch 987/1000\n",
      "8890/8890 [==============================] - 1s 63us/sample - loss: 1.3027 - mae: 0.8720 - mse: 1.3027 - val_loss: 1.3811 - val_mae: 0.9112 - val_mse: 1.3811\n",
      "Epoch 988/1000\n",
      "8890/8890 [==============================] - 1s 58us/sample - loss: 1.3019 - mae: 0.8727 - mse: 1.3019 - val_loss: 1.3686 - val_mae: 0.8961 - val_mse: 1.3686\n",
      "Epoch 989/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8890/8890 [==============================] - 0s 39us/sample - loss: 1.3028 - mae: 0.8730 - mse: 1.3028 - val_loss: 1.3736 - val_mae: 0.8838 - val_mse: 1.3736\n",
      "Epoch 990/1000\n",
      "8890/8890 [==============================] - 0s 36us/sample - loss: 1.3010 - mae: 0.8710 - mse: 1.3010 - val_loss: 1.4042 - val_mae: 0.9274 - val_mse: 1.4042\n",
      "Epoch 991/1000\n",
      "8890/8890 [==============================] - 0s 42us/sample - loss: 1.3034 - mae: 0.8739 - mse: 1.3034 - val_loss: 1.3676 - val_mae: 0.8960 - val_mse: 1.3676\n",
      "Epoch 992/1000\n",
      "8890/8890 [==============================] - 0s 38us/sample - loss: 1.3027 - mae: 0.8731 - mse: 1.3027 - val_loss: 1.3715 - val_mae: 0.8915 - val_mse: 1.3715\n",
      "Epoch 993/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3017 - mae: 0.8727 - mse: 1.3017 - val_loss: 1.3682 - val_mae: 0.8988 - val_mse: 1.3682\n",
      "Epoch 994/1000\n",
      "8890/8890 [==============================] - 0s 35us/sample - loss: 1.3025 - mae: 0.8734 - mse: 1.3025 - val_loss: 1.3741 - val_mae: 0.8821 - val_mse: 1.3741\n",
      "Epoch 995/1000\n",
      "8890/8890 [==============================] - 0s 37us/sample - loss: 1.3035 - mae: 0.8723 - mse: 1.3035 - val_loss: 1.3698 - val_mae: 0.8835 - val_mse: 1.3698\n",
      "Epoch 996/1000\n",
      "8890/8890 [==============================] - 0s 39us/sample - loss: 1.3029 - mae: 0.8715 - mse: 1.3029 - val_loss: 1.3758 - val_mae: 0.9053 - val_mse: 1.3758\n",
      "Epoch 997/1000\n",
      "8890/8890 [==============================] - 0s 41us/sample - loss: 1.3030 - mae: 0.8716 - mse: 1.3030 - val_loss: 1.3676 - val_mae: 0.8940 - val_mse: 1.3676\n",
      "Epoch 998/1000\n",
      "8890/8890 [==============================] - 0s 39us/sample - loss: 1.3013 - mae: 0.8720 - mse: 1.3013 - val_loss: 1.3656 - val_mae: 0.8819 - val_mse: 1.3656\n",
      "Epoch 999/1000\n",
      "8890/8890 [==============================] - 0s 32us/sample - loss: 1.3010 - mae: 0.8709 - mse: 1.3010 - val_loss: 1.3658 - val_mae: 0.8819 - val_mse: 1.3658\n",
      "Epoch 1000/1000\n",
      "8890/8890 [==============================] - 0s 30us/sample - loss: 1.3040 - mae: 0.8721 - mse: 1.3040 - val_loss: 1.3664 - val_mae: 0.8905 - val_mse: 1.3664\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 1000\n",
    "history = ks.fit(X_train,\n",
    "                 y_train,\n",
    "                 epochs=EPOCHS,\n",
    "                 batch_size=128,\n",
    "                 validation_split = 0.2,\n",
    "                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(a,b):\n",
    "    #print('pred :',a,'actual :',b)\n",
    "    if a == b:\n",
    "        result = 1\n",
    "    else:\n",
    "        result = 0\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.04525503395754438\n",
      "dt 0.06490847567193248\n",
      "rf 0.08241761784397061\n",
      "vr 0.07381738626076562\n",
      "ks 0.87309194\n"
     ]
    }
   ],
   "source": [
    "print('lr',lr.score(X_train, y_train))\n",
    "print('dt',dt.score(X_train, y_train))\n",
    "print('rf',rf.score(X_train, y_train))\n",
    "print('vr',vr.score(X_train, y_train))\n",
    "ks_test = ks.evaluate(X_train, y_train,verbose=0)\n",
    "print('ks',ks_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_pred_results(result,num):\n",
    "    score = check(result,y_test.loc[num])\n",
    "    return score\n",
    "\n",
    "def predictionTest(num,model):\n",
    "    p = X_test.loc[num].tolist()\n",
    "    result = model.predict([p]).flatten().round()\n",
    "    prediction = print_pred_results(int(result[0]),num)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = X_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random_nums = random.choices(numbers, k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vr score:  3 \n",
      "dt score:  4 \n",
      "rf score:  3 \n",
      "ks score:  3\n"
     ]
    }
   ],
   "source": [
    "a,b,c,d = [],[],[],[]\n",
    "for i in random_nums:\n",
    "    a.append(predictionTest(i,vr))\n",
    "    b.append(predictionTest(i,dt))\n",
    "    c.append(predictionTest(i,rf))\n",
    "    d.append(predictionTest(i,ks))\n",
    "print('vr score: ',sum(a),'\\ndt score: ',sum(b),'\\nrf score: ',sum(c),'\\nks score: ',sum(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cycle_prob_test(num,model):\n",
    "    p = X_test.iloc[num].tolist()\n",
    "    e = model.predict([p]).flatten()\n",
    "    e = e[0]\n",
    "    if e < 1:\n",
    "        e = 0\n",
    "    elif e < 2:\n",
    "        e = 1\n",
    "    return e\n",
    "\n",
    "def model_pred_test(model):\n",
    "    b = []\n",
    "    prob = []\n",
    "    random_nums = np.random.randint(low=1, high=58, size=(20))\n",
    "    for i in random_nums:\n",
    "        prob.append(cycle_prob_test(i,model))\n",
    "    df = pd.DataFrame(prob)\n",
    "    df = df.values\n",
    "    print('scores :\\n',df)\n",
    "    #print(df)\n",
    "    #return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'models/cpl_score_regressor.sav'\n",
    "pickle.dump(dt, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import cpl_main as cpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = '2020'\n",
    "team_ref = pd.read_csv('datasets/teams.csv')\n",
    "results = pd.read_csv(f'datasets/{year}/cpl-{year}-results.csv')\n",
    "stats = pd.read_csv(f'datasets/{year}/cpl-{year}-stats.csv')\n",
    "player_info = pd.read_csv(f'datasets/{year}/player-{year}-info.csv')\n",
    "results_brief = pd.read_csv(f'datasets/{year}/cpl-{year}-results_brief.csv')\n",
    "team_stats = pd.read_csv(f'datasets/{year}/cpl-{year}-team_stats.csv')\n",
    "schedule = pd.read_csv(f'datasets/{year}/cpl-{year}-schedule.csv')\n",
    "rated_forwards = pd.read_csv(f'datasets/{year}/cpl-{year}-forwards.csv')\n",
    "rated_midfielders = pd.read_csv(f'datasets/{year}/cpl-{year}-midfielders.csv')\n",
    "rated_defenders = pd.read_csv(f'datasets/{year}/cpl-{year}-defenders.csv')\n",
    "rated_keepers = pd.read_csv(f'datasets/{year}/cpl-{year}-keepers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'models/cpl_score_regressor.sav'\n",
    "cpl_score_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_pred_test(cpl_classifier_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "York9 FC HFX Wanderers FC\n"
     ]
    }
   ],
   "source": [
    "# home side\n",
    "q1 = schedule.iloc[2]['home']\n",
    "# away side\n",
    "q2 = schedule.iloc[2]['away']\n",
    "print(q1,q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare = cpl.get_team_comparison(results_brief,q1,q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_x, t1_y = cpl.get_NB_data(compare,q1)\n",
    "t2_x, t2_y = cpl.get_NB_data(compare,q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game</th>\n",
       "      <th>home</th>\n",
       "      <th>away</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>II3</td>\n",
       "      <td>York9 FC</td>\n",
       "      <td>HFX Wanderers FC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  game      home              away\n",
       "2  II3  York9 FC  HFX Wanderers FC"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_info = schedule[schedule['home'] == q1]\n",
    "game_info = game_info[game_info['away'] == q2]\n",
    "game_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = game_info.iloc[0]['game']\n",
    "game_h = cpl.get_home_away_comparison(stats,game,q1)\n",
    "game_a = cpl.get_home_away_comparison(stats,game,q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/todd/anaconda3/lib/python3.7/site-packages/pandas/core/ops/array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>number</th>\n",
       "      <th>position</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Christian Oxner</td>\n",
       "      <td>50</td>\n",
       "      <td>g</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Peter Schaale</td>\n",
       "      <td>2</td>\n",
       "      <td>d</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chrisnovic N'sa</td>\n",
       "      <td>6</td>\n",
       "      <td>d</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alex DeCarolis</td>\n",
       "      <td>24</td>\n",
       "      <td>d</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Daniel Kinumbe</td>\n",
       "      <td>13</td>\n",
       "      <td>d</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Louis Béland-Goyette</td>\n",
       "      <td>5</td>\n",
       "      <td>m</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Andre Rampersad</td>\n",
       "      <td>18</td>\n",
       "      <td>m</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Scott Firth</td>\n",
       "      <td>15</td>\n",
       "      <td>m</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Aboubacar Sissoko</td>\n",
       "      <td>17</td>\n",
       "      <td>m</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Akeem Garcia</td>\n",
       "      <td>11</td>\n",
       "      <td>f</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Alessandro Riggi</td>\n",
       "      <td>10</td>\n",
       "      <td>f</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name  number position overall\n",
       "0        Christian Oxner      50        g    0.54\n",
       "1          Peter Schaale       2        d    0.62\n",
       "2        Chrisnovic N'sa       6        d    0.41\n",
       "3         Alex DeCarolis      24        d     0.4\n",
       "4         Daniel Kinumbe      13        d     0.0\n",
       "5   Louis Béland-Goyette       5        m    0.64\n",
       "6        Andre Rampersad      18        m    0.57\n",
       "7            Scott Firth      15        m     0.1\n",
       "8      Aboubacar Sissoko      17        m     0.0\n",
       "9           Akeem Garcia      11        f    0.47\n",
       "10      Alessandro Riggi      10        f     0.0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "home_roster = cpl.get_compare_roster(results,q1,team_stats,team_ref,rated_forwards,rated_midfielders,rated_defenders,rated_keepers,player_info)\n",
    "away_roster = cpl.get_compare_roster(results,q2,team_stats,team_ref,rated_forwards,rated_midfielders,rated_defenders,rated_keepers,player_info)\n",
    "away_roster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_overall_roster(game_roster):\n",
    "    b = []\n",
    "    for i in range(game_roster.shape[0]):\n",
    "        b.append(game_roster.iloc[i]['overall']) # get the player overall score for each player in the game\n",
    "    if len(b) < 16:\n",
    "        i = int(16 - len(b))\n",
    "        for j in range(0,i):\n",
    "            b.append(0)\n",
    "    db = pd.DataFrame(b[0:14])\n",
    "    db = db.T\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2     3     4     5    6     7     8    9   10 11 12 13\n",
       "0  0.93  0.92  0.91  0.86  0.67  0.65  0.6  0.46  0.45  0.0  0.0  0  0  0"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_roster = get_overall_roster(home_roster)\n",
    "q1_roster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.54</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2    3    4     5     6    7    8     9   10 11 12 13\n",
       "0  0.54  0.62  0.41  0.4  0.0  0.64  0.57  0.1  0.0  0.47  0.0  0  0  0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_roster = get_overall_roster(away_roster)\n",
    "q2_roster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roster_pred(model,array):\n",
    "    prediction = model.predict([array]).flatten()\n",
    "    df = pd.DataFrame(prediction)\n",
    "    #print('score :',prediction)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_win, draw, away_win = cpl.get_match_prediction(q1,q2,t1_x,t1_y,t2_x,t2_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/todd/anaconda3/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.22.1 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/todd/anaconda3/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.22.1 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "classifier = 'models/cpl_roster_classifier.sav'\n",
    "cpl_classifier_model = pickle.load(open(classifier, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_win_new, away_win_new, draw_new = cpl.get_final_game_prediction(cpl_classifier_model,q1_roster,q2_roster,home_win,away_win,draw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "York9 FC \n",
      "win probability:  0.42\n"
     ]
    }
   ],
   "source": [
    "print(q1,'\\nwin probability: ', round(home_win_new,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HFX Wanderers FC \n",
      "win probability:  0.28\n"
     ]
    }
   ],
   "source": [
    "print(q2,'\\nwin probability: ', round(away_win_new,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Draw probability:  0.3\n"
     ]
    }
   ],
   "source": [
    "print('Draw probability: ', round(draw_new,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = 2.56\n",
    "t = int(round(t,0))\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_score_prediction(model,q1_roster,q2_roster,home_win_new,away_win_new):\n",
    "    \n",
    "    def final_score_fix(home_score,away_score,home_win_new,away_win_new):\n",
    "        if home_win_new > away_win_new: # fix the score prediction - if the probability of home win > away win\n",
    "            home_score = away_score + 1 # change the predicted score to reflect that\n",
    "            return home_score,away_score \n",
    "        elif home_win_new < away_win_new: # else the probability of home win < away win\n",
    "            away_score = home_score + 1 # change the predicted score to reflect that\n",
    "            return home_score,away_score  \n",
    "    \n",
    "    def score(num): #improve this later for greater predictions\n",
    "        new_score = int(round(num,0)) # convert the float value to int and round it\n",
    "        return new_score\n",
    "    \n",
    "    q1_pred = roster_pred(model,q1_roster)\n",
    "    q1_s = score(q1_pred.iloc[0][0])\n",
    "    q2_pred = roster_pred(model,q2_roster)\n",
    "    q2_s = score(q2_pred.iloc[0][0])\n",
    "    home_score, away_score = final_score_fix(q1_s, q2_s,home_win_new,away_win_new)\n",
    "    return home_score, away_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_score, away_score = get_final_score_prediction(cpl_score_model,q1_roster,q2_roster,home_win_new,away_win_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 1\n"
     ]
    }
   ],
   "source": [
    "print(home_score, away_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_score_fix(home_score,away_score,home_win_new,away_win_new):\n",
    "    if home_win_new > away_win_new:\n",
    "        print('greater')\n",
    "        home_score = away_score + 1\n",
    "        return home_score,away_score \n",
    "    elif home_win_new < away_win_new:\n",
    "        print('less than')\n",
    "        away_score = home_score + 1\n",
    "        return home_score,away_score    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "greater\n"
     ]
    }
   ],
   "source": [
    "home_score, away_score = final_score_fix(home_score,away_score,home_win_new,away_win_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "home_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "away_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
